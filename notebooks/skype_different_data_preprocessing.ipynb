{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "sns.set()  # make plots nicer\n",
    "\n",
    "np.random.seed(42)  # set seed for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_parser_with_prev_next(path):\n",
    "    file = open(path, 'r')\n",
    "    lines = file.readlines()\n",
    "    \n",
    "    file_name = [path.split('/')[-1]]\n",
    "    sentence = \"\"\n",
    "    file_data = []\n",
    "    \n",
    "    has_value = False\n",
    "    previous = 0\n",
    "    \n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        \n",
    "        # if there are only 2 informations on line and second is h#, then ignore\n",
    "        # strip line, split primarly on ; secondary on ,\n",
    "        if (line.startswith('#')):\n",
    "            if (not sentence):\n",
    "                sentence = line[len('# Sentence: \"'): len(line) - 1]\n",
    "            continue\n",
    "        \n",
    "        line = line.split(';')\n",
    "        \n",
    "        if (len(line) == 1):\n",
    "            #lines containing only their packet size and nothing else, they should be added\n",
    "            #TODO\n",
    "            line += [\"\"]\n",
    "            line += [\"\"]\n",
    "            #continue\n",
    "        \n",
    "        if (len(line) == 2):\n",
    "            #this tries to remove most of the silence at the start of the recording\n",
    "            #potentionally harmfull as we shouldn't clean test data this way (we will be reading labels)\n",
    "            #if (line[1] == 'h#'):\n",
    "            #    continue\n",
    "            line += [\"\"]\n",
    "        \n",
    "        line[1] = tuple(line[1].split(','))\n",
    "        line[2] = tuple(list(map(lambda a: a.strip('\"'), line[2].split(','))))\n",
    "        \n",
    "        if (has_value):\n",
    "            file_data[-1][-4] = line[0]\n",
    "           \n",
    "        # file_type and sentence contain duplicate informations, but are kept for readability\n",
    "        split_filename = file_name[0].split('-')\n",
    "        \n",
    "        line = file_name + [split_filename[0]] + [split_filename[1]] + [split_filename[2][0:-4]] + [sentence] + [previous] + [0] + line\n",
    "        #adding previous as feature\n",
    "        previous = line[-3]\n",
    "        file_data += [line]\n",
    "        \n",
    "        #adding next frame as feature\n",
    "        has_value = True\n",
    "        \n",
    "    return pd.DataFrame(file_data, columns=['file', 'dialect', 'speaker', 'sentence_id', 'sentence', 'previous_packet', 'next_packet','packet_size', 'phonemes', 'words'])\n",
    "\n",
    "def load_files_with_prev_next(directory):\n",
    "    filelist = os.listdir(directory)\n",
    "    #read them into pandas\n",
    "    df_list = [file_parser_with_prev_next(directory+file) for file in filelist]\n",
    "    #concatenate them together\n",
    "    return pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "def convert_types(data_frame):\n",
    "    data_frame['packet_size'] = pd.to_numeric(data_frame['packet_size'])\n",
    "    data_frame['previous_packet'] = pd.to_numeric(data_frame['previous_packet'])\n",
    "    data_frame['next_packet'] = pd.to_numeric(data_frame['next_packet'])\n",
    "\n",
    "    data_frame['file'] = data_frame['file'].astype('category')\n",
    "    data_frame['sentence'] = data_frame['sentence'].astype('category')\n",
    "    \n",
    "    data_frame['dialect'] = data_frame['dialect'].astype('category')\n",
    "    data_frame['speaker'] = data_frame['speaker'].astype('category')\n",
    "    data_frame['sentence_id'] = data_frame['sentence_id'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>dialect</th>\n",
       "      <th>speaker</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>previous_packet</th>\n",
       "      <th>next_packet</th>\n",
       "      <th>packet_size</th>\n",
       "      <th>phonemes</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DR1-FAKS0-SA1.CSV</td>\n",
       "      <td>DR1</td>\n",
       "      <td>FAKS0</td>\n",
       "      <td>SA1</td>\n",
       "      <td>She had your dark suit in greasy wash water al...</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>30</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DR1-FAKS0-SA1.CSV</td>\n",
       "      <td>DR1</td>\n",
       "      <td>FAKS0</td>\n",
       "      <td>SA1</td>\n",
       "      <td>She had your dark suit in greasy wash water al...</td>\n",
       "      <td>30</td>\n",
       "      <td>43</td>\n",
       "      <td>35</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DR1-FAKS0-SA1.CSV</td>\n",
       "      <td>DR1</td>\n",
       "      <td>FAKS0</td>\n",
       "      <td>SA1</td>\n",
       "      <td>She had your dark suit in greasy wash water al...</td>\n",
       "      <td>35</td>\n",
       "      <td>26</td>\n",
       "      <td>43</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DR1-FAKS0-SA1.CSV</td>\n",
       "      <td>DR1</td>\n",
       "      <td>FAKS0</td>\n",
       "      <td>SA1</td>\n",
       "      <td>She had your dark suit in greasy wash water al...</td>\n",
       "      <td>43</td>\n",
       "      <td>30</td>\n",
       "      <td>26</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DR1-FAKS0-SA1.CSV</td>\n",
       "      <td>DR1</td>\n",
       "      <td>FAKS0</td>\n",
       "      <td>SA1</td>\n",
       "      <td>She had your dark suit in greasy wash water al...</td>\n",
       "      <td>26</td>\n",
       "      <td>31</td>\n",
       "      <td>30</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258516</th>\n",
       "      <td>DR8-MSLB0-SX383.CSV</td>\n",
       "      <td>DR8</td>\n",
       "      <td>MSLB0</td>\n",
       "      <td>SX383</td>\n",
       "      <td>The carpet cleaners shampooed our oriental rug.</td>\n",
       "      <td>40</td>\n",
       "      <td>43</td>\n",
       "      <td>46</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258517</th>\n",
       "      <td>DR8-MSLB0-SX383.CSV</td>\n",
       "      <td>DR8</td>\n",
       "      <td>MSLB0</td>\n",
       "      <td>SX383</td>\n",
       "      <td>The carpet cleaners shampooed our oriental rug.</td>\n",
       "      <td>46</td>\n",
       "      <td>41</td>\n",
       "      <td>43</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258518</th>\n",
       "      <td>DR8-MSLB0-SX383.CSV</td>\n",
       "      <td>DR8</td>\n",
       "      <td>MSLB0</td>\n",
       "      <td>SX383</td>\n",
       "      <td>The carpet cleaners shampooed our oriental rug.</td>\n",
       "      <td>43</td>\n",
       "      <td>34</td>\n",
       "      <td>41</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258519</th>\n",
       "      <td>DR8-MSLB0-SX383.CSV</td>\n",
       "      <td>DR8</td>\n",
       "      <td>MSLB0</td>\n",
       "      <td>SX383</td>\n",
       "      <td>The carpet cleaners shampooed our oriental rug.</td>\n",
       "      <td>41</td>\n",
       "      <td>33</td>\n",
       "      <td>34</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258520</th>\n",
       "      <td>DR8-MSLB0-SX383.CSV</td>\n",
       "      <td>DR8</td>\n",
       "      <td>MSLB0</td>\n",
       "      <td>SX383</td>\n",
       "      <td>The carpet cleaners shampooed our oriental rug.</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>258521 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       file dialect speaker sentence_id  \\\n",
       "0         DR1-FAKS0-SA1.CSV     DR1   FAKS0         SA1   \n",
       "1         DR1-FAKS0-SA1.CSV     DR1   FAKS0         SA1   \n",
       "2         DR1-FAKS0-SA1.CSV     DR1   FAKS0         SA1   \n",
       "3         DR1-FAKS0-SA1.CSV     DR1   FAKS0         SA1   \n",
       "4         DR1-FAKS0-SA1.CSV     DR1   FAKS0         SA1   \n",
       "...                     ...     ...     ...         ...   \n",
       "258516  DR8-MSLB0-SX383.CSV     DR8   MSLB0       SX383   \n",
       "258517  DR8-MSLB0-SX383.CSV     DR8   MSLB0       SX383   \n",
       "258518  DR8-MSLB0-SX383.CSV     DR8   MSLB0       SX383   \n",
       "258519  DR8-MSLB0-SX383.CSV     DR8   MSLB0       SX383   \n",
       "258520  DR8-MSLB0-SX383.CSV     DR8   MSLB0       SX383   \n",
       "\n",
       "                                                 sentence  previous_packet  \\\n",
       "0       She had your dark suit in greasy wash water al...                0   \n",
       "1       She had your dark suit in greasy wash water al...               30   \n",
       "2       She had your dark suit in greasy wash water al...               35   \n",
       "3       She had your dark suit in greasy wash water al...               43   \n",
       "4       She had your dark suit in greasy wash water al...               26   \n",
       "...                                                   ...              ...   \n",
       "258516    The carpet cleaners shampooed our oriental rug.               40   \n",
       "258517    The carpet cleaners shampooed our oriental rug.               46   \n",
       "258518    The carpet cleaners shampooed our oriental rug.               43   \n",
       "258519    The carpet cleaners shampooed our oriental rug.               41   \n",
       "258520    The carpet cleaners shampooed our oriental rug.               34   \n",
       "\n",
       "        next_packet  packet_size phonemes words  \n",
       "0                35           30    (h#,)   (,)  \n",
       "1                43           35    (h#,)   (,)  \n",
       "2                26           43    (h#,)   (,)  \n",
       "3                30           26    (h#,)   (,)  \n",
       "4                31           30    (h#,)   (,)  \n",
       "...             ...          ...      ...   ...  \n",
       "258516           43           46    (h#,)   (,)  \n",
       "258517           41           43    (h#,)   (,)  \n",
       "258518           34           41    (h#,)   (,)  \n",
       "258519           33           34    (h#,)   (,)  \n",
       "258520            0           33    (h#,)   (,)  \n",
       "\n",
       "[258521 rows x 10 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skype_data_train = load_files_with_prev_next(\"./../data/skype_train_data/\")\n",
    "skype_data_test = load_files_with_prev_next(\"./../data/skype_test_data/\")\n",
    "convert_types(skype_data_train)\n",
    "convert_types(skype_data_test)\n",
    "skype_data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>dialect</th>\n",
       "      <th>speaker</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>previous_packet</th>\n",
       "      <th>next_packet</th>\n",
       "      <th>packet_size</th>\n",
       "      <th>prev_curr</th>\n",
       "      <th>next_curr</th>\n",
       "      <th>packet_surrounding</th>\n",
       "      <th>phonemes</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DR1-FCJF0-SA1.CSV</td>\n",
       "      <td>DR1</td>\n",
       "      <td>FCJF0</td>\n",
       "      <td>SA1</td>\n",
       "      <td>She had your dark suit in greasy wash water al...</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>(0, 32)</td>\n",
       "      <td>(32, 32)</td>\n",
       "      <td>(0, 32, 32)</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DR1-FCJF0-SA1.CSV</td>\n",
       "      <td>DR1</td>\n",
       "      <td>FCJF0</td>\n",
       "      <td>SA1</td>\n",
       "      <td>She had your dark suit in greasy wash water al...</td>\n",
       "      <td>32</td>\n",
       "      <td>31</td>\n",
       "      <td>32</td>\n",
       "      <td>(32, 32)</td>\n",
       "      <td>(31, 32)</td>\n",
       "      <td>(32, 32, 31)</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DR1-FCJF0-SA1.CSV</td>\n",
       "      <td>DR1</td>\n",
       "      <td>FCJF0</td>\n",
       "      <td>SA1</td>\n",
       "      <td>She had your dark suit in greasy wash water al...</td>\n",
       "      <td>32</td>\n",
       "      <td>28</td>\n",
       "      <td>31</td>\n",
       "      <td>(32, 31)</td>\n",
       "      <td>(28, 31)</td>\n",
       "      <td>(32, 31, 28)</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DR1-FCJF0-SA1.CSV</td>\n",
       "      <td>DR1</td>\n",
       "      <td>FCJF0</td>\n",
       "      <td>SA1</td>\n",
       "      <td>She had your dark suit in greasy wash water al...</td>\n",
       "      <td>31</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>(31, 28)</td>\n",
       "      <td>(28, 28)</td>\n",
       "      <td>(31, 28, 28)</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DR1-FCJF0-SA1.CSV</td>\n",
       "      <td>DR1</td>\n",
       "      <td>FCJF0</td>\n",
       "      <td>SA1</td>\n",
       "      <td>She had your dark suit in greasy wash water al...</td>\n",
       "      <td>28</td>\n",
       "      <td>36</td>\n",
       "      <td>28</td>\n",
       "      <td>(28, 28)</td>\n",
       "      <td>(36, 28)</td>\n",
       "      <td>(28, 28, 36)</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707433</th>\n",
       "      <td>DR8-MTCS0-SX82.CSV</td>\n",
       "      <td>DR8</td>\n",
       "      <td>MTCS0</td>\n",
       "      <td>SX82</td>\n",
       "      <td>Good service should be rewarded by big tips.</td>\n",
       "      <td>47</td>\n",
       "      <td>34</td>\n",
       "      <td>32</td>\n",
       "      <td>(47, 32)</td>\n",
       "      <td>(34, 32)</td>\n",
       "      <td>(47, 32, 34)</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707434</th>\n",
       "      <td>DR8-MTCS0-SX82.CSV</td>\n",
       "      <td>DR8</td>\n",
       "      <td>MTCS0</td>\n",
       "      <td>SX82</td>\n",
       "      <td>Good service should be rewarded by big tips.</td>\n",
       "      <td>32</td>\n",
       "      <td>39</td>\n",
       "      <td>34</td>\n",
       "      <td>(32, 34)</td>\n",
       "      <td>(39, 34)</td>\n",
       "      <td>(32, 34, 39)</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707435</th>\n",
       "      <td>DR8-MTCS0-SX82.CSV</td>\n",
       "      <td>DR8</td>\n",
       "      <td>MTCS0</td>\n",
       "      <td>SX82</td>\n",
       "      <td>Good service should be rewarded by big tips.</td>\n",
       "      <td>34</td>\n",
       "      <td>33</td>\n",
       "      <td>39</td>\n",
       "      <td>(34, 39)</td>\n",
       "      <td>(33, 39)</td>\n",
       "      <td>(34, 39, 33)</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707436</th>\n",
       "      <td>DR8-MTCS0-SX82.CSV</td>\n",
       "      <td>DR8</td>\n",
       "      <td>MTCS0</td>\n",
       "      <td>SX82</td>\n",
       "      <td>Good service should be rewarded by big tips.</td>\n",
       "      <td>39</td>\n",
       "      <td>36</td>\n",
       "      <td>33</td>\n",
       "      <td>(39, 33)</td>\n",
       "      <td>(36, 33)</td>\n",
       "      <td>(39, 33, 36)</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707437</th>\n",
       "      <td>DR8-MTCS0-SX82.CSV</td>\n",
       "      <td>DR8</td>\n",
       "      <td>MTCS0</td>\n",
       "      <td>SX82</td>\n",
       "      <td>Good service should be rewarded by big tips.</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>(33, 36)</td>\n",
       "      <td>(0, 36)</td>\n",
       "      <td>(33, 36, 0)</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>707438 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      file dialect speaker sentence_id  \\\n",
       "0        DR1-FCJF0-SA1.CSV     DR1   FCJF0         SA1   \n",
       "1        DR1-FCJF0-SA1.CSV     DR1   FCJF0         SA1   \n",
       "2        DR1-FCJF0-SA1.CSV     DR1   FCJF0         SA1   \n",
       "3        DR1-FCJF0-SA1.CSV     DR1   FCJF0         SA1   \n",
       "4        DR1-FCJF0-SA1.CSV     DR1   FCJF0         SA1   \n",
       "...                    ...     ...     ...         ...   \n",
       "707433  DR8-MTCS0-SX82.CSV     DR8   MTCS0        SX82   \n",
       "707434  DR8-MTCS0-SX82.CSV     DR8   MTCS0        SX82   \n",
       "707435  DR8-MTCS0-SX82.CSV     DR8   MTCS0        SX82   \n",
       "707436  DR8-MTCS0-SX82.CSV     DR8   MTCS0        SX82   \n",
       "707437  DR8-MTCS0-SX82.CSV     DR8   MTCS0        SX82   \n",
       "\n",
       "                                                 sentence  previous_packet  \\\n",
       "0       She had your dark suit in greasy wash water al...                0   \n",
       "1       She had your dark suit in greasy wash water al...               32   \n",
       "2       She had your dark suit in greasy wash water al...               32   \n",
       "3       She had your dark suit in greasy wash water al...               31   \n",
       "4       She had your dark suit in greasy wash water al...               28   \n",
       "...                                                   ...              ...   \n",
       "707433       Good service should be rewarded by big tips.               47   \n",
       "707434       Good service should be rewarded by big tips.               32   \n",
       "707435       Good service should be rewarded by big tips.               34   \n",
       "707436       Good service should be rewarded by big tips.               39   \n",
       "707437       Good service should be rewarded by big tips.               33   \n",
       "\n",
       "        next_packet  packet_size prev_curr next_curr packet_surrounding  \\\n",
       "0                32           32   (0, 32)  (32, 32)        (0, 32, 32)   \n",
       "1                31           32  (32, 32)  (31, 32)       (32, 32, 31)   \n",
       "2                28           31  (32, 31)  (28, 31)       (32, 31, 28)   \n",
       "3                28           28  (31, 28)  (28, 28)       (31, 28, 28)   \n",
       "4                36           28  (28, 28)  (36, 28)       (28, 28, 36)   \n",
       "...             ...          ...       ...       ...                ...   \n",
       "707433           34           32  (47, 32)  (34, 32)       (47, 32, 34)   \n",
       "707434           39           34  (32, 34)  (39, 34)       (32, 34, 39)   \n",
       "707435           33           39  (34, 39)  (33, 39)       (34, 39, 33)   \n",
       "707436           36           33  (39, 33)  (36, 33)       (39, 33, 36)   \n",
       "707437            0           36  (33, 36)   (0, 36)        (33, 36, 0)   \n",
       "\n",
       "       phonemes words  \n",
       "0         (h#,)   (,)  \n",
       "1         (h#,)   (,)  \n",
       "2         (h#,)   (,)  \n",
       "3         (h#,)   (,)  \n",
       "4         (h#,)   (,)  \n",
       "...         ...   ...  \n",
       "707433    (h#,)   (,)  \n",
       "707434    (h#,)   (,)  \n",
       "707435    (h#,)   (,)  \n",
       "707436    (h#,)   (,)  \n",
       "707437    (h#,)   (,)  \n",
       "\n",
       "[707438 rows x 13 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_surrounding(data_frame):\n",
    "    data_frame['prev_curr'] = list(zip(data_frame.previous_packet, data_frame.packet_size))\n",
    "    data_frame['next_curr'] = list(zip(data_frame.next_packet, data_frame.packet_size))\n",
    "    data_frame['packet_surrounding'] = list(zip(data_frame.previous_packet, data_frame.packet_size, data_frame.next_packet))\n",
    "    \n",
    "    #data_frame['prev_curr'] = data_frame['prev_curr'].astype('category')\n",
    "    #data_frame['next_curr'] = data_frame['next_curr'].astype('category')\n",
    "    #data_frame['packet_surrounding'] = data_frame['packet_surrounding'].astype('category')\n",
    "\n",
    "add_surrounding(skype_data_train)\n",
    "add_surrounding(skype_data_test)\n",
    "\n",
    "skype_data_train = skype_data_train[['file', 'dialect', 'speaker', 'sentence_id', 'sentence', 'previous_packet', 'next_packet','packet_size', 'prev_curr', 'next_curr', 'packet_surrounding', 'phonemes', 'words']]\n",
    "skype_data_test = skype_data_test[['file', 'dialect', 'speaker', 'sentence_id', 'sentence', 'previous_packet', 'next_packet','packet_size', 'prev_curr', 'next_curr', 'packet_surrounding', 'phonemes', 'words']]\n",
    "skype_data_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>previous_packet</th>\n",
       "      <th>packet_size</th>\n",
       "      <th>next_packet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32</td>\n",
       "      <td>31</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707433</th>\n",
       "      <td>47</td>\n",
       "      <td>32</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707434</th>\n",
       "      <td>32</td>\n",
       "      <td>34</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707435</th>\n",
       "      <td>34</td>\n",
       "      <td>39</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707436</th>\n",
       "      <td>39</td>\n",
       "      <td>33</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707437</th>\n",
       "      <td>33</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>707438 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        previous_packet  packet_size  next_packet\n",
       "0                     0           32           32\n",
       "1                    32           32           31\n",
       "2                    32           31           28\n",
       "3                    31           28           28\n",
       "4                    28           28           36\n",
       "...                 ...          ...          ...\n",
       "707433               47           32           34\n",
       "707434               32           34           39\n",
       "707435               34           39           33\n",
       "707436               39           33           36\n",
       "707437               33           36            0\n",
       "\n",
       "[707438 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skype_data_train.loc[:, [\"previous_packet\", \"packet_size\", \"next_packet\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add removal of labels for the test_dataset\n",
    "def get_labels(df, label=[\"words\"], feature=[\"previous_packet\", \"packet_size\", \"next_packet\"]):\n",
    "    labels = df.loc[:, label]\n",
    "    features = df.loc[:, feature]\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_labels(train_labels, test_labels, label=[\"words\"]):\n",
    "    train_labels = train_labels.astype('category')\n",
    "    test_labels = test_labels.astype('category')\n",
    "    \n",
    "    total_labels = train_labels.append(test_labels)\n",
    "    \n",
    "    lab_enc = LabelEncoder()\n",
    "    lab_enc.fit(total_labels[label])\n",
    "\n",
    "    train_labels = lab_enc.transform(train_labels[label])\n",
    "    test_labels = lab_enc.transform(test_labels[label])\n",
    "    \n",
    "    return train_labels, test_labels, lab_enc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>dialect</th>\n",
       "      <th>speaker</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>previous_packet</th>\n",
       "      <th>next_packet</th>\n",
       "      <th>packet_size</th>\n",
       "      <th>prev_curr</th>\n",
       "      <th>next_curr</th>\n",
       "      <th>packet_surrounding</th>\n",
       "      <th>phonemes</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DR1-FCJF0-SA1.CSV</td>\n",
       "      <td>DR1</td>\n",
       "      <td>FCJF0</td>\n",
       "      <td>SA1</td>\n",
       "      <td>She had your dark suit in greasy wash water al...</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>(0, 32)</td>\n",
       "      <td>(32, 32)</td>\n",
       "      <td>(0, 32, 32)</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DR1-FCJF0-SA1.CSV</td>\n",
       "      <td>DR1</td>\n",
       "      <td>FCJF0</td>\n",
       "      <td>SA1</td>\n",
       "      <td>She had your dark suit in greasy wash water al...</td>\n",
       "      <td>32</td>\n",
       "      <td>31</td>\n",
       "      <td>32</td>\n",
       "      <td>(32, 32)</td>\n",
       "      <td>(31, 32)</td>\n",
       "      <td>(32, 32, 31)</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DR1-FCJF0-SA1.CSV</td>\n",
       "      <td>DR1</td>\n",
       "      <td>FCJF0</td>\n",
       "      <td>SA1</td>\n",
       "      <td>She had your dark suit in greasy wash water al...</td>\n",
       "      <td>32</td>\n",
       "      <td>28</td>\n",
       "      <td>31</td>\n",
       "      <td>(32, 31)</td>\n",
       "      <td>(28, 31)</td>\n",
       "      <td>(32, 31, 28)</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DR1-FCJF0-SA1.CSV</td>\n",
       "      <td>DR1</td>\n",
       "      <td>FCJF0</td>\n",
       "      <td>SA1</td>\n",
       "      <td>She had your dark suit in greasy wash water al...</td>\n",
       "      <td>31</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>(31, 28)</td>\n",
       "      <td>(28, 28)</td>\n",
       "      <td>(31, 28, 28)</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DR1-FCJF0-SA1.CSV</td>\n",
       "      <td>DR1</td>\n",
       "      <td>FCJF0</td>\n",
       "      <td>SA1</td>\n",
       "      <td>She had your dark suit in greasy wash water al...</td>\n",
       "      <td>28</td>\n",
       "      <td>36</td>\n",
       "      <td>28</td>\n",
       "      <td>(28, 28)</td>\n",
       "      <td>(36, 28)</td>\n",
       "      <td>(28, 28, 36)</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533700</th>\n",
       "      <td>DR8-MTCS0-SX82.CSV</td>\n",
       "      <td>DR8</td>\n",
       "      <td>MTCS0</td>\n",
       "      <td>SX82</td>\n",
       "      <td>Good service should be rewarded by big tips.</td>\n",
       "      <td>47</td>\n",
       "      <td>34</td>\n",
       "      <td>32</td>\n",
       "      <td>(47, 32)</td>\n",
       "      <td>(34, 32)</td>\n",
       "      <td>(47, 32, 34)</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533701</th>\n",
       "      <td>DR8-MTCS0-SX82.CSV</td>\n",
       "      <td>DR8</td>\n",
       "      <td>MTCS0</td>\n",
       "      <td>SX82</td>\n",
       "      <td>Good service should be rewarded by big tips.</td>\n",
       "      <td>32</td>\n",
       "      <td>39</td>\n",
       "      <td>34</td>\n",
       "      <td>(32, 34)</td>\n",
       "      <td>(39, 34)</td>\n",
       "      <td>(32, 34, 39)</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533702</th>\n",
       "      <td>DR8-MTCS0-SX82.CSV</td>\n",
       "      <td>DR8</td>\n",
       "      <td>MTCS0</td>\n",
       "      <td>SX82</td>\n",
       "      <td>Good service should be rewarded by big tips.</td>\n",
       "      <td>34</td>\n",
       "      <td>33</td>\n",
       "      <td>39</td>\n",
       "      <td>(34, 39)</td>\n",
       "      <td>(33, 39)</td>\n",
       "      <td>(34, 39, 33)</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533703</th>\n",
       "      <td>DR8-MTCS0-SX82.CSV</td>\n",
       "      <td>DR8</td>\n",
       "      <td>MTCS0</td>\n",
       "      <td>SX82</td>\n",
       "      <td>Good service should be rewarded by big tips.</td>\n",
       "      <td>39</td>\n",
       "      <td>36</td>\n",
       "      <td>33</td>\n",
       "      <td>(39, 33)</td>\n",
       "      <td>(36, 33)</td>\n",
       "      <td>(39, 33, 36)</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533704</th>\n",
       "      <td>DR8-MTCS0-SX82.CSV</td>\n",
       "      <td>DR8</td>\n",
       "      <td>MTCS0</td>\n",
       "      <td>SX82</td>\n",
       "      <td>Good service should be rewarded by big tips.</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>(33, 36)</td>\n",
       "      <td>(0, 36)</td>\n",
       "      <td>(33, 36, 0)</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>533705 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      file dialect speaker sentence_id  \\\n",
       "0        DR1-FCJF0-SA1.CSV     DR1   FCJF0         SA1   \n",
       "1        DR1-FCJF0-SA1.CSV     DR1   FCJF0         SA1   \n",
       "2        DR1-FCJF0-SA1.CSV     DR1   FCJF0         SA1   \n",
       "3        DR1-FCJF0-SA1.CSV     DR1   FCJF0         SA1   \n",
       "4        DR1-FCJF0-SA1.CSV     DR1   FCJF0         SA1   \n",
       "...                    ...     ...     ...         ...   \n",
       "533700  DR8-MTCS0-SX82.CSV     DR8   MTCS0        SX82   \n",
       "533701  DR8-MTCS0-SX82.CSV     DR8   MTCS0        SX82   \n",
       "533702  DR8-MTCS0-SX82.CSV     DR8   MTCS0        SX82   \n",
       "533703  DR8-MTCS0-SX82.CSV     DR8   MTCS0        SX82   \n",
       "533704  DR8-MTCS0-SX82.CSV     DR8   MTCS0        SX82   \n",
       "\n",
       "                                                 sentence  previous_packet  \\\n",
       "0       She had your dark suit in greasy wash water al...                0   \n",
       "1       She had your dark suit in greasy wash water al...               32   \n",
       "2       She had your dark suit in greasy wash water al...               32   \n",
       "3       She had your dark suit in greasy wash water al...               31   \n",
       "4       She had your dark suit in greasy wash water al...               28   \n",
       "...                                                   ...              ...   \n",
       "533700       Good service should be rewarded by big tips.               47   \n",
       "533701       Good service should be rewarded by big tips.               32   \n",
       "533702       Good service should be rewarded by big tips.               34   \n",
       "533703       Good service should be rewarded by big tips.               39   \n",
       "533704       Good service should be rewarded by big tips.               33   \n",
       "\n",
       "        next_packet  packet_size prev_curr next_curr packet_surrounding  \\\n",
       "0                32           32   (0, 32)  (32, 32)        (0, 32, 32)   \n",
       "1                31           32  (32, 32)  (31, 32)       (32, 32, 31)   \n",
       "2                28           31  (32, 31)  (28, 31)       (32, 31, 28)   \n",
       "3                28           28  (31, 28)  (28, 28)       (31, 28, 28)   \n",
       "4                36           28  (28, 28)  (36, 28)       (28, 28, 36)   \n",
       "...             ...          ...       ...       ...                ...   \n",
       "533700           34           32  (47, 32)  (34, 32)       (47, 32, 34)   \n",
       "533701           39           34  (32, 34)  (39, 34)       (32, 34, 39)   \n",
       "533702           33           39  (34, 39)  (33, 39)       (34, 39, 33)   \n",
       "533703           36           33  (39, 33)  (36, 33)       (39, 33, 36)   \n",
       "533704            0           36  (33, 36)   (0, 36)        (33, 36, 0)   \n",
       "\n",
       "       phonemes words  \n",
       "0         (h#,)   (,)  \n",
       "1         (h#,)   (,)  \n",
       "2         (h#,)   (,)  \n",
       "3         (h#,)   (,)  \n",
       "4         (h#,)   (,)  \n",
       "...         ...   ...  \n",
       "533700    (h#,)   (,)  \n",
       "533701    (h#,)   (,)  \n",
       "533702    (h#,)   (,)  \n",
       "533703    (h#,)   (,)  \n",
       "533704    (h#,)   (,)  \n",
       "\n",
       "[533705 rows x 13 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# there are no \"empty\" phonemes\n",
    "single_phonemes_train = skype_data_train.loc[skype_data_train.phonemes.apply(len) == 1].reset_index(drop=True)\n",
    "single_phonemes_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pd.unique(single_phonemes_train.phonemes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([('h#',), ('sh',), ('ix',), ('hv',), ('eh',), ('jh',), ('ih',),\n",
       "       ('dcl',), ('ah',), ('kcl',), ('k',), ('s',), ('ux',), ('q',),\n",
       "       ('en',), ('r',), ('w',), ('ao',), ('axr',), ('l',), ('y',),\n",
       "       ('uh',), ('n',), ('ae',), ('dx',), ('oy',), ('ax',), ('gcl',),\n",
       "       ('dh',), ('tcl',), ('iy',), ('v',), ('t',), ('f',), ('ow',),\n",
       "       ('d',), ('hh',), ('ch',), ('bcl',), ('aa',), ('em',), ('ng',),\n",
       "       ('m',), ('ay',), ('th',), ('ax-h',), ('ey',), ('p',), ('pcl',),\n",
       "       ('aw',), ('er',), ('z',), ('epi',), ('el',), ('uw',), ('g',),\n",
       "       ('',), ('b',), ('pau',), ('zh',), ('nx',), ('eng',)], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.unique(single_phonemes_train.phonemes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taken from: https://github.com/jhasegaw/phonecodes/blob/master/src/phonecode_tables.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "arpa_to_ipa = {\n",
    "    'aa':'ɑ',\n",
    "    'ae':'æ',\n",
    "    'ah':'ʌ',\n",
    "    'ah0':'ə',\n",
    "    'ao':'ɔ',\n",
    "    'aw':'aʊ',\n",
    "    'ay':'aɪ',\n",
    "    'eh':'ɛ',\n",
    "    'er':'ɝ',\n",
    "    'er0':'ɚ',\n",
    "    'ey':'eɪ',\n",
    "    'ih':'ɪ',\n",
    "    'ih0':'ɨ',\n",
    "    'iy':'i',\n",
    "    'ow':'oʊ',\n",
    "    'oy':'ɔɪ',\n",
    "    'uh':'ʊ',\n",
    "    'uw':'u',\n",
    "    'b':'b',\n",
    "    'ch':'tʃ',\n",
    "    'd':'d',\n",
    "    'dh':'ð',\n",
    "    'el':'l̩',\n",
    "    'em':'m̩',\n",
    "    'en':'n̩',\n",
    "    'f':'f',\n",
    "    'g':'ɡ',\n",
    "    'hh':'h',\n",
    "    'jh':'dʒ',\n",
    "    'k':'k',\n",
    "    'l':'l',\n",
    "    'm':'m',\n",
    "    'n':'n',\n",
    "    'ng':'ŋ',\n",
    "    'p':'p',\n",
    "    'q':'ʔ',\n",
    "    'r':'ɹ',\n",
    "    's':'s',\n",
    "    'sh':'ʃ',\n",
    "    't':'t',\n",
    "    'th':'θ',\n",
    "    'v':'v',\n",
    "    'w':'w',\n",
    "    'wh':'ʍ',\n",
    "    'y':'j',\n",
    "    'z':'z',\n",
    "    'zh':'ʒ',\n",
    "\n",
    "    'ax':'ə',\n",
    "    'ax-h':'ə̥',\n",
    "    'axr':'ɚ',\n",
    "    'bcl':'b',\n",
    "    'dcl':'d',\n",
    "    'dx':'ɾ',\n",
    "    'eng':'ŋ̍',\n",
    "    'epi':'',\n",
    "    'gcl':'g',\n",
    "    'hv':'ɦ',\n",
    "    'h#':'',\n",
    "    'ix':'ɨ',\n",
    "    'kcl':'k',\n",
    "    'nx':'ɾ̃',\n",
    "    'pau':'',\n",
    "    'pcl':'p',\n",
    "    'tcl':'t',\n",
    "    'ux':'ʉ',\n",
    "    '':'',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(arpa_to_ipa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This modification is based on this: https://en.wikipedia.org/wiki/ARPABET (+ minor guessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipa_allophone = {\n",
    "    'ŋ̍':'n', #should be ŋ\n",
    "    'ə̥':'ɛ',\n",
    "    'ɨ':'ɪ',\n",
    "    'n̩':'n',\n",
    "    'm̩':'m',\n",
    "    'ŋ':'n',\n",
    "    'ɾ̃':'n',\n",
    "    'ð':'θ',\n",
    "    'ʉ':'u',\n",
    "    'ɾ':'d',\n",
    "    'l̩':'l',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', 'ʃ', 'ɪ', 'ɦ', 'ɛ', 'dʒ', 'ɪ', 'd', 'ʌ', 'k', 'k', 's', 'u',\n",
       "       'ʔ', 'n', 'ɹ', 'w', 'ɔ', 'ɚ', 'l', 'j', 'ʊ', 'n', 'æ', 'd', 'ɔɪ',\n",
       "       'ə', 'g', 'θ', 't', 'i', 'v', 't', 'f', 'oʊ', 'd', 'h', 'tʃ', 'b',\n",
       "       'ɑ', 'm', 'n', 'm', 'aɪ', 'θ', 'ɛ', 'eɪ', 'p', 'p', 'aʊ', 'ɝ', 'z',\n",
       "       '', 'l', 'u', 'ɡ', '', 'b', '', 'ʒ', 'n', 'n'], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniq_phon = pd.unique(single_phonemes_train.phonemes)\n",
    "for i in range(len(uniq_phon)):\n",
    "    uniq_phon[i] = arpa_to_ipa.get(uniq_phon[i][0], uniq_phon[i][0])\n",
    "    uniq_phon[i] = ipa_allophone.get(uniq_phon[i], uniq_phon[i])\n",
    "    \n",
    "uniq_phon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(uniq_phon))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now modifying our input dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input is expected to be a tuple\n",
    "def convert_phoneme(phoneme):\n",
    "    tmp_1 = arpa_to_ipa.get(phoneme[0], phoneme[0])\n",
    "    tmp_2 = ipa_allophone.get(tmp_1, tmp_1)\n",
    "    return tmp_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>dialect</th>\n",
       "      <th>speaker</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>previous_packet</th>\n",
       "      <th>next_packet</th>\n",
       "      <th>packet_size</th>\n",
       "      <th>prev_curr</th>\n",
       "      <th>next_curr</th>\n",
       "      <th>packet_surrounding</th>\n",
       "      <th>phonemes</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DR1-FAKS0-SA1.CSV</td>\n",
       "      <td>DR1</td>\n",
       "      <td>FAKS0</td>\n",
       "      <td>SA1</td>\n",
       "      <td>She had your dark suit in greasy wash water al...</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>30</td>\n",
       "      <td>(0, 30)</td>\n",
       "      <td>(35, 30)</td>\n",
       "      <td>(0, 30, 35)</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DR1-FAKS0-SA1.CSV</td>\n",
       "      <td>DR1</td>\n",
       "      <td>FAKS0</td>\n",
       "      <td>SA1</td>\n",
       "      <td>She had your dark suit in greasy wash water al...</td>\n",
       "      <td>30</td>\n",
       "      <td>43</td>\n",
       "      <td>35</td>\n",
       "      <td>(30, 35)</td>\n",
       "      <td>(43, 35)</td>\n",
       "      <td>(30, 35, 43)</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DR1-FAKS0-SA1.CSV</td>\n",
       "      <td>DR1</td>\n",
       "      <td>FAKS0</td>\n",
       "      <td>SA1</td>\n",
       "      <td>She had your dark suit in greasy wash water al...</td>\n",
       "      <td>35</td>\n",
       "      <td>26</td>\n",
       "      <td>43</td>\n",
       "      <td>(35, 43)</td>\n",
       "      <td>(26, 43)</td>\n",
       "      <td>(35, 43, 26)</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DR1-FAKS0-SA1.CSV</td>\n",
       "      <td>DR1</td>\n",
       "      <td>FAKS0</td>\n",
       "      <td>SA1</td>\n",
       "      <td>She had your dark suit in greasy wash water al...</td>\n",
       "      <td>43</td>\n",
       "      <td>30</td>\n",
       "      <td>26</td>\n",
       "      <td>(43, 26)</td>\n",
       "      <td>(30, 26)</td>\n",
       "      <td>(43, 26, 30)</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DR1-FAKS0-SA1.CSV</td>\n",
       "      <td>DR1</td>\n",
       "      <td>FAKS0</td>\n",
       "      <td>SA1</td>\n",
       "      <td>She had your dark suit in greasy wash water al...</td>\n",
       "      <td>26</td>\n",
       "      <td>31</td>\n",
       "      <td>30</td>\n",
       "      <td>(26, 30)</td>\n",
       "      <td>(31, 30)</td>\n",
       "      <td>(26, 30, 31)</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195608</th>\n",
       "      <td>DR8-MSLB0-SX383.CSV</td>\n",
       "      <td>DR8</td>\n",
       "      <td>MSLB0</td>\n",
       "      <td>SX383</td>\n",
       "      <td>The carpet cleaners shampooed our oriental rug.</td>\n",
       "      <td>40</td>\n",
       "      <td>43</td>\n",
       "      <td>46</td>\n",
       "      <td>(40, 46)</td>\n",
       "      <td>(43, 46)</td>\n",
       "      <td>(40, 46, 43)</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195609</th>\n",
       "      <td>DR8-MSLB0-SX383.CSV</td>\n",
       "      <td>DR8</td>\n",
       "      <td>MSLB0</td>\n",
       "      <td>SX383</td>\n",
       "      <td>The carpet cleaners shampooed our oriental rug.</td>\n",
       "      <td>46</td>\n",
       "      <td>41</td>\n",
       "      <td>43</td>\n",
       "      <td>(46, 43)</td>\n",
       "      <td>(41, 43)</td>\n",
       "      <td>(46, 43, 41)</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195610</th>\n",
       "      <td>DR8-MSLB0-SX383.CSV</td>\n",
       "      <td>DR8</td>\n",
       "      <td>MSLB0</td>\n",
       "      <td>SX383</td>\n",
       "      <td>The carpet cleaners shampooed our oriental rug.</td>\n",
       "      <td>43</td>\n",
       "      <td>34</td>\n",
       "      <td>41</td>\n",
       "      <td>(43, 41)</td>\n",
       "      <td>(34, 41)</td>\n",
       "      <td>(43, 41, 34)</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195611</th>\n",
       "      <td>DR8-MSLB0-SX383.CSV</td>\n",
       "      <td>DR8</td>\n",
       "      <td>MSLB0</td>\n",
       "      <td>SX383</td>\n",
       "      <td>The carpet cleaners shampooed our oriental rug.</td>\n",
       "      <td>41</td>\n",
       "      <td>33</td>\n",
       "      <td>34</td>\n",
       "      <td>(41, 34)</td>\n",
       "      <td>(33, 34)</td>\n",
       "      <td>(41, 34, 33)</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195612</th>\n",
       "      <td>DR8-MSLB0-SX383.CSV</td>\n",
       "      <td>DR8</td>\n",
       "      <td>MSLB0</td>\n",
       "      <td>SX383</td>\n",
       "      <td>The carpet cleaners shampooed our oriental rug.</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>(34, 33)</td>\n",
       "      <td>(0, 33)</td>\n",
       "      <td>(34, 33, 0)</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195613 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       file dialect speaker sentence_id  \\\n",
       "0         DR1-FAKS0-SA1.CSV     DR1   FAKS0         SA1   \n",
       "1         DR1-FAKS0-SA1.CSV     DR1   FAKS0         SA1   \n",
       "2         DR1-FAKS0-SA1.CSV     DR1   FAKS0         SA1   \n",
       "3         DR1-FAKS0-SA1.CSV     DR1   FAKS0         SA1   \n",
       "4         DR1-FAKS0-SA1.CSV     DR1   FAKS0         SA1   \n",
       "...                     ...     ...     ...         ...   \n",
       "195608  DR8-MSLB0-SX383.CSV     DR8   MSLB0       SX383   \n",
       "195609  DR8-MSLB0-SX383.CSV     DR8   MSLB0       SX383   \n",
       "195610  DR8-MSLB0-SX383.CSV     DR8   MSLB0       SX383   \n",
       "195611  DR8-MSLB0-SX383.CSV     DR8   MSLB0       SX383   \n",
       "195612  DR8-MSLB0-SX383.CSV     DR8   MSLB0       SX383   \n",
       "\n",
       "                                                 sentence  previous_packet  \\\n",
       "0       She had your dark suit in greasy wash water al...                0   \n",
       "1       She had your dark suit in greasy wash water al...               30   \n",
       "2       She had your dark suit in greasy wash water al...               35   \n",
       "3       She had your dark suit in greasy wash water al...               43   \n",
       "4       She had your dark suit in greasy wash water al...               26   \n",
       "...                                                   ...              ...   \n",
       "195608    The carpet cleaners shampooed our oriental rug.               40   \n",
       "195609    The carpet cleaners shampooed our oriental rug.               46   \n",
       "195610    The carpet cleaners shampooed our oriental rug.               43   \n",
       "195611    The carpet cleaners shampooed our oriental rug.               41   \n",
       "195612    The carpet cleaners shampooed our oriental rug.               34   \n",
       "\n",
       "        next_packet  packet_size prev_curr next_curr packet_surrounding  \\\n",
       "0                35           30   (0, 30)  (35, 30)        (0, 30, 35)   \n",
       "1                43           35  (30, 35)  (43, 35)       (30, 35, 43)   \n",
       "2                26           43  (35, 43)  (26, 43)       (35, 43, 26)   \n",
       "3                30           26  (43, 26)  (30, 26)       (43, 26, 30)   \n",
       "4                31           30  (26, 30)  (31, 30)       (26, 30, 31)   \n",
       "...             ...          ...       ...       ...                ...   \n",
       "195608           43           46  (40, 46)  (43, 46)       (40, 46, 43)   \n",
       "195609           41           43  (46, 43)  (41, 43)       (46, 43, 41)   \n",
       "195610           34           41  (43, 41)  (34, 41)       (43, 41, 34)   \n",
       "195611           33           34  (41, 34)  (33, 34)       (41, 34, 33)   \n",
       "195612            0           33  (34, 33)   (0, 33)        (34, 33, 0)   \n",
       "\n",
       "       phonemes words  \n",
       "0         (h#,)   (,)  \n",
       "1         (h#,)   (,)  \n",
       "2         (h#,)   (,)  \n",
       "3         (h#,)   (,)  \n",
       "4         (h#,)   (,)  \n",
       "...         ...   ...  \n",
       "195608    (h#,)   (,)  \n",
       "195609    (h#,)   (,)  \n",
       "195610    (h#,)   (,)  \n",
       "195611    (h#,)   (,)  \n",
       "195612    (h#,)   (,)  \n",
       "\n",
       "[195613 rows x 13 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_phonemes_train = skype_data_train.loc[skype_data_train.phonemes.apply(len) == 1].reset_index(drop=True)\n",
    "single_phonemes_test = skype_data_test.loc[skype_data_test.phonemes.apply(len) == 1].reset_index(drop=True)\n",
    "single_phonemes_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>dialect</th>\n",
       "      <th>speaker</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>previous_packet</th>\n",
       "      <th>next_packet</th>\n",
       "      <th>packet_size</th>\n",
       "      <th>prev_curr</th>\n",
       "      <th>next_curr</th>\n",
       "      <th>packet_surrounding</th>\n",
       "      <th>phonemes</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DR1-FCJF0-SA1.CSV</td>\n",
       "      <td>DR1</td>\n",
       "      <td>FCJF0</td>\n",
       "      <td>SA1</td>\n",
       "      <td>She had your dark suit in greasy wash water al...</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>(0, 32)</td>\n",
       "      <td>(32, 32)</td>\n",
       "      <td>(0, 32, 32)</td>\n",
       "      <td></td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DR1-FCJF0-SA1.CSV</td>\n",
       "      <td>DR1</td>\n",
       "      <td>FCJF0</td>\n",
       "      <td>SA1</td>\n",
       "      <td>She had your dark suit in greasy wash water al...</td>\n",
       "      <td>32</td>\n",
       "      <td>31</td>\n",
       "      <td>32</td>\n",
       "      <td>(32, 32)</td>\n",
       "      <td>(31, 32)</td>\n",
       "      <td>(32, 32, 31)</td>\n",
       "      <td></td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DR1-FCJF0-SA1.CSV</td>\n",
       "      <td>DR1</td>\n",
       "      <td>FCJF0</td>\n",
       "      <td>SA1</td>\n",
       "      <td>She had your dark suit in greasy wash water al...</td>\n",
       "      <td>32</td>\n",
       "      <td>28</td>\n",
       "      <td>31</td>\n",
       "      <td>(32, 31)</td>\n",
       "      <td>(28, 31)</td>\n",
       "      <td>(32, 31, 28)</td>\n",
       "      <td></td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DR1-FCJF0-SA1.CSV</td>\n",
       "      <td>DR1</td>\n",
       "      <td>FCJF0</td>\n",
       "      <td>SA1</td>\n",
       "      <td>She had your dark suit in greasy wash water al...</td>\n",
       "      <td>31</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>(31, 28)</td>\n",
       "      <td>(28, 28)</td>\n",
       "      <td>(31, 28, 28)</td>\n",
       "      <td></td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DR1-FCJF0-SA1.CSV</td>\n",
       "      <td>DR1</td>\n",
       "      <td>FCJF0</td>\n",
       "      <td>SA1</td>\n",
       "      <td>She had your dark suit in greasy wash water al...</td>\n",
       "      <td>28</td>\n",
       "      <td>36</td>\n",
       "      <td>28</td>\n",
       "      <td>(28, 28)</td>\n",
       "      <td>(36, 28)</td>\n",
       "      <td>(28, 28, 36)</td>\n",
       "      <td></td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533700</th>\n",
       "      <td>DR8-MTCS0-SX82.CSV</td>\n",
       "      <td>DR8</td>\n",
       "      <td>MTCS0</td>\n",
       "      <td>SX82</td>\n",
       "      <td>Good service should be rewarded by big tips.</td>\n",
       "      <td>47</td>\n",
       "      <td>34</td>\n",
       "      <td>32</td>\n",
       "      <td>(47, 32)</td>\n",
       "      <td>(34, 32)</td>\n",
       "      <td>(47, 32, 34)</td>\n",
       "      <td></td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533701</th>\n",
       "      <td>DR8-MTCS0-SX82.CSV</td>\n",
       "      <td>DR8</td>\n",
       "      <td>MTCS0</td>\n",
       "      <td>SX82</td>\n",
       "      <td>Good service should be rewarded by big tips.</td>\n",
       "      <td>32</td>\n",
       "      <td>39</td>\n",
       "      <td>34</td>\n",
       "      <td>(32, 34)</td>\n",
       "      <td>(39, 34)</td>\n",
       "      <td>(32, 34, 39)</td>\n",
       "      <td></td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533702</th>\n",
       "      <td>DR8-MTCS0-SX82.CSV</td>\n",
       "      <td>DR8</td>\n",
       "      <td>MTCS0</td>\n",
       "      <td>SX82</td>\n",
       "      <td>Good service should be rewarded by big tips.</td>\n",
       "      <td>34</td>\n",
       "      <td>33</td>\n",
       "      <td>39</td>\n",
       "      <td>(34, 39)</td>\n",
       "      <td>(33, 39)</td>\n",
       "      <td>(34, 39, 33)</td>\n",
       "      <td></td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533703</th>\n",
       "      <td>DR8-MTCS0-SX82.CSV</td>\n",
       "      <td>DR8</td>\n",
       "      <td>MTCS0</td>\n",
       "      <td>SX82</td>\n",
       "      <td>Good service should be rewarded by big tips.</td>\n",
       "      <td>39</td>\n",
       "      <td>36</td>\n",
       "      <td>33</td>\n",
       "      <td>(39, 33)</td>\n",
       "      <td>(36, 33)</td>\n",
       "      <td>(39, 33, 36)</td>\n",
       "      <td></td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533704</th>\n",
       "      <td>DR8-MTCS0-SX82.CSV</td>\n",
       "      <td>DR8</td>\n",
       "      <td>MTCS0</td>\n",
       "      <td>SX82</td>\n",
       "      <td>Good service should be rewarded by big tips.</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>(33, 36)</td>\n",
       "      <td>(0, 36)</td>\n",
       "      <td>(33, 36, 0)</td>\n",
       "      <td></td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>533705 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      file dialect speaker sentence_id  \\\n",
       "0        DR1-FCJF0-SA1.CSV     DR1   FCJF0         SA1   \n",
       "1        DR1-FCJF0-SA1.CSV     DR1   FCJF0         SA1   \n",
       "2        DR1-FCJF0-SA1.CSV     DR1   FCJF0         SA1   \n",
       "3        DR1-FCJF0-SA1.CSV     DR1   FCJF0         SA1   \n",
       "4        DR1-FCJF0-SA1.CSV     DR1   FCJF0         SA1   \n",
       "...                    ...     ...     ...         ...   \n",
       "533700  DR8-MTCS0-SX82.CSV     DR8   MTCS0        SX82   \n",
       "533701  DR8-MTCS0-SX82.CSV     DR8   MTCS0        SX82   \n",
       "533702  DR8-MTCS0-SX82.CSV     DR8   MTCS0        SX82   \n",
       "533703  DR8-MTCS0-SX82.CSV     DR8   MTCS0        SX82   \n",
       "533704  DR8-MTCS0-SX82.CSV     DR8   MTCS0        SX82   \n",
       "\n",
       "                                                 sentence  previous_packet  \\\n",
       "0       She had your dark suit in greasy wash water al...                0   \n",
       "1       She had your dark suit in greasy wash water al...               32   \n",
       "2       She had your dark suit in greasy wash water al...               32   \n",
       "3       She had your dark suit in greasy wash water al...               31   \n",
       "4       She had your dark suit in greasy wash water al...               28   \n",
       "...                                                   ...              ...   \n",
       "533700       Good service should be rewarded by big tips.               47   \n",
       "533701       Good service should be rewarded by big tips.               32   \n",
       "533702       Good service should be rewarded by big tips.               34   \n",
       "533703       Good service should be rewarded by big tips.               39   \n",
       "533704       Good service should be rewarded by big tips.               33   \n",
       "\n",
       "        next_packet  packet_size prev_curr next_curr packet_surrounding  \\\n",
       "0                32           32   (0, 32)  (32, 32)        (0, 32, 32)   \n",
       "1                31           32  (32, 32)  (31, 32)       (32, 32, 31)   \n",
       "2                28           31  (32, 31)  (28, 31)       (32, 31, 28)   \n",
       "3                28           28  (31, 28)  (28, 28)       (31, 28, 28)   \n",
       "4                36           28  (28, 28)  (36, 28)       (28, 28, 36)   \n",
       "...             ...          ...       ...       ...                ...   \n",
       "533700           34           32  (47, 32)  (34, 32)       (47, 32, 34)   \n",
       "533701           39           34  (32, 34)  (39, 34)       (32, 34, 39)   \n",
       "533702           33           39  (34, 39)  (33, 39)       (34, 39, 33)   \n",
       "533703           36           33  (39, 33)  (36, 33)       (39, 33, 36)   \n",
       "533704            0           36  (33, 36)   (0, 36)        (33, 36, 0)   \n",
       "\n",
       "       phonemes words  \n",
       "0                 (,)  \n",
       "1                 (,)  \n",
       "2                 (,)  \n",
       "3                 (,)  \n",
       "4                 (,)  \n",
       "...         ...   ...  \n",
       "533700            (,)  \n",
       "533701            (,)  \n",
       "533702            (,)  \n",
       "533703            (,)  \n",
       "533704            (,)  \n",
       "\n",
       "[533705 rows x 13 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_phonemes_test['phonemes'] = single_phonemes_test[\"phonemes\"].apply(convert_phoneme)\n",
    "single_phonemes_train['phonemes'] = single_phonemes_train[\"phonemes\"].apply(convert_phoneme)\n",
    "single_phonemes_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['', 'ʃ', 'i', 'ɦ', 'æ', 'd', 'ɝ', 'ɑ', 'ɹ', 'k', 's', 'u', 'ɪ',\n",
       "       'n', 'g', 'ɡ', 'w', 'ʔ', 'ɔ', 'l', 'j', 'ɚ', 'oʊ', 't', 'ɛ', 'ɔɪ',\n",
       "       'aɪ', 'θ', 'h', 'z', 'p', 'ə', 'b', 'f', 'v', 'm', 'aʊ', 'ʌ', 'eɪ',\n",
       "       'tʃ', 'ʊ', 'dʒ', 'ʒ'], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = pd.unique(single_phonemes_test.phonemes)\n",
    "print(len(tmp))\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n",
      "43\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set, train_labels = get_labels(single_phonemes_train, label=['phonemes'])\n",
    "test_set, test_labels = get_labels(single_phonemes_test, label=['phonemes'])\n",
    "\n",
    "train_labels = train_labels.astype('category')\n",
    "test_labels = test_labels.astype('category')\n",
    "\n",
    "total_labels = train_labels.append(test_labels)\n",
    "print(len(pd.unique(train_labels.phonemes)))\n",
    "print(len(pd.unique(test_labels.phonemes)))\n",
    "total_unique_phonemes = len(pd.unique(total_labels.phonemes))\n",
    "total_unique_phonemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5104\n",
      "2464\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6387"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set, train_labels = get_labels(single_phonemes_train)\n",
    "test_set, test_labels = get_labels(single_phonemes_test)\n",
    "\n",
    "train_labels = train_labels.astype('category')\n",
    "test_labels = test_labels.astype('category')\n",
    "\n",
    "total_labels = train_labels.append(test_labels)\n",
    "print(len(pd.unique(train_labels.words)))\n",
    "print(len(pd.unique(test_labels.words)))\n",
    "total_unique_words = len(pd.unique(total_labels.words))\n",
    "total_unique_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging long sequencess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         True\n",
       "1         True\n",
       "2         True\n",
       "3         True\n",
       "4         True\n",
       "          ... \n",
       "533699    True\n",
       "533700    True\n",
       "533701    True\n",
       "533702    True\n",
       "533703    True\n",
       "Length: 533704, dtype: bool"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = single_phonemes_train[[\"file\", \"phonemes\", \"packet_surrounding\"]][1:].reset_index(drop=True) != single_phonemes_train[[\"file\", \"phonemes\", \"packet_surrounding\"]][:-1]\n",
    "prev_not_same = (tmp.phonemes | tmp.packet_surrounding)\n",
    "prev_not_same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         True\n",
       "1         True\n",
       "2         True\n",
       "3         True\n",
       "4         True\n",
       "          ... \n",
       "533700    True\n",
       "533701    True\n",
       "533702    True\n",
       "533703    True\n",
       "533704    True\n",
       "Length: 533705, dtype: bool"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prev_not_same.loc[-1] = True\n",
    "prev_not_same.index = prev_not_same.index + 1\n",
    "prev_not_same.sort_index(inplace=True)\n",
    "prev_not_same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>dialect</th>\n",
       "      <th>speaker</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>previous_packet</th>\n",
       "      <th>next_packet</th>\n",
       "      <th>packet_size</th>\n",
       "      <th>prev_curr</th>\n",
       "      <th>next_curr</th>\n",
       "      <th>packet_surrounding</th>\n",
       "      <th>phonemes</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3542</th>\n",
       "      <td>DR1-FECD0-SI1418.CSV</td>\n",
       "      <td>DR1</td>\n",
       "      <td>FECD0</td>\n",
       "      <td>SI1418</td>\n",
       "      <td>Personal predispositions tend to blunt the ear...</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>(39, 39)</td>\n",
       "      <td>(39, 39)</td>\n",
       "      <td>(39, 39, 39)</td>\n",
       "      <td></td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5220</th>\n",
       "      <td>DR1-FETB0-SX248.CSV</td>\n",
       "      <td>DR1</td>\n",
       "      <td>FETB0</td>\n",
       "      <td>SX248</td>\n",
       "      <td>Reading in poor light gives you eyestrain.</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>(33, 33)</td>\n",
       "      <td>(33, 33)</td>\n",
       "      <td>(33, 33, 33)</td>\n",
       "      <td></td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6012</th>\n",
       "      <td>DR1-FJSP0-SI1763.CSV</td>\n",
       "      <td>DR1</td>\n",
       "      <td>FJSP0</td>\n",
       "      <td>SI1763</td>\n",
       "      <td>That's your headache.</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>(42, 42)</td>\n",
       "      <td>(42, 42)</td>\n",
       "      <td>(42, 42, 42)</td>\n",
       "      <td></td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6559</th>\n",
       "      <td>DR1-FJSP0-SX444.CSV</td>\n",
       "      <td>DR1</td>\n",
       "      <td>FJSP0</td>\n",
       "      <td>SX444</td>\n",
       "      <td>The toddler found a clamshell near the camp site.</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>(42, 42)</td>\n",
       "      <td>(42, 42)</td>\n",
       "      <td>(42, 42, 42)</td>\n",
       "      <td></td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8242</th>\n",
       "      <td>DR1-FMEM0-SA2.CSV</td>\n",
       "      <td>DR1</td>\n",
       "      <td>FMEM0</td>\n",
       "      <td>SA2</td>\n",
       "      <td>Don't ask me to carry an oily rag like that.</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>(30, 30)</td>\n",
       "      <td>(30, 30)</td>\n",
       "      <td>(30, 30, 30)</td>\n",
       "      <td></td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515430</th>\n",
       "      <td>DR8-FMBG0-SA1.CSV</td>\n",
       "      <td>DR8</td>\n",
       "      <td>FMBG0</td>\n",
       "      <td>SA1</td>\n",
       "      <td>She had your dark suit in greasy wash water al...</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>(30, 30)</td>\n",
       "      <td>(30, 30)</td>\n",
       "      <td>(30, 30, 30)</td>\n",
       "      <td></td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518926</th>\n",
       "      <td>DR8-MBCG0-SI2217.CSV</td>\n",
       "      <td>DR8</td>\n",
       "      <td>MBCG0</td>\n",
       "      <td>SI2217</td>\n",
       "      <td>He'd not only told me so, he'd proved it.</td>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "      <td>(63, 63)</td>\n",
       "      <td>(63, 63)</td>\n",
       "      <td>(63, 63, 63)</td>\n",
       "      <td>i</td>\n",
       "      <td>(he'd,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524746</th>\n",
       "      <td>DR8-MKRG0-SX31.CSV</td>\n",
       "      <td>DR8</td>\n",
       "      <td>MKRG0</td>\n",
       "      <td>SX31</td>\n",
       "      <td>A good attitude is unbeatable.</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>(38, 38)</td>\n",
       "      <td>(38, 38)</td>\n",
       "      <td>(38, 38, 38)</td>\n",
       "      <td></td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525211</th>\n",
       "      <td>DR8-MMEA0-SI2018.CSV</td>\n",
       "      <td>DR8</td>\n",
       "      <td>MMEA0</td>\n",
       "      <td>SI2018</td>\n",
       "      <td>They were shattered.</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>(27, 27)</td>\n",
       "      <td>(27, 27)</td>\n",
       "      <td>(27, 27, 27)</td>\n",
       "      <td></td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530312</th>\n",
       "      <td>DR8-MRLK0-SA2.CSV</td>\n",
       "      <td>DR8</td>\n",
       "      <td>MRLK0</td>\n",
       "      <td>SA2</td>\n",
       "      <td>Don't ask me to carry an oily rag like that.</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>(43, 43)</td>\n",
       "      <td>(43, 43)</td>\n",
       "      <td>(43, 43, 43)</td>\n",
       "      <td></td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        file dialect speaker sentence_id  \\\n",
       "3542    DR1-FECD0-SI1418.CSV     DR1   FECD0      SI1418   \n",
       "5220     DR1-FETB0-SX248.CSV     DR1   FETB0       SX248   \n",
       "6012    DR1-FJSP0-SI1763.CSV     DR1   FJSP0      SI1763   \n",
       "6559     DR1-FJSP0-SX444.CSV     DR1   FJSP0       SX444   \n",
       "8242       DR1-FMEM0-SA2.CSV     DR1   FMEM0         SA2   \n",
       "...                      ...     ...     ...         ...   \n",
       "515430     DR8-FMBG0-SA1.CSV     DR8   FMBG0         SA1   \n",
       "518926  DR8-MBCG0-SI2217.CSV     DR8   MBCG0      SI2217   \n",
       "524746    DR8-MKRG0-SX31.CSV     DR8   MKRG0        SX31   \n",
       "525211  DR8-MMEA0-SI2018.CSV     DR8   MMEA0      SI2018   \n",
       "530312     DR8-MRLK0-SA2.CSV     DR8   MRLK0         SA2   \n",
       "\n",
       "                                                 sentence  previous_packet  \\\n",
       "3542    Personal predispositions tend to blunt the ear...               39   \n",
       "5220           Reading in poor light gives you eyestrain.               33   \n",
       "6012                                That's your headache.               42   \n",
       "6559    The toddler found a clamshell near the camp site.               42   \n",
       "8242         Don't ask me to carry an oily rag like that.               30   \n",
       "...                                                   ...              ...   \n",
       "515430  She had your dark suit in greasy wash water al...               30   \n",
       "518926          He'd not only told me so, he'd proved it.               63   \n",
       "524746                     A good attitude is unbeatable.               38   \n",
       "525211                               They were shattered.               27   \n",
       "530312       Don't ask me to carry an oily rag like that.               43   \n",
       "\n",
       "        next_packet  packet_size prev_curr next_curr packet_surrounding  \\\n",
       "3542             39           39  (39, 39)  (39, 39)       (39, 39, 39)   \n",
       "5220             33           33  (33, 33)  (33, 33)       (33, 33, 33)   \n",
       "6012             42           42  (42, 42)  (42, 42)       (42, 42, 42)   \n",
       "6559             42           42  (42, 42)  (42, 42)       (42, 42, 42)   \n",
       "8242             30           30  (30, 30)  (30, 30)       (30, 30, 30)   \n",
       "...             ...          ...       ...       ...                ...   \n",
       "515430           30           30  (30, 30)  (30, 30)       (30, 30, 30)   \n",
       "518926           63           63  (63, 63)  (63, 63)       (63, 63, 63)   \n",
       "524746           38           38  (38, 38)  (38, 38)       (38, 38, 38)   \n",
       "525211           27           27  (27, 27)  (27, 27)       (27, 27, 27)   \n",
       "530312           43           43  (43, 43)  (43, 43)       (43, 43, 43)   \n",
       "\n",
       "       phonemes    words  \n",
       "3542                 (,)  \n",
       "5220                 (,)  \n",
       "6012                 (,)  \n",
       "6559                 (,)  \n",
       "8242                 (,)  \n",
       "...         ...      ...  \n",
       "515430               (,)  \n",
       "518926        i  (he'd,)  \n",
       "524746               (,)  \n",
       "525211               (,)  \n",
       "530312               (,)  \n",
       "\n",
       "[100 rows x 13 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_phonemes_train.loc[~prev_not_same.values]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is going to only remove around 100 values, which is literally nothing => this won't help us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_phonemes_train = skype_data_train.loc[skype_data_train.phonemes.apply(len) == 1].reset_index(drop=True)\n",
    "single_phonemes_test = skype_data_test.loc[skype_data_test.phonemes.apply(len) == 1].reset_index(drop=True)\n",
    "\n",
    "single_phonemes_test['phonemes'] = single_phonemes_test[\"phonemes\"].apply(convert_phoneme)\n",
    "single_phonemes_train['phonemes'] = single_phonemes_train[\"phonemes\"].apply(convert_phoneme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xkadlec6/.local/lib/python3.6/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "train_set, train_labels = get_labels(single_phonemes_train, label=['phonemes'])\n",
    "test_set, test_labels = get_labels(single_phonemes_test, label=['phonemes'])\n",
    "\n",
    "train_labels, test_labels, encoder = prepare_labels(train_labels, test_labels, label=['phonemes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(533705, 3)\n",
      "(533705,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_set.shape)\n",
    "print(train_labels.shape)\n",
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', '', '', ..., '', '', ''], dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.inverse_transform(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(533705, 43)\n"
     ]
    }
   ],
   "source": [
    "train_labels = to_categorical(train_labels, num_classes=total_unique_phonemes)\n",
    "test_labels = to_categorical(test_labels, num_classes=total_unique_phonemes)\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 43)                11051     \n",
      "=================================================================\n",
      "Total params: 144,427\n",
      "Trainable params: 144,427\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(units=512, activation='relu', input_dim=3*1))  # first hidden layer\n",
    "model.add(Dense(units=256, activation='relu'))  # second hidden layer\n",
    "# model.add(Dense(units=128, activation='relu'))  # third hidden layer\n",
    "model.add(Dense(units=total_unique_phonemes, activation='softmax'))  # output layer\n",
    "# model.add(Dense(units=128))  # output layer\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "2085/2085 [==============================] - 11s 5ms/step - loss: 3.1741 - accuracy: 0.2093\n",
      "Epoch 2/16\n",
      "2085/2085 [==============================] - 10s 5ms/step - loss: 2.8044 - accuracy: 0.2495\n",
      "Epoch 3/16\n",
      "2085/2085 [==============================] - 10s 5ms/step - loss: 2.7909 - accuracy: 0.2511\n",
      "Epoch 4/16\n",
      "2085/2085 [==============================] - 10s 5ms/step - loss: 2.7824 - accuracy: 0.2521\n",
      "Epoch 5/16\n",
      "2085/2085 [==============================] - 10s 5ms/step - loss: 2.7732 - accuracy: 0.2546\n",
      "Epoch 6/16\n",
      "2085/2085 [==============================] - 10s 5ms/step - loss: 2.7724 - accuracy: 0.2539\n",
      "Epoch 7/16\n",
      "2085/2085 [==============================] - 10s 5ms/step - loss: 2.7660 - accuracy: 0.2564\n",
      "Epoch 8/16\n",
      "2085/2085 [==============================] - 9s 4ms/step - loss: 2.7656 - accuracy: 0.2568\n",
      "Epoch 9/16\n",
      "2085/2085 [==============================] - 10s 5ms/step - loss: 2.7639 - accuracy: 0.2559\n",
      "Epoch 10/16\n",
      "2085/2085 [==============================] - 10s 5ms/step - loss: 2.7617 - accuracy: 0.2564\n",
      "Epoch 11/16\n",
      "2085/2085 [==============================] - 10s 5ms/step - loss: 2.7590 - accuracy: 0.2573\n",
      "Epoch 12/16\n",
      "2085/2085 [==============================] - 10s 5ms/step - loss: 2.7613 - accuracy: 0.2563\n",
      "Epoch 13/16\n",
      "2085/2085 [==============================] - 10s 5ms/step - loss: 2.7627 - accuracy: 0.2571\n",
      "Epoch 14/16\n",
      "2085/2085 [==============================] - 10s 5ms/step - loss: 2.7591 - accuracy: 0.2574\n",
      "Epoch 15/16\n",
      "2085/2085 [==============================] - 10s 5ms/step - loss: 2.7552 - accuracy: 0.2584\n",
      "Epoch 16/16\n",
      "2085/2085 [==============================] - 10s 5ms/step - loss: 2.7600 - accuracy: 0.2565\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc1f8644198>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_set, train_labels, epochs=16, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6113/6113 [==============================] - 9s 1ms/step - loss: 2.7819 - accuracy: 0.2516\n",
      "test loss, test acc: [2.7818515300750732, 0.251639723777771]\n"
     ]
    }
   ],
   "source": [
    "print(\"test loss, test acc:\", model.evaluate(test_set, test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Looking into predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0000000e+00 1.5664994e-18 5.1657892e-18 3.4360964e-13 7.2738590e-12\n",
      " 8.2338135e-16 1.3029220e-17 1.8735704e-15 7.4111111e-13 1.3470942e-17\n",
      " 5.6108193e-16 4.0928293e-16 1.1059671e-10 1.0719312e-15 2.2022715e-16\n",
      " 2.3376375e-14 9.0254072e-21 5.6870753e-10 3.0952113e-15 1.3630438e-09\n",
      " 2.9085349e-16 2.5611391e-16 1.4442367e-14 3.0740780e-15 8.8032828e-16\n",
      " 5.3163752e-15 2.8342186e-17 7.0128281e-18 1.8402124e-18 7.9902635e-16\n",
      " 3.0420285e-18 2.8845040e-15 4.6031349e-22 9.2929475e-15 2.4367294e-28\n",
      " 5.5194319e-15 4.5049643e-16 6.2950621e-19 3.0640642e-25 6.9720208e-17\n",
      " 2.4212579e-26 3.7422556e-12 5.0861529e-12]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(train_set)\n",
    "print(predictions[0])\n",
    "np.argmax(predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', '', '', ..., '', '', ''], dtype=object)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_array = [np.argmax(x) for x in predictions]\n",
    "encoder.inverse_transform(predictions_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phonemes</th>\n",
       "      <th>predictions</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533700</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533701</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533702</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533703</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533704</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>533705 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       phonemes predictions words\n",
       "0                             (,)\n",
       "1                             (,)\n",
       "2                             (,)\n",
       "3                             (,)\n",
       "4                             (,)\n",
       "...         ...         ...   ...\n",
       "533700                        (,)\n",
       "533701                        (,)\n",
       "533702                        (,)\n",
       "533703                        (,)\n",
       "533704                        (,)\n",
       "\n",
       "[533705 rows x 3 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison = single_phonemes_train.assign(predictions=encoder.inverse_transform(predictions_array))\n",
    "compar = comparison[[\"phonemes\", \"predictions\", \"words\"]]\n",
    "compar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Now showing values for phoneme: \n",
      "Accuraccy: 0.159762415566652\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "     85266\n",
       "s     1421\n",
       "n     1313\n",
       "ɪ     1172\n",
       "i     1076\n",
       "k      908\n",
       "æ      904\n",
       "t      867\n",
       "d      246\n",
       "ɹ       34\n",
       "ʔ       18\n",
       "w       10\n",
       "θ        7\n",
       "p        2\n",
       "Name: predictions, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Now showing values for phoneme: ʃ\n",
      "Accuraccy: 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "s    8794\n",
       "ɪ     954\n",
       "z     336\n",
       "k     149\n",
       "ɹ     123\n",
       "i      93\n",
       "æ      81\n",
       "n      41\n",
       "t      28\n",
       "ɔ      20\n",
       "        9\n",
       "ɦ       3\n",
       "d       1\n",
       "ʔ       1\n",
       "l       1\n",
       "Name: predictions, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Now showing values for phoneme: ɪ\n",
      "Accuraccy: 0.01539989319942665\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "s     12167\n",
       "ɪ      8219\n",
       "i      2256\n",
       "æ      1866\n",
       "ɹ      1135\n",
       "        738\n",
       "n       680\n",
       "z       452\n",
       "k       372\n",
       "ɔ       147\n",
       "t        82\n",
       "d        50\n",
       "ɦ        45\n",
       "w        19\n",
       "ʔ        13\n",
       "θ         3\n",
       "l         2\n",
       "dʒ        1\n",
       "Name: predictions, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Now showing values for phoneme: ɦ\n",
      "Accuraccy: 0.00018362203839199557\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "s    1240\n",
       "z     406\n",
       "ɪ     331\n",
       "ɹ     311\n",
       "ɔ     108\n",
       "ɦ      98\n",
       "æ      91\n",
       "i      82\n",
       "       41\n",
       "k      18\n",
       "n      14\n",
       "d       2\n",
       "t       2\n",
       "w       1\n",
       "Name: predictions, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Now showing values for phoneme: ɛ\n",
      "Accuraccy: 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "s     6721\n",
       "ɪ     3529\n",
       "i     1098\n",
       "æ      890\n",
       "ɹ      484\n",
       "       352\n",
       "z      330\n",
       "n      241\n",
       "k      117\n",
       "ɔ       62\n",
       "t       38\n",
       "d       20\n",
       "ɦ        8\n",
       "w        7\n",
       "ʔ        5\n",
       "l        3\n",
       "θ        3\n",
       "dʒ       1\n",
       "f        1\n",
       "Name: predictions, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Now showing values for phoneme: dʒ\n",
      "Accuraccy: 1.8736942693060773e-06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "s     1110\n",
       "ɪ      365\n",
       "k      356\n",
       "ɹ      130\n",
       "t      125\n",
       "z       92\n",
       "æ       24\n",
       "        24\n",
       "i       13\n",
       "ɔ       12\n",
       "w        8\n",
       "n        5\n",
       "ɦ        5\n",
       "θ        3\n",
       "ʔ        3\n",
       "dʒ       1\n",
       "Name: predictions, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Now showing values for phoneme: d\n",
      "Accuraccy: 0.0012141538865103382\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "     4672\n",
       "k    1480\n",
       "t     854\n",
       "d     648\n",
       "ɪ     573\n",
       "n     500\n",
       "s     480\n",
       "i     261\n",
       "æ     121\n",
       "ɹ     111\n",
       "ʔ      34\n",
       "ɔ      16\n",
       "θ      14\n",
       "z       9\n",
       "w       7\n",
       "ɦ       4\n",
       "p       1\n",
       "Name: predictions, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Now showing values for phoneme: ʌ\n",
      "Accuraccy: 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "s    3789\n",
       "ɪ    2048\n",
       "i     533\n",
       "æ     476\n",
       "ɹ     355\n",
       "z     283\n",
       "      133\n",
       "n      93\n",
       "k      83\n",
       "ɔ      59\n",
       "ɦ      20\n",
       "t      15\n",
       "d      12\n",
       "w       5\n",
       "ʔ       3\n",
       "θ       2\n",
       "Name: predictions, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Now showing values for phoneme: k\n",
      "Accuraccy: 0.007352376312757048\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "      7327\n",
       "k     3924\n",
       "s     2469\n",
       "t     2147\n",
       "ɪ     1491\n",
       "æ      448\n",
       "n      429\n",
       "i      379\n",
       "d      350\n",
       "ɹ      176\n",
       "ʔ       38\n",
       "w       25\n",
       "p       15\n",
       "θ       13\n",
       "z        5\n",
       "ɔ        4\n",
       "l        2\n",
       "ɦ        1\n",
       "dʒ       1\n",
       "Name: predictions, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Now showing values for phoneme: s\n",
      "Accuraccy: 0.0503143122136761\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "s    26853\n",
       "ɪ     4498\n",
       "z      899\n",
       "æ      607\n",
       "ɹ      509\n",
       "k      417\n",
       "i      415\n",
       "n      114\n",
       "t       81\n",
       "ɔ       69\n",
       "        55\n",
       "w        6\n",
       "θ        4\n",
       "ɦ        3\n",
       "ʔ        3\n",
       "d        2\n",
       "Name: predictions, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Now showing values for phoneme: u\n",
      "Accuraccy: 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "s    3479\n",
       "ɪ    2684\n",
       "i    1362\n",
       "æ    1258\n",
       "     1010\n",
       "n     396\n",
       "ɹ     325\n",
       "k      99\n",
       "z      54\n",
       "ɔ      19\n",
       "d      17\n",
       "w      10\n",
       "ɦ       7\n",
       "ʔ       6\n",
       "t       5\n",
       "l       5\n",
       "θ       3\n",
       "f       1\n",
       "Name: predictions, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Now showing values for phoneme: ʔ\n",
      "Accuraccy: 0.00010117949054252818\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "     2408\n",
       "s    1151\n",
       "ɪ    1113\n",
       "k     882\n",
       "i     562\n",
       "n     512\n",
       "æ     463\n",
       "t     380\n",
       "d     237\n",
       "ɹ     217\n",
       "ʔ      54\n",
       "z      31\n",
       "w      22\n",
       "θ      20\n",
       "ɔ      13\n",
       "ɦ       4\n",
       "p       3\n",
       "f       1\n",
       "Name: predictions, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Now showing values for phoneme: n\n",
      "Accuraccy: 0.0032789649712856354\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "      3996\n",
       "ɪ     3685\n",
       "s     3277\n",
       "i     2340\n",
       "n     1750\n",
       "æ     1293\n",
       "k      374\n",
       "ɹ      277\n",
       "d      264\n",
       "t       55\n",
       "w       33\n",
       "z       17\n",
       "ʔ       12\n",
       "θ        6\n",
       "ɔ        6\n",
       "ɦ        1\n",
       "dʒ       1\n",
       "f        1\n",
       "Name: predictions, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Now showing values for phoneme: ɹ\n",
      "Accuraccy: 0.0028517626778838496\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "s     5228\n",
       "ɪ     2761\n",
       "ɹ     1522\n",
       "æ     1305\n",
       "i      831\n",
       "       587\n",
       "z      270\n",
       "k      268\n",
       "n      218\n",
       "ɔ       74\n",
       "ɦ       40\n",
       "w       35\n",
       "t       24\n",
       "d       13\n",
       "ʔ        7\n",
       "θ        5\n",
       "l        3\n",
       "dʒ       1\n",
       "Name: predictions, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Now showing values for phoneme: w\n",
      "Accuraccy: 9.743210200391603e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "s    2077\n",
       "ɪ    1307\n",
       "æ     881\n",
       "ɹ     839\n",
       "      682\n",
       "i     651\n",
       "k     411\n",
       "n     174\n",
       "z      84\n",
       "w      52\n",
       "ɔ      31\n",
       "t      29\n",
       "d      14\n",
       "ʔ      13\n",
       "ɦ      10\n",
       "θ       6\n",
       "l       1\n",
       "Name: predictions, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Now showing values for phoneme: ɔ\n",
      "Accuraccy: 0.0002323380893939536\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "s     7538\n",
       "ɪ     3341\n",
       "æ     1152\n",
       "i     1071\n",
       "ɹ      767\n",
       "       429\n",
       "z      393\n",
       "n      218\n",
       "k      124\n",
       "ɔ      124\n",
       "ɦ       37\n",
       "t       17\n",
       "w       10\n",
       "d        6\n",
       "θ        3\n",
       "ʔ        1\n",
       "l        1\n",
       "dʒ       1\n",
       "Name: predictions, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Now showing values for phoneme: ɚ\n",
      "Accuraccy: 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "s    4364\n",
       "ɪ    2692\n",
       "æ    1054\n",
       "i     941\n",
       "ɹ     420\n",
       "      414\n",
       "n     260\n",
       "k      98\n",
       "z      90\n",
       "ɔ      42\n",
       "d       9\n",
       "ɦ       7\n",
       "t       6\n",
       "ʔ       3\n",
       "w       2\n",
       "Name: predictions, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Now showing values for phoneme: l\n",
      "Accuraccy: 7.494777077224309e-06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "s    6177\n",
       "ɪ    3800\n",
       "æ    1272\n",
       "i    1246\n",
       "ɹ    1096\n",
       "      426\n",
       "n     290\n",
       "k     214\n",
       "z     192\n",
       "ɔ      88\n",
       "ɦ      25\n",
       "d      20\n",
       "t      20\n",
       "w      12\n",
       "ʔ       6\n",
       "l       4\n",
       "Name: predictions, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Now showing values for phoneme: j\n",
      "Accuraccy: 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "s    1412\n",
       "ɪ     919\n",
       "æ     463\n",
       "i     401\n",
       "      271\n",
       "ɹ     156\n",
       "n     145\n",
       "k     112\n",
       "z      31\n",
       "ɔ      16\n",
       "t      15\n",
       "d      13\n",
       "w       6\n",
       "ɦ       5\n",
       "θ       3\n",
       "l       1\n",
       "Name: predictions, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Now showing values for phoneme: ʊ\n",
      "Accuraccy: 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "s    712\n",
       "ɪ    411\n",
       "i    114\n",
       "æ     81\n",
       "ɹ     69\n",
       "z     48\n",
       "      23\n",
       "n     19\n",
       "k     10\n",
       "ɔ      7\n",
       "t      4\n",
       "ɦ      3\n",
       "f      1\n",
       "d      1\n",
       "w      1\n",
       "Name: predictions, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Now showing values for phoneme: æ\n",
      "Accuraccy: 0.004480002997910831\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "s    10647\n",
       "ɪ     6157\n",
       "æ     2391\n",
       "i     2376\n",
       "      1371\n",
       "ɹ      943\n",
       "n      645\n",
       "z      500\n",
       "k      279\n",
       "ɔ      106\n",
       "d       43\n",
       "ɦ       31\n",
       "t       30\n",
       "w       26\n",
       "ʔ       10\n",
       "l        2\n",
       "Name: predictions, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Now showing values for phoneme: ɔɪ\n",
      "Accuraccy: 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "s    2614\n",
       "ɪ     959\n",
       "ɹ     348\n",
       "æ     247\n",
       "i     239\n",
       "z     181\n",
       "ɔ      66\n",
       "       44\n",
       "n      43\n",
       "k      36\n",
       "ɦ      21\n",
       "t      15\n",
       "w       3\n",
       "d       1\n",
       "Name: predictions, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Now showing values for phoneme: ə\n",
      "Accuraccy: 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "s    2294\n",
       "ɪ    1593\n",
       "æ     280\n",
       "i     237\n",
       "ɹ     235\n",
       "z     108\n",
       "k      99\n",
       "       79\n",
       "n      73\n",
       "ɔ      30\n",
       "t      24\n",
       "ɦ      16\n",
       "d       9\n",
       "w       4\n",
       "ʔ       4\n",
       "l       1\n",
       "Name: predictions, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Now showing values for phoneme: g\n",
      "Accuraccy: 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "     1808\n",
       "k     508\n",
       "n     228\n",
       "t     223\n",
       "d     174\n",
       "i     113\n",
       "ɪ     108\n",
       "s      56\n",
       "æ      32\n",
       "ʔ       8\n",
       "ɹ       7\n",
       "p       2\n",
       "θ       2\n",
       "Name: predictions, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Now showing values for phoneme: θ\n",
      "Accuraccy: 4.309496819403978e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "     1384\n",
       "s     987\n",
       "ɪ     714\n",
       "k     691\n",
       "i     347\n",
       "n     337\n",
       "æ     237\n",
       "t     184\n",
       "d     140\n",
       "ɹ     111\n",
       "w      38\n",
       "θ      23\n",
       "ʔ      17\n",
       "z      15\n",
       "ɔ       7\n",
       "ɦ       1\n",
       "f       1\n",
       "l       1\n",
       "Name: predictions, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Now showing values for phoneme: t\n",
      "Accuraccy: 0.004579308794184053\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "      7357\n",
       "k     2583\n",
       "t     2444\n",
       "s     2401\n",
       "ɪ     1288\n",
       "n      403\n",
       "d      374\n",
       "i      277\n",
       "æ      237\n",
       "ɹ      140\n",
       "ʔ       30\n",
       "p       10\n",
       "θ        8\n",
       "w        7\n",
       "z        5\n",
       "ɔ        3\n",
       "dʒ       2\n",
       "ɦ        1\n",
       "Name: predictions, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Now showing values for phoneme: i\n",
      "Accuraccy: 0.005319418030559953\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "s    9319\n",
       "ɪ    6272\n",
       "i    2839\n",
       "æ    2077\n",
       "     1411\n",
       "n     843\n",
       "ɹ     789\n",
       "z     423\n",
       "k     223\n",
       "ɔ      62\n",
       "d      51\n",
       "w      32\n",
       "ɦ      31\n",
       "t      24\n",
       "θ       6\n",
       "ʔ       5\n",
       "f       1\n",
       "l       1\n",
       "Name: predictions, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Now showing values for phoneme: v\n",
      "Accuraccy: 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "s    860\n",
       "     855\n",
       "ɪ    705\n",
       "i    472\n",
       "n    340\n",
       "æ    244\n",
       "ɹ    154\n",
       "k    133\n",
       "d     75\n",
       "z     58\n",
       "t     22\n",
       "ɔ     20\n",
       "w     17\n",
       "ʔ     10\n",
       "ɦ      9\n",
       "θ      8\n",
       "l      1\n",
       "Name: predictions, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Now showing values for phoneme: f\n",
      "Accuraccy: 3.7473885386121546e-06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "s    4021\n",
       "ɪ    1698\n",
       "      983\n",
       "i     816\n",
       "æ     675\n",
       "n     400\n",
       "k     255\n",
       "ɹ     149\n",
       "z      64\n",
       "d      43\n",
       "t      29\n",
       "w      12\n",
       "ɔ      10\n",
       "ʔ       2\n",
       "f       2\n",
       "ɦ       1\n",
       "θ       1\n",
       "Name: predictions, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Now showing values for phoneme: oʊ\n",
      "Accuraccy: 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "s     5401\n",
       "ɪ     2662\n",
       "æ      960\n",
       "i      922\n",
       "ɹ      511\n",
       "       325\n",
       "z      196\n",
       "n      141\n",
       "k       75\n",
       "ɔ       46\n",
       "t       15\n",
       "ɦ       15\n",
       "d        7\n",
       "w        5\n",
       "l        1\n",
       "dʒ       1\n",
       "θ        1\n",
       "Name: predictions, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Now showing values for phoneme: h\n",
      "Accuraccy: 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "s    993\n",
       "ɪ    355\n",
       "     196\n",
       "i    149\n",
       "æ    148\n",
       "k    100\n",
       "ɹ     84\n",
       "n     50\n",
       "z     32\n",
       "ɔ      9\n",
       "t      5\n",
       "d      4\n",
       "w      4\n",
       "ɦ      2\n",
       "Name: predictions, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Now showing values for phoneme: tʃ\n",
      "Accuraccy: 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "s    1764\n",
       "ɪ     404\n",
       "k     253\n",
       "t     102\n",
       "ɹ      73\n",
       "æ      29\n",
       "       22\n",
       "i      21\n",
       "z      11\n",
       "n       6\n",
       "w       3\n",
       "ɔ       3\n",
       "ɦ       2\n",
       "θ       2\n",
       "ʔ       1\n",
       "Name: predictions, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Now showing values for phoneme: b\n",
      "Accuraccy: 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "     2860\n",
       "k     646\n",
       "t     317\n",
       "d     136\n",
       "n     107\n",
       "ɪ      58\n",
       "i      42\n",
       "s      35\n",
       "ʔ      11\n",
       "æ       4\n",
       "p       4\n",
       "ɹ       4\n",
       "z       1\n",
       "θ       1\n",
       "Name: predictions, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Now showing values for phoneme: ɑ\n",
      "Accuraccy: 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "s     7820\n",
       "ɪ     3539\n",
       "i     1091\n",
       "æ     1057\n",
       "ɹ      768\n",
       "z      447\n",
       "       392\n",
       "n      220\n",
       "ɔ      114\n",
       "k      107\n",
       "ɦ       33\n",
       "t       18\n",
       "d       10\n",
       "w       10\n",
       "dʒ       1\n",
       "Name: predictions, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Now showing values for phoneme: m\n",
      "Accuraccy: 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "      1790\n",
       "ɪ     1643\n",
       "s     1616\n",
       "i     1088\n",
       "æ      750\n",
       "n      719\n",
       "k      374\n",
       "ɹ      181\n",
       "d       91\n",
       "t       37\n",
       "w       21\n",
       "ʔ       16\n",
       "z        5\n",
       "θ        4\n",
       "ɔ        2\n",
       "ɦ        2\n",
       "dʒ       1\n",
       "Name: predictions, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Now showing values for phoneme: aɪ\n",
      "Accuraccy: 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "s    7570\n",
       "ɪ    3221\n",
       "æ    1111\n",
       "i     974\n",
       "ɹ     521\n",
       "      493\n",
       "z     403\n",
       "n     204\n",
       "ɔ     128\n",
       "k      85\n",
       "ɦ      34\n",
       "t      16\n",
       "d      13\n",
       "w       5\n",
       "ʔ       1\n",
       "l       1\n",
       "Name: predictions, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Now showing values for phoneme: eɪ\n",
      "Accuraccy: 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "s    5301\n",
       "ɪ    2898\n",
       "i    1199\n",
       "æ    1089\n",
       "      620\n",
       "ɹ     310\n",
       "n     302\n",
       "z     258\n",
       "k      88\n",
       "ɔ      37\n",
       "ɦ      17\n",
       "t      16\n",
       "d      15\n",
       "w       5\n",
       "l       3\n",
       "ʔ       1\n",
       "f       1\n",
       "Name: predictions, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Now showing values for phoneme: p\n",
      "Accuraccy: 2.4358025500979007e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "     4865\n",
       "k    1638\n",
       "t    1178\n",
       "s     660\n",
       "ɪ     539\n",
       "æ     219\n",
       "i     164\n",
       "n     134\n",
       "ɹ     131\n",
       "d      87\n",
       "ʔ      18\n",
       "w      16\n",
       "p      13\n",
       "θ      11\n",
       "z       7\n",
       "ɦ       3\n",
       "ɔ       2\n",
       "l       1\n",
       "Name: predictions, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Now showing values for phoneme: aʊ\n",
      "Accuraccy: 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "s    2426\n",
       "ɪ    1128\n",
       "æ     511\n",
       "i     446\n",
       "      216\n",
       "ɹ     142\n",
       "n     100\n",
       "z      88\n",
       "k      42\n",
       "d       9\n",
       "ɔ       9\n",
       "t       3\n",
       "w       3\n",
       "ɦ       1\n",
       "Name: predictions, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Now showing values for phoneme: ɝ\n",
      "Accuraccy: 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "s    4102\n",
       "ɪ    2493\n",
       "æ    1123\n",
       "i     978\n",
       "ɹ     441\n",
       "      354\n",
       "n     186\n",
       "z     104\n",
       "k      74\n",
       "ɔ      35\n",
       "t      13\n",
       "d       9\n",
       "w       9\n",
       "ɦ       8\n",
       "ʔ       1\n",
       "l       1\n",
       "Name: predictions, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Now showing values for phoneme: z\n",
      "Accuraccy: 0.002877994397654135\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "s    7426\n",
       "ɪ    1704\n",
       "z    1536\n",
       "ɹ     369\n",
       "i     205\n",
       "k     172\n",
       "æ     153\n",
       "ɦ     128\n",
       "ɔ      74\n",
       "n      69\n",
       "       32\n",
       "t      22\n",
       "d       9\n",
       "w       4\n",
       "ʔ       3\n",
       "θ       2\n",
       "Name: predictions, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Now showing values for phoneme: ɡ\n",
      "Accuraccy: 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "k     393\n",
       "      205\n",
       "æ     104\n",
       "ɪ      88\n",
       "t      71\n",
       "i      63\n",
       "s      62\n",
       "ɹ      36\n",
       "n      27\n",
       "w      13\n",
       "d       8\n",
       "ʔ       8\n",
       "θ       4\n",
       "z       1\n",
       "dʒ      1\n",
       "Name: predictions, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Now showing values for phoneme: ʒ\n",
      "Accuraccy: 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "s    285\n",
       "z     88\n",
       "ɪ     44\n",
       "ɹ     12\n",
       "ɦ     10\n",
       "æ      8\n",
       "ɔ      5\n",
       "i      4\n",
       "k      2\n",
       "n      1\n",
       "d      1\n",
       "       1\n",
       "Name: predictions, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for phoneme in pd.unique(compar.phonemes):\n",
    "    tmp = compar.loc[comparison.phonemes == phoneme]\n",
    "    print(\"\\n\\nNow showing values for phoneme:\", phoneme)\n",
    "    print(\"Accuraccy:\", len(tmp.loc[tmp.phonemes == tmp.predictions])/len(compar))\n",
    "    display(tmp.predictions.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, we can see, that our model works only on paper, because if we focus only on \"important\" predictions, the accuraccies are really low and almost nothing saying."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding scaler (as values should be in range (-1,1) or here (0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>previous_packet</th>\n",
       "      <th>packet_size</th>\n",
       "      <th>next_packet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.343137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.271739</td>\n",
       "      <td>0.421569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.343137</td>\n",
       "      <td>0.358696</td>\n",
       "      <td>0.254902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.421569</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.294118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.254902</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.303922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195608</th>\n",
       "      <td>0.392157</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>0.421569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195609</th>\n",
       "      <td>0.450980</td>\n",
       "      <td>0.358696</td>\n",
       "      <td>0.401961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195610</th>\n",
       "      <td>0.421569</td>\n",
       "      <td>0.336957</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195611</th>\n",
       "      <td>0.401961</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.323529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195612</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195613 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        previous_packet  packet_size  next_packet\n",
       "0              0.000000     0.217391     0.343137\n",
       "1              0.294118     0.271739     0.421569\n",
       "2              0.343137     0.358696     0.254902\n",
       "3              0.421569     0.173913     0.294118\n",
       "4              0.254902     0.217391     0.303922\n",
       "...                 ...          ...          ...\n",
       "195608         0.392157     0.391304     0.421569\n",
       "195609         0.450980     0.358696     0.401961\n",
       "195610         0.421569     0.336957     0.333333\n",
       "195611         0.401961     0.260870     0.323529\n",
       "195612         0.333333     0.250000     0.000000\n",
       "\n",
       "[195613 rows x 3 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "train_set[[\"previous_packet\", \"next_packet\", \"packet_size\"]] = scaler.fit_transform(train_set[[\"previous_packet\", \"next_packet\", \"packet_size\"]])\n",
    "test_set[[\"previous_packet\", \"next_packet\", \"packet_size\"]] = scaler.transform(test_set[[\"previous_packet\", \"next_packet\", \"packet_size\"]])\n",
    "test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 43)                11051     \n",
      "=================================================================\n",
      "Total params: 144,427\n",
      "Trainable params: 144,427\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(units=512, activation='relu', input_dim=3*1))  # first hidden layer\n",
    "model.add(Dense(units=256, activation='relu'))  # second hidden layer\n",
    "# model.add(Dense(units=128, activation='relu'))  # third hidden layer\n",
    "model.add(Dense(units=total_unique_phonemes, activation='softmax'))  # output layer\n",
    "# model.add(Dense(units=128))  # output layer\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "2085/2085 [==============================] - 10s 5ms/step - loss: 2.9381 - accuracy: 0.2316\n",
      "Epoch 2/16\n",
      "2085/2085 [==============================] - 10s 5ms/step - loss: 2.7855 - accuracy: 0.2526\n",
      "Epoch 3/16\n",
      "2085/2085 [==============================] - 10s 5ms/step - loss: 2.7694 - accuracy: 0.2555\n",
      "Epoch 4/16\n",
      "2085/2085 [==============================] - 10s 5ms/step - loss: 2.7644 - accuracy: 0.2569\n",
      "Epoch 5/16\n",
      "2085/2085 [==============================] - 10s 5ms/step - loss: 2.7604 - accuracy: 0.2565\n",
      "Epoch 6/16\n",
      "2085/2085 [==============================] - 10s 5ms/step - loss: 2.7570 - accuracy: 0.2566\n",
      "Epoch 7/16\n",
      "2085/2085 [==============================] - 10s 5ms/step - loss: 2.7527 - accuracy: 0.2582\n",
      "Epoch 8/16\n",
      "2085/2085 [==============================] - 10s 5ms/step - loss: 2.7528 - accuracy: 0.2582\n",
      "Epoch 9/16\n",
      "2085/2085 [==============================] - 10s 5ms/step - loss: 2.7501 - accuracy: 0.2591\n",
      "Epoch 10/16\n",
      "2085/2085 [==============================] - 10s 5ms/step - loss: 2.7490 - accuracy: 0.2592\n",
      "Epoch 11/16\n",
      "2085/2085 [==============================] - 10s 5ms/step - loss: 2.7505 - accuracy: 0.2581\n",
      "Epoch 12/16\n",
      "2085/2085 [==============================] - 9s 5ms/step - loss: 2.7477 - accuracy: 0.2588\n",
      "Epoch 13/16\n",
      "2085/2085 [==============================] - 9s 4ms/step - loss: 2.7489 - accuracy: 0.2588\n",
      "Epoch 14/16\n",
      "2085/2085 [==============================] - 9s 4ms/step - loss: 2.7485 - accuracy: 0.2596\n",
      "Epoch 15/16\n",
      "2085/2085 [==============================] - 9s 4ms/step - loss: 2.7475 - accuracy: 0.2595\n",
      "Epoch 16/16\n",
      "2085/2085 [==============================] - 9s 4ms/step - loss: 2.7478 - accuracy: 0.2593\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7efd2c0bea90>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_set, train_labels, epochs=16, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6113/6113 [==============================] - 9s 1ms/step - loss: 2.7797 - accuracy: 0.2519\n",
      "test loss, test acc: [2.7797038555145264, 0.25186464190483093]\n"
     ]
    }
   ],
   "source": [
    "print(\"test loss, test acc:\", model.evaluate(test_set, test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_lstm = Sequential()\n",
    "# model_lstm.add(LSTM(256, input_shape = (1, 3)))\n",
    "# model_lstm.add(Dense(units=total_unique_words))\n",
    "# model_lstm.compile(loss='categorical_crossentropy',\n",
    "#               optimizer='adam',\n",
    "#               metrics=['accuracy']\n",
    "#              )\n",
    "\n",
    "# model_lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Embedding\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import SpatialDropout1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 256)               266240    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 43)                11051     \n",
      "=================================================================\n",
      "Total params: 343,083\n",
      "Trainable params: 343,083\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#more elaborate model\n",
    "model_lstm = Sequential()\n",
    "\n",
    "#model_lstm.add(Embedding(input_dim = 3, output_dim = 2, input_length = 86497))\n",
    "#model_lstm.add(SpatialDropout1D(0.3))\n",
    "model_lstm.add(LSTM(256, input_shape = (1, 3), dropout = 0.3, recurrent_dropout = 0.3))\n",
    "model_lstm.add(Dense(256, activation = 'relu'))\n",
    "model_lstm.add(Dropout(0.3))\n",
    "model_lstm.add(Dense(total_unique_phonemes, activation = 'softmax'))\n",
    "\n",
    "model_lstm.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='Adam',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model_lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_phonemes_train = skype_data_train.loc[skype_data_train.phonemes.apply(len) == 1].reset_index(drop=True)\n",
    "single_phonemes_test = skype_data_test.loc[skype_data_test.phonemes.apply(len) == 1].reset_index(drop=True)\n",
    "\n",
    "single_phonemes_test['phonemes'] = single_phonemes_test[\"phonemes\"].apply(convert_phoneme)\n",
    "single_phonemes_train['phonemes'] = single_phonemes_train[\"phonemes\"].apply(convert_phoneme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xkadlec6/.local/lib/python3.6/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "train_set, train_labels = get_labels(single_phonemes_train, label=['phonemes'])\n",
    "test_set, test_labels = get_labels(single_phonemes_test, label=['phonemes'])\n",
    "\n",
    "train_labels, test_labels, _ = prepare_labels(train_labels, test_labels, label=['phonemes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(533705, 43)\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "train_labels = to_categorical(train_labels, num_classes=total_unique_phonemes)\n",
    "test_labels = to_categorical(test_labels, num_classes=total_unique_phonemes)\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0, 32, 32])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshaped_values = train_set.values.reshape(-1, 1, 3)\n",
    "reshaped_values[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "4170/4170 [==============================] - 28s 6ms/step - loss: 3.0098 - accuracy: 0.2207\n",
      "Epoch 2/16\n",
      "4170/4170 [==============================] - 24s 6ms/step - loss: 2.8634 - accuracy: 0.2403\n",
      "Epoch 3/16\n",
      "4170/4170 [==============================] - 24s 6ms/step - loss: 2.8541 - accuracy: 0.2405\n",
      "Epoch 4/16\n",
      "4170/4170 [==============================] - 24s 6ms/step - loss: 2.8472 - accuracy: 0.2423\n",
      "Epoch 5/16\n",
      "4170/4170 [==============================] - 24s 6ms/step - loss: 2.8406 - accuracy: 0.2439\n",
      "Epoch 6/16\n",
      "4170/4170 [==============================] - 25s 6ms/step - loss: 2.8352 - accuracy: 0.2448\n",
      "Epoch 7/16\n",
      "4170/4170 [==============================] - 26s 6ms/step - loss: 2.8292 - accuracy: 0.2459\n",
      "Epoch 8/16\n",
      "4170/4170 [==============================] - 28s 7ms/step - loss: 2.8279 - accuracy: 0.2457\n",
      "Epoch 9/16\n",
      "4170/4170 [==============================] - 25s 6ms/step - loss: 2.8281 - accuracy: 0.2463\n",
      "Epoch 10/16\n",
      "4170/4170 [==============================] - 26s 6ms/step - loss: 2.8267 - accuracy: 0.2455\n",
      "Epoch 11/16\n",
      "4170/4170 [==============================] - 24s 6ms/step - loss: 2.8269 - accuracy: 0.2457\n",
      "Epoch 12/16\n",
      "4170/4170 [==============================] - 25s 6ms/step - loss: 2.8262 - accuracy: 0.2461\n",
      "Epoch 13/16\n",
      "4170/4170 [==============================] - 26s 6ms/step - loss: 2.8247 - accuracy: 0.2462\n",
      "Epoch 14/16\n",
      "4170/4170 [==============================] - 25s 6ms/step - loss: 2.8228 - accuracy: 0.2462\n",
      "Epoch 15/16\n",
      "4170/4170 [==============================] - 25s 6ms/step - loss: 2.8201 - accuracy: 0.2473\n",
      "Epoch 16/16\n",
      "4170/4170 [==============================] - 24s 6ms/step - loss: 2.8201 - accuracy: 0.2473\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8ca99835c0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lstm.fit(reshaped_values, train_labels, epochs=16, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6113/6113 [==============================] - 13s 2ms/step - loss: 4.3564 - accuracy: 0.1769\n",
      "test loss, test acc: [4.356447696685791, 0.17691053450107574]\n"
     ]
    }
   ],
   "source": [
    "print(\"test loss, test acc:\", model_lstm.evaluate(test_set.values.reshape(-1, 1, 3), test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>previous_packet</th>\n",
       "      <th>packet_size</th>\n",
       "      <th>next_packet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.343137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.271739</td>\n",
       "      <td>0.421569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.343137</td>\n",
       "      <td>0.358696</td>\n",
       "      <td>0.254902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.421569</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.294118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.254902</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.303922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195608</th>\n",
       "      <td>0.392157</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>0.421569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195609</th>\n",
       "      <td>0.450980</td>\n",
       "      <td>0.358696</td>\n",
       "      <td>0.401961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195610</th>\n",
       "      <td>0.421569</td>\n",
       "      <td>0.336957</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195611</th>\n",
       "      <td>0.401961</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.323529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195612</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195613 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        previous_packet  packet_size  next_packet\n",
       "0              0.000000     0.217391     0.343137\n",
       "1              0.294118     0.271739     0.421569\n",
       "2              0.343137     0.358696     0.254902\n",
       "3              0.421569     0.173913     0.294118\n",
       "4              0.254902     0.217391     0.303922\n",
       "...                 ...          ...          ...\n",
       "195608         0.392157     0.391304     0.421569\n",
       "195609         0.450980     0.358696     0.401961\n",
       "195610         0.421569     0.336957     0.333333\n",
       "195611         0.401961     0.260870     0.323529\n",
       "195612         0.333333     0.250000     0.000000\n",
       "\n",
       "[195613 rows x 3 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "train_set[[\"previous_packet\", \"next_packet\", \"packet_size\"]] = scaler.fit_transform(train_set[[\"previous_packet\", \"next_packet\", \"packet_size\"]])\n",
    "test_set[[\"previous_packet\", \"next_packet\", \"packet_size\"]] = scaler.transform(test_set[[\"previous_packet\", \"next_packet\", \"packet_size\"]])\n",
    "test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (None, 256)               266240    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 43)                11051     \n",
      "=================================================================\n",
      "Total params: 343,083\n",
      "Trainable params: 343,083\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#more elaborate model\n",
    "model_lstm = Sequential()\n",
    "\n",
    "#model_lstm.add(Embedding(input_dim = 3, output_dim = 2, input_length = 86497))\n",
    "#model_lstm.add(SpatialDropout1D(0.3))\n",
    "model_lstm.add(LSTM(256, input_shape = (1, 3), dropout = 0.3, recurrent_dropout = 0.3))\n",
    "model_lstm.add(Dense(256, activation = 'relu'))\n",
    "model_lstm.add(Dropout(0.3))\n",
    "model_lstm.add(Dense(total_unique_phonemes, activation = 'softmax'))\n",
    "\n",
    "model_lstm.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='Adam',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model_lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.23913043, 0.31372549])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshaped_values = train_set.values.reshape(-1, 1, 3)\n",
    "reshaped_values[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "4170/4170 [==============================] - 28s 6ms/step - loss: 3.1329 - accuracy: 0.2100\n",
      "Epoch 2/16\n",
      "4170/4170 [==============================] - 25s 6ms/step - loss: 2.9663 - accuracy: 0.2297\n",
      "Epoch 3/16\n",
      "4170/4170 [==============================] - 27s 6ms/step - loss: 2.9388 - accuracy: 0.2318\n",
      "Epoch 4/16\n",
      "4170/4170 [==============================] - 24s 6ms/step - loss: 2.9156 - accuracy: 0.2343\n",
      "Epoch 5/16\n",
      "4170/4170 [==============================] - 24s 6ms/step - loss: 2.9051 - accuracy: 0.2365\n",
      "Epoch 6/16\n",
      "4170/4170 [==============================] - 24s 6ms/step - loss: 2.8884 - accuracy: 0.2375\n",
      "Epoch 7/16\n",
      "4170/4170 [==============================] - 24s 6ms/step - loss: 2.8732 - accuracy: 0.2402\n",
      "Epoch 8/16\n",
      "4170/4170 [==============================] - 26s 6ms/step - loss: 2.8576 - accuracy: 0.2415\n",
      "Epoch 9/16\n",
      "4170/4170 [==============================] - 24s 6ms/step - loss: 2.8467 - accuracy: 0.2426\n",
      "Epoch 10/16\n",
      "4170/4170 [==============================] - 25s 6ms/step - loss: 2.8349 - accuracy: 0.2444\n",
      "Epoch 11/16\n",
      "4170/4170 [==============================] - 25s 6ms/step - loss: 2.8284 - accuracy: 0.2452\n",
      "Epoch 12/16\n",
      "4170/4170 [==============================] - 27s 7ms/step - loss: 2.8249 - accuracy: 0.2451\n",
      "Epoch 13/16\n",
      "4170/4170 [==============================] - 25s 6ms/step - loss: 2.8216 - accuracy: 0.2458\n",
      "Epoch 14/16\n",
      "4170/4170 [==============================] - 25s 6ms/step - loss: 2.8190 - accuracy: 0.2468\n",
      "Epoch 15/16\n",
      "4170/4170 [==============================] - 25s 6ms/step - loss: 2.8152 - accuracy: 0.2473\n",
      "Epoch 16/16\n",
      "4170/4170 [==============================] - 24s 6ms/step - loss: 2.8131 - accuracy: 0.2471\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8ca9bc4f28>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lstm.fit(reshaped_values, train_labels, epochs=16, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6113/6113 [==============================] - 12s 2ms/step - loss: 4.7506 - accuracy: 0.1772\n",
      "test loss, test acc: [4.750559329986572, 0.17720703780651093]\n"
     ]
    }
   ],
   "source": [
    "print(\"test loss, test acc:\", model_lstm.evaluate(test_set.values.reshape(-1, 1, 3), test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KFold crossvalidation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(output_size):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(units=512, activation='relu', input_dim=3*1))  # first hidden layer\n",
    "    model.add(Dense(units=256, activation='relu'))  # second hidden layer\n",
    "    model.add(Dense(units=output_size, activation='softmax'))  # output layer\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_phonemes_train = skype_data_train.loc[skype_data_train.phonemes.apply(len) == 1].reset_index(drop=True)\n",
    "single_phonemes_test = skype_data_test.loc[skype_data_test.phonemes.apply(len) == 1].reset_index(drop=True)\n",
    "\n",
    "single_phonemes_test['phonemes'] = single_phonemes_test[\"phonemes\"].apply(convert_phoneme)\n",
    "single_phonemes_train['phonemes'] = single_phonemes_train[\"phonemes\"].apply(convert_phoneme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xkadlec6/.local/lib/python3.6/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "train_set, train_labels = get_labels(single_phonemes_train, label=['phonemes'])\n",
    "test_set, test_labels = get_labels(single_phonemes_test, label=['phonemes'])\n",
    "\n",
    "train_labels, test_labels, _ = prepare_labels(train_labels, test_labels, label=['phonemes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "train_set[[\"previous_packet\", \"next_packet\", \"packet_size\"]] = scaler.fit_transform(train_set[[\"previous_packet\", \"next_packet\", \"packet_size\"]])\n",
    "test_set[[\"previous_packet\", \"next_packet\", \"packet_size\"]] = scaler.transform(test_set[[\"previous_packet\", \"next_packet\", \"packet_size\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(533705, 43)\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "train_labels = to_categorical(train_labels, num_classes=total_unique_phonemes)\n",
    "test_labels = to_categorical(test_labels, num_classes=total_unique_phonemes)\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Now validating on dialect: DR1\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_30 (Dense)             (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 43)                11051     \n",
      "=================================================================\n",
      "Total params: 144,427\n",
      "Trainable params: 144,427\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/16\n",
      "1916/1916 [==============================] - 8s 4ms/step - loss: 2.9463 - accuracy: 0.2297\n",
      "Epoch 2/16\n",
      "1916/1916 [==============================] - 8s 4ms/step - loss: 2.7882 - accuracy: 0.2511\n",
      "Epoch 3/16\n",
      "1916/1916 [==============================] - 8s 4ms/step - loss: 2.7710 - accuracy: 0.2559\n",
      "Epoch 4/16\n",
      "1916/1916 [==============================] - 7s 4ms/step - loss: 2.7693 - accuracy: 0.2553\n",
      "Epoch 5/16\n",
      "1916/1916 [==============================] - 7s 4ms/step - loss: 2.7632 - accuracy: 0.2556\n",
      "Epoch 6/16\n",
      "1916/1916 [==============================] - 8s 4ms/step - loss: 2.7604 - accuracy: 0.2557\n",
      "Epoch 7/16\n",
      "1916/1916 [==============================] - 8s 4ms/step - loss: 2.7582 - accuracy: 0.2565\n",
      "Epoch 8/16\n",
      "1916/1916 [==============================] - 8s 4ms/step - loss: 2.7530 - accuracy: 0.2584\n",
      "Epoch 9/16\n",
      "1916/1916 [==============================] - 8s 4ms/step - loss: 2.7522 - accuracy: 0.2576\n",
      "Epoch 10/16\n",
      "1916/1916 [==============================] - 7s 4ms/step - loss: 2.7530 - accuracy: 0.2575\n",
      "Epoch 11/16\n",
      "1916/1916 [==============================] - 7s 4ms/step - loss: 2.7508 - accuracy: 0.2580\n",
      "Epoch 12/16\n",
      "1916/1916 [==============================] - 7s 4ms/step - loss: 2.7515 - accuracy: 0.2580\n",
      "Epoch 13/16\n",
      "1916/1916 [==============================] - 8s 4ms/step - loss: 2.7512 - accuracy: 0.2586\n",
      "Epoch 14/16\n",
      "1916/1916 [==============================] - 7s 4ms/step - loss: 2.7484 - accuracy: 0.2593\n",
      "Epoch 15/16\n",
      "1916/1916 [==============================] - 7s 4ms/step - loss: 2.7474 - accuracy: 0.2583\n",
      "Epoch 16/16\n",
      "1916/1916 [==============================] - 7s 4ms/step - loss: 2.7485 - accuracy: 0.2586\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7efd2c192198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1352/1352 [==============================] - 2s 1ms/step - loss: 2.7424 - accuracy: 0.2659\n",
      "test loss, test acc: [2.742433547973633, 0.2659114599227905]\n",
      "\n",
      "\n",
      "Now validating on dialect: DR2\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_33 (Dense)             (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 43)                11051     \n",
      "=================================================================\n",
      "Total params: 144,427\n",
      "Trainable params: 144,427\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/16\n",
      "1750/1750 [==============================] - 8s 4ms/step - loss: 2.9572 - accuracy: 0.2288\n",
      "Epoch 2/16\n",
      "1750/1750 [==============================] - 7s 4ms/step - loss: 2.7895 - accuracy: 0.2514\n",
      "Epoch 3/16\n",
      "1750/1750 [==============================] - 7s 4ms/step - loss: 2.7759 - accuracy: 0.2549\n",
      "Epoch 4/16\n",
      "1750/1750 [==============================] - 7s 4ms/step - loss: 2.7694 - accuracy: 0.2547\n",
      "Epoch 5/16\n",
      "1750/1750 [==============================] - 7s 4ms/step - loss: 2.7631 - accuracy: 0.2572\n",
      "Epoch 6/16\n",
      "1750/1750 [==============================] - 7s 4ms/step - loss: 2.7597 - accuracy: 0.2572\n",
      "Epoch 7/16\n",
      "1750/1750 [==============================] - 8s 4ms/step - loss: 2.7623 - accuracy: 0.2567\n",
      "Epoch 8/16\n",
      "1750/1750 [==============================] - 7s 4ms/step - loss: 2.7568 - accuracy: 0.2569\n",
      "Epoch 9/16\n",
      "1750/1750 [==============================] - 7s 4ms/step - loss: 2.7566 - accuracy: 0.2574\n",
      "Epoch 10/16\n",
      "1750/1750 [==============================] - 7s 4ms/step - loss: 2.7525 - accuracy: 0.2585\n",
      "Epoch 11/16\n",
      "1750/1750 [==============================] - 7s 4ms/step - loss: 2.7511 - accuracy: 0.2584\n",
      "Epoch 12/16\n",
      "1750/1750 [==============================] - 7s 4ms/step - loss: 2.7525 - accuracy: 0.2586\n",
      "Epoch 13/16\n",
      "1750/1750 [==============================] - 8s 5ms/step - loss: 2.7498 - accuracy: 0.2588\n",
      "Epoch 14/16\n",
      "1750/1750 [==============================] - 7s 4ms/step - loss: 2.7474 - accuracy: 0.2594\n",
      "Epoch 15/16\n",
      "1750/1750 [==============================] - 7s 4ms/step - loss: 2.7487 - accuracy: 0.2584\n",
      "Epoch 16/16\n",
      "1750/1750 [==============================] - 8s 4ms/step - loss: 2.7550 - accuracy: 0.2573\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7efd2c3234a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2682/2682 [==============================] - 4s 1ms/step - loss: 2.7401 - accuracy: 0.2601\n",
      "test loss, test acc: [2.740063190460205, 0.26007410883903503]\n",
      "\n",
      "\n",
      "Now validating on dialect: DR3\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_36 (Dense)             (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 43)                11051     \n",
      "=================================================================\n",
      "Total params: 144,427\n",
      "Trainable params: 144,427\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/16\n",
      "1749/1749 [==============================] - 7s 4ms/step - loss: 2.9656 - accuracy: 0.2293\n",
      "Epoch 2/16\n",
      "1749/1749 [==============================] - 7s 4ms/step - loss: 2.7927 - accuracy: 0.2508\n",
      "Epoch 3/16\n",
      "1749/1749 [==============================] - 7s 4ms/step - loss: 2.7731 - accuracy: 0.2552\n",
      "Epoch 4/16\n",
      "1749/1749 [==============================] - 7s 4ms/step - loss: 2.7690 - accuracy: 0.2557\n",
      "Epoch 5/16\n",
      "1749/1749 [==============================] - 7s 4ms/step - loss: 2.7685 - accuracy: 0.2561\n",
      "Epoch 6/16\n",
      "1749/1749 [==============================] - 7s 4ms/step - loss: 2.7634 - accuracy: 0.2564\n",
      "Epoch 7/16\n",
      "1749/1749 [==============================] - 7s 4ms/step - loss: 2.7587 - accuracy: 0.2583\n",
      "Epoch 8/16\n",
      "1749/1749 [==============================] - 8s 4ms/step - loss: 2.7595 - accuracy: 0.2580\n",
      "Epoch 9/16\n",
      "1749/1749 [==============================] - 7s 4ms/step - loss: 2.7538 - accuracy: 0.2580\n",
      "Epoch 10/16\n",
      "1749/1749 [==============================] - 7s 4ms/step - loss: 2.7562 - accuracy: 0.2577\n",
      "Epoch 11/16\n",
      "1749/1749 [==============================] - 8s 4ms/step - loss: 2.7538 - accuracy: 0.2588\n",
      "Epoch 12/16\n",
      "1749/1749 [==============================] - 8s 5ms/step - loss: 2.7571 - accuracy: 0.2574\n",
      "Epoch 13/16\n",
      "1749/1749 [==============================] - 7s 4ms/step - loss: 2.7514 - accuracy: 0.2596\n",
      "Epoch 14/16\n",
      "1749/1749 [==============================] - 7s 4ms/step - loss: 2.7503 - accuracy: 0.2592\n",
      "Epoch 15/16\n",
      "1749/1749 [==============================] - 7s 4ms/step - loss: 2.7476 - accuracy: 0.2598\n",
      "Epoch 16/16\n",
      "1749/1749 [==============================] - 7s 4ms/step - loss: 2.7513 - accuracy: 0.2586\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7efd2c3de780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2688/2688 [==============================] - 4s 1ms/step - loss: 2.7439 - accuracy: 0.2607\n",
      "test loss, test acc: [2.7439026832580566, 0.2607249617576599]\n",
      "\n",
      "\n",
      "Now validating on dialect: DR4\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_39 (Dense)             (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 43)                11051     \n",
      "=================================================================\n",
      "Total params: 144,427\n",
      "Trainable params: 144,427\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/16\n",
      "1771/1771 [==============================] - 8s 4ms/step - loss: 2.9489 - accuracy: 0.2322\n",
      "Epoch 2/16\n",
      "1771/1771 [==============================] - 8s 4ms/step - loss: 2.7876 - accuracy: 0.2532\n",
      "Epoch 3/16\n",
      "1771/1771 [==============================] - 7s 4ms/step - loss: 2.7641 - accuracy: 0.2579\n",
      "Epoch 4/16\n",
      "1771/1771 [==============================] - 7s 4ms/step - loss: 2.7601 - accuracy: 0.2588\n",
      "Epoch 5/16\n",
      "1771/1771 [==============================] - 6s 4ms/step - loss: 2.7552 - accuracy: 0.2603\n",
      "Epoch 6/16\n",
      "1771/1771 [==============================] - 7s 4ms/step - loss: 2.7544 - accuracy: 0.2592\n",
      "Epoch 7/16\n",
      "1771/1771 [==============================] - 7s 4ms/step - loss: 2.7523 - accuracy: 0.2600\n",
      "Epoch 8/16\n",
      "1771/1771 [==============================] - 7s 4ms/step - loss: 2.7464 - accuracy: 0.2604\n",
      "Epoch 9/16\n",
      "1771/1771 [==============================] - 7s 4ms/step - loss: 2.7461 - accuracy: 0.2608\n",
      "Epoch 10/16\n",
      "1771/1771 [==============================] - 7s 4ms/step - loss: 2.7438 - accuracy: 0.2607\n",
      "Epoch 11/16\n",
      "1771/1771 [==============================] - 7s 4ms/step - loss: 2.7434 - accuracy: 0.2612\n",
      "Epoch 12/16\n",
      "1771/1771 [==============================] - 6s 4ms/step - loss: 2.7421 - accuracy: 0.2621\n",
      "Epoch 13/16\n",
      "1771/1771 [==============================] - 6s 4ms/step - loss: 2.7410 - accuracy: 0.2616\n",
      "Epoch 14/16\n",
      "1771/1771 [==============================] - 7s 4ms/step - loss: 2.7399 - accuracy: 0.2618\n",
      "Epoch 15/16\n",
      "1771/1771 [==============================] - 7s 4ms/step - loss: 2.7423 - accuracy: 0.2612\n",
      "Epoch 16/16\n",
      "1771/1771 [==============================] - 8s 4ms/step - loss: 2.7402 - accuracy: 0.2616\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7efd2c3f3898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2517/2517 [==============================] - 4s 1ms/step - loss: 2.7913 - accuracy: 0.2448\n",
      "test loss, test acc: [2.7913384437561035, 0.24482445418834686]\n",
      "\n",
      "\n",
      "Now validating on dialect: DR5\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_42 (Dense)             (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 43)                11051     \n",
      "=================================================================\n",
      "Total params: 144,427\n",
      "Trainable params: 144,427\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/16\n",
      "1748/1748 [==============================] - 7s 4ms/step - loss: 2.9434 - accuracy: 0.2312\n",
      "Epoch 2/16\n",
      "1748/1748 [==============================] - 7s 4ms/step - loss: 2.7840 - accuracy: 0.2520\n",
      "Epoch 3/16\n",
      "1748/1748 [==============================] - 7s 4ms/step - loss: 2.7668 - accuracy: 0.2568\n",
      "Epoch 4/16\n",
      "1748/1748 [==============================] - 7s 4ms/step - loss: 2.7603 - accuracy: 0.2568\n",
      "Epoch 5/16\n",
      "1748/1748 [==============================] - 7s 4ms/step - loss: 2.7614 - accuracy: 0.2568\n",
      "Epoch 6/16\n",
      "1748/1748 [==============================] - 7s 4ms/step - loss: 2.7542 - accuracy: 0.2574\n",
      "Epoch 7/16\n",
      "1748/1748 [==============================] - 7s 4ms/step - loss: 2.7519 - accuracy: 0.2585\n",
      "Epoch 8/16\n",
      "1748/1748 [==============================] - 7s 4ms/step - loss: 2.7519 - accuracy: 0.2575\n",
      "Epoch 9/16\n",
      "1748/1748 [==============================] - 7s 4ms/step - loss: 2.7455 - accuracy: 0.2600\n",
      "Epoch 10/16\n",
      "1748/1748 [==============================] - 7s 4ms/step - loss: 2.7474 - accuracy: 0.2590\n",
      "Epoch 11/16\n",
      "1748/1748 [==============================] - 7s 4ms/step - loss: 2.7437 - accuracy: 0.2603\n",
      "Epoch 12/16\n",
      "1748/1748 [==============================] - 7s 4ms/step - loss: 2.7464 - accuracy: 0.2589\n",
      "Epoch 13/16\n",
      "1748/1748 [==============================] - 7s 4ms/step - loss: 2.7457 - accuracy: 0.2591\n",
      "Epoch 14/16\n",
      "1748/1748 [==============================] - 7s 4ms/step - loss: 2.7441 - accuracy: 0.2600\n",
      "Epoch 15/16\n",
      "1748/1748 [==============================] - 7s 4ms/step - loss: 2.7399 - accuracy: 0.2604\n",
      "Epoch 16/16\n",
      "1748/1748 [==============================] - 7s 4ms/step - loss: 2.7452 - accuracy: 0.2594\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7efd2c481470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2701/2701 [==============================] - 4s 1ms/step - loss: 2.7719 - accuracy: 0.2552\n",
      "test loss, test acc: [2.771883487701416, 0.25521525740623474]\n",
      "\n",
      "\n",
      "Now validating on dialect: DR6\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_45 (Dense)             (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 43)                11051     \n",
      "=================================================================\n",
      "Total params: 144,427\n",
      "Trainable params: 144,427\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/16\n",
      "1923/1923 [==============================] - 8s 4ms/step - loss: 2.9409 - accuracy: 0.2319\n",
      "Epoch 2/16\n",
      "1923/1923 [==============================] - 8s 4ms/step - loss: 2.7852 - accuracy: 0.2518\n",
      "Epoch 3/16\n",
      "1923/1923 [==============================] - 7s 4ms/step - loss: 2.7706 - accuracy: 0.2553\n",
      "Epoch 4/16\n",
      "1923/1923 [==============================] - 7s 4ms/step - loss: 2.7624 - accuracy: 0.2565\n",
      "Epoch 5/16\n",
      "1923/1923 [==============================] - 7s 4ms/step - loss: 2.7602 - accuracy: 0.2568\n",
      "Epoch 6/16\n",
      "1923/1923 [==============================] - 8s 4ms/step - loss: 2.7584 - accuracy: 0.2573\n",
      "Epoch 7/16\n",
      "1923/1923 [==============================] - 8s 4ms/step - loss: 2.7554 - accuracy: 0.2583\n",
      "Epoch 8/16\n",
      "1923/1923 [==============================] - 8s 4ms/step - loss: 2.7516 - accuracy: 0.2581\n",
      "Epoch 9/16\n",
      "1923/1923 [==============================] - 8s 4ms/step - loss: 2.7513 - accuracy: 0.2580\n",
      "Epoch 10/16\n",
      "1923/1923 [==============================] - 8s 4ms/step - loss: 2.7514 - accuracy: 0.2585\n",
      "Epoch 11/16\n",
      "1923/1923 [==============================] - 8s 4ms/step - loss: 2.7518 - accuracy: 0.2579\n",
      "Epoch 12/16\n",
      "1923/1923 [==============================] - 8s 4ms/step - loss: 2.7476 - accuracy: 0.2586\n",
      "Epoch 13/16\n",
      "1923/1923 [==============================] - 7s 4ms/step - loss: 2.7476 - accuracy: 0.2587\n",
      "Epoch 14/16\n",
      "1923/1923 [==============================] - 8s 4ms/step - loss: 2.7484 - accuracy: 0.2582\n",
      "Epoch 15/16\n",
      "1923/1923 [==============================] - 8s 4ms/step - loss: 2.7464 - accuracy: 0.2599\n",
      "Epoch 16/16\n",
      "1923/1923 [==============================] - 7s 4ms/step - loss: 2.7460 - accuracy: 0.2593\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7efd2c515e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1295/1295 [==============================] - 2s 1ms/step - loss: 2.7528 - accuracy: 0.2638\n",
      "test loss, test acc: [2.7528064250946045, 0.2638198137283325]\n",
      "\n",
      "\n",
      "Now validating on dialect: DR7\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_48 (Dense)             (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 43)                11051     \n",
      "=================================================================\n",
      "Total params: 144,427\n",
      "Trainable params: 144,427\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/16\n",
      "1747/1747 [==============================] - 8s 4ms/step - loss: 2.9579 - accuracy: 0.2291\n",
      "Epoch 2/16\n",
      "1747/1747 [==============================] - 6s 4ms/step - loss: 2.7914 - accuracy: 0.2511\n",
      "Epoch 3/16\n",
      "1747/1747 [==============================] - 6s 4ms/step - loss: 2.7751 - accuracy: 0.2550\n",
      "Epoch 4/16\n",
      "1747/1747 [==============================] - 8s 4ms/step - loss: 2.7715 - accuracy: 0.2553\n",
      "Epoch 5/16\n",
      "1747/1747 [==============================] - 7s 4ms/step - loss: 2.7653 - accuracy: 0.2561\n",
      "Epoch 6/16\n",
      "1747/1747 [==============================] - 6s 4ms/step - loss: 2.7630 - accuracy: 0.2563\n",
      "Epoch 7/16\n",
      "1747/1747 [==============================] - 7s 4ms/step - loss: 2.7614 - accuracy: 0.2568\n",
      "Epoch 8/16\n",
      "1747/1747 [==============================] - 7s 4ms/step - loss: 2.7626 - accuracy: 0.2565\n",
      "Epoch 9/16\n",
      "1747/1747 [==============================] - 6s 4ms/step - loss: 2.7585 - accuracy: 0.2579\n",
      "Epoch 10/16\n",
      "1747/1747 [==============================] - 6s 4ms/step - loss: 2.7569 - accuracy: 0.2583\n",
      "Epoch 11/16\n",
      "1747/1747 [==============================] - 7s 4ms/step - loss: 2.7563 - accuracy: 0.2574\n",
      "Epoch 12/16\n",
      "1747/1747 [==============================] - 6s 4ms/step - loss: 2.7552 - accuracy: 0.2577\n",
      "Epoch 13/16\n",
      "1747/1747 [==============================] - 7s 4ms/step - loss: 2.7549 - accuracy: 0.2581\n",
      "Epoch 14/16\n",
      "1747/1747 [==============================] - 6s 4ms/step - loss: 2.7519 - accuracy: 0.2589\n",
      "Epoch 15/16\n",
      "1747/1747 [==============================] - 7s 4ms/step - loss: 2.7530 - accuracy: 0.2583\n",
      "Epoch 16/16\n",
      "1747/1747 [==============================] - 7s 4ms/step - loss: 2.7512 - accuracy: 0.2578\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7efd2c5aafd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2707/2707 [==============================] - 3s 1ms/step - loss: 2.7261 - accuracy: 0.2636\n",
      "test loss, test acc: [2.726121187210083, 0.263571172952652]\n",
      "\n",
      "\n",
      "Now validating on dialect: DR8\n",
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_51 (Dense)             (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 43)                11051     \n",
      "=================================================================\n",
      "Total params: 144,427\n",
      "Trainable params: 144,427\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/16\n",
      "1993/1993 [==============================] - 9s 4ms/step - loss: 2.9422 - accuracy: 0.2321\n",
      "Epoch 2/16\n",
      "1993/1993 [==============================] - 7s 4ms/step - loss: 2.7861 - accuracy: 0.2522\n",
      "Epoch 3/16\n",
      "1993/1993 [==============================] - 7s 4ms/step - loss: 2.7727 - accuracy: 0.2549\n",
      "Epoch 4/16\n",
      "1993/1993 [==============================] - 7s 3ms/step - loss: 2.7680 - accuracy: 0.2555\n",
      "Epoch 5/16\n",
      "1993/1993 [==============================] - 7s 4ms/step - loss: 2.7622 - accuracy: 0.2571\n",
      "Epoch 6/16\n",
      "1993/1993 [==============================] - 7s 4ms/step - loss: 2.7604 - accuracy: 0.2571\n",
      "Epoch 7/16\n",
      "1993/1993 [==============================] - 7s 4ms/step - loss: 2.7588 - accuracy: 0.2574\n",
      "Epoch 8/16\n",
      "1993/1993 [==============================] - 8s 4ms/step - loss: 2.7565 - accuracy: 0.2577\n",
      "Epoch 9/16\n",
      "1993/1993 [==============================] - 8s 4ms/step - loss: 2.7548 - accuracy: 0.2573\n",
      "Epoch 10/16\n",
      "1993/1993 [==============================] - 8s 4ms/step - loss: 2.7507 - accuracy: 0.2592\n",
      "Epoch 11/16\n",
      "1993/1993 [==============================] - 7s 4ms/step - loss: 2.7548 - accuracy: 0.2573\n",
      "Epoch 12/16\n",
      "1993/1993 [==============================] - 7s 4ms/step - loss: 2.7495 - accuracy: 0.2587\n",
      "Epoch 13/16\n",
      "1993/1993 [==============================] - 7s 4ms/step - loss: 2.7495 - accuracy: 0.2590\n",
      "Epoch 14/16\n",
      "1993/1993 [==============================] - 7s 4ms/step - loss: 2.7505 - accuracy: 0.2583\n",
      "Epoch 15/16\n",
      "1993/1993 [==============================] - 7s 4ms/step - loss: 2.7522 - accuracy: 0.2579\n",
      "Epoch 16/16\n",
      "1993/1993 [==============================] - 7s 4ms/step - loss: 2.7470 - accuracy: 0.2592\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7efd2c5e3c88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "740/740 [==============================] - 1s 1ms/step - loss: 2.7295 - accuracy: 0.2650\n",
      "test loss, test acc: [2.729466438293457, 0.2649991512298584]\n",
      "\n",
      "Done!\n",
      "[[2.742433547973633, 0.2659114599227905], [2.740063190460205, 0.26007410883903503], [2.7439026832580566, 0.2607249617576599], [2.7913384437561035, 0.24482445418834686], [2.771883487701416, 0.25521525740623474], [2.7528064250946045, 0.2638198137283325], [2.726121187210083, 0.263571172952652], [2.729466438293457, 0.2649991512298584]]\n"
     ]
    }
   ],
   "source": [
    "dialects = pd.unique(skype_data_train.dialect)\n",
    "\n",
    "results = []\n",
    "\n",
    "for dialect in dialects:\n",
    "    print(\"\\n\\nNow validating on dialect:\", dialect)\n",
    "    \n",
    "    set_train = train_set.loc[single_phonemes_train[\"dialect\"] != dialect]\n",
    "    label_train = train_labels[single_phonemes_train[\"dialect\"] != dialect]\n",
    "    \n",
    "    validation_set = train_set.loc[single_phonemes_train[\"dialect\"] == dialect]\n",
    "    validation_labels = train_labels[single_phonemes_train[\"dialect\"] == dialect]\n",
    "    \n",
    "    model = create_model(total_unique_phonemes)\n",
    "    \n",
    "    display(model.fit(set_train, label_train, epochs=32, batch_size=256))\n",
    "    \n",
    "    result = model.evaluate(validation_set, validation_labels)\n",
    "    results.extend([result])\n",
    "    \n",
    "    print(\"test loss, test acc:\", result)\n",
    "print(\"\\nDone!\")\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
