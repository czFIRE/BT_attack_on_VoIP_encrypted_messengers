{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "sns.set()  # make plots nicer\n",
    "\n",
    "np.random.seed(42)  # set seed for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_parser_with_prev_next(path):\n",
    "    file = open(path, 'r')\n",
    "    lines = file.readlines()\n",
    "    \n",
    "    file_name = [path.split('/')[-1]]\n",
    "    sentence = \"\"\n",
    "    file_data = []\n",
    "    \n",
    "    has_value = False\n",
    "    previous = 0\n",
    "    \n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        \n",
    "        # if there are only 2 informations on line and second is h#, then ignore\n",
    "        # strip line, split primarly on ; secondary on ,\n",
    "        if (line.startswith('#')):\n",
    "            if (not sentence):\n",
    "                sentence = line[len('# Sentence: \"'): len(line) - 1]\n",
    "            continue\n",
    "        \n",
    "        line = line.split(';')\n",
    "        \n",
    "        if (len(line) == 1):\n",
    "            #lines containing only their packet size and nothing else, they should be added\n",
    "            #TODO\n",
    "            line += [\"\"]\n",
    "            line += [\"\"]\n",
    "            #continue\n",
    "        \n",
    "        if (len(line) == 2):\n",
    "            #this tries to remove most of the silence at the start of the recording\n",
    "            #potentionally harmfull as we shouldn't clean test data this way (we will be reading labels)\n",
    "            #if (line[1] == 'h#'):\n",
    "            #    continue\n",
    "            line += [\"\"]\n",
    "        \n",
    "        line[1] = tuple(line[1].split(','))\n",
    "        line[2] = tuple(list(map(lambda a: a.strip('\"'), line[2].split(','))))\n",
    "        \n",
    "        if (has_value):\n",
    "            file_data[-1][-4] = line[0]\n",
    "           \n",
    "        # file_type and sentence contain duplicate informations, but are kept for readability\n",
    "        split_filename = file_name[0].split('-')\n",
    "        \n",
    "        line = file_name + [split_filename[0]] + [split_filename[1]] + [split_filename[2][0:-4]] + [sentence] + [previous] + [0] + line\n",
    "        #adding previous as feature\n",
    "        previous = line[-3]\n",
    "        file_data += [line]\n",
    "        \n",
    "        #adding next frame as feature\n",
    "        has_value = True\n",
    "        \n",
    "    return pd.DataFrame(file_data, columns=['file', 'dialect', 'speaker', 'sentence_id', 'sentence', 'previous_packet', 'next_packet','packet_size', 'phonemes', 'words'])\n",
    "\n",
    "def load_files_with_prev_next(directory):\n",
    "    filelist = os.listdir(directory)\n",
    "    #read them into pandas\n",
    "    df_list = [file_parser_with_prev_next(directory+file) for file in filelist]\n",
    "    #concatenate them together\n",
    "    return pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "def convert_types(data_frame):\n",
    "    data_frame['packet_size'] = pd.to_numeric(data_frame['packet_size'])\n",
    "    data_frame['previous_packet'] = pd.to_numeric(data_frame['previous_packet'])\n",
    "    data_frame['next_packet'] = pd.to_numeric(data_frame['next_packet'])\n",
    "\n",
    "    data_frame['file'] = data_frame['file'].astype('category')\n",
    "    data_frame['sentence'] = data_frame['sentence'].astype('category')\n",
    "    \n",
    "    data_frame['dialect'] = data_frame['dialect'].astype('category')\n",
    "    data_frame['speaker'] = data_frame['speaker'].astype('category')\n",
    "    data_frame['sentence_id'] = data_frame['sentence_id'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>dialect</th>\n",
       "      <th>speaker</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>previous_packet</th>\n",
       "      <th>next_packet</th>\n",
       "      <th>packet_size</th>\n",
       "      <th>phonemes</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DR1-FAKS0-SA1.CSV</td>\n",
       "      <td>DR1</td>\n",
       "      <td>FAKS0</td>\n",
       "      <td>SA1</td>\n",
       "      <td>She had your dark suit in greasy wash water al...</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>30</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DR1-FAKS0-SA1.CSV</td>\n",
       "      <td>DR1</td>\n",
       "      <td>FAKS0</td>\n",
       "      <td>SA1</td>\n",
       "      <td>She had your dark suit in greasy wash water al...</td>\n",
       "      <td>30</td>\n",
       "      <td>43</td>\n",
       "      <td>35</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DR1-FAKS0-SA1.CSV</td>\n",
       "      <td>DR1</td>\n",
       "      <td>FAKS0</td>\n",
       "      <td>SA1</td>\n",
       "      <td>She had your dark suit in greasy wash water al...</td>\n",
       "      <td>35</td>\n",
       "      <td>26</td>\n",
       "      <td>43</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DR1-FAKS0-SA1.CSV</td>\n",
       "      <td>DR1</td>\n",
       "      <td>FAKS0</td>\n",
       "      <td>SA1</td>\n",
       "      <td>She had your dark suit in greasy wash water al...</td>\n",
       "      <td>43</td>\n",
       "      <td>30</td>\n",
       "      <td>26</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DR1-FAKS0-SA1.CSV</td>\n",
       "      <td>DR1</td>\n",
       "      <td>FAKS0</td>\n",
       "      <td>SA1</td>\n",
       "      <td>She had your dark suit in greasy wash water al...</td>\n",
       "      <td>26</td>\n",
       "      <td>31</td>\n",
       "      <td>30</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258516</th>\n",
       "      <td>DR8-MSLB0-SX383.CSV</td>\n",
       "      <td>DR8</td>\n",
       "      <td>MSLB0</td>\n",
       "      <td>SX383</td>\n",
       "      <td>The carpet cleaners shampooed our oriental rug.</td>\n",
       "      <td>40</td>\n",
       "      <td>43</td>\n",
       "      <td>46</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258517</th>\n",
       "      <td>DR8-MSLB0-SX383.CSV</td>\n",
       "      <td>DR8</td>\n",
       "      <td>MSLB0</td>\n",
       "      <td>SX383</td>\n",
       "      <td>The carpet cleaners shampooed our oriental rug.</td>\n",
       "      <td>46</td>\n",
       "      <td>41</td>\n",
       "      <td>43</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258518</th>\n",
       "      <td>DR8-MSLB0-SX383.CSV</td>\n",
       "      <td>DR8</td>\n",
       "      <td>MSLB0</td>\n",
       "      <td>SX383</td>\n",
       "      <td>The carpet cleaners shampooed our oriental rug.</td>\n",
       "      <td>43</td>\n",
       "      <td>34</td>\n",
       "      <td>41</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258519</th>\n",
       "      <td>DR8-MSLB0-SX383.CSV</td>\n",
       "      <td>DR8</td>\n",
       "      <td>MSLB0</td>\n",
       "      <td>SX383</td>\n",
       "      <td>The carpet cleaners shampooed our oriental rug.</td>\n",
       "      <td>41</td>\n",
       "      <td>33</td>\n",
       "      <td>34</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258520</th>\n",
       "      <td>DR8-MSLB0-SX383.CSV</td>\n",
       "      <td>DR8</td>\n",
       "      <td>MSLB0</td>\n",
       "      <td>SX383</td>\n",
       "      <td>The carpet cleaners shampooed our oriental rug.</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>258521 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       file dialect speaker sentence_id  \\\n",
       "0         DR1-FAKS0-SA1.CSV     DR1   FAKS0         SA1   \n",
       "1         DR1-FAKS0-SA1.CSV     DR1   FAKS0         SA1   \n",
       "2         DR1-FAKS0-SA1.CSV     DR1   FAKS0         SA1   \n",
       "3         DR1-FAKS0-SA1.CSV     DR1   FAKS0         SA1   \n",
       "4         DR1-FAKS0-SA1.CSV     DR1   FAKS0         SA1   \n",
       "...                     ...     ...     ...         ...   \n",
       "258516  DR8-MSLB0-SX383.CSV     DR8   MSLB0       SX383   \n",
       "258517  DR8-MSLB0-SX383.CSV     DR8   MSLB0       SX383   \n",
       "258518  DR8-MSLB0-SX383.CSV     DR8   MSLB0       SX383   \n",
       "258519  DR8-MSLB0-SX383.CSV     DR8   MSLB0       SX383   \n",
       "258520  DR8-MSLB0-SX383.CSV     DR8   MSLB0       SX383   \n",
       "\n",
       "                                                 sentence  previous_packet  \\\n",
       "0       She had your dark suit in greasy wash water al...                0   \n",
       "1       She had your dark suit in greasy wash water al...               30   \n",
       "2       She had your dark suit in greasy wash water al...               35   \n",
       "3       She had your dark suit in greasy wash water al...               43   \n",
       "4       She had your dark suit in greasy wash water al...               26   \n",
       "...                                                   ...              ...   \n",
       "258516    The carpet cleaners shampooed our oriental rug.               40   \n",
       "258517    The carpet cleaners shampooed our oriental rug.               46   \n",
       "258518    The carpet cleaners shampooed our oriental rug.               43   \n",
       "258519    The carpet cleaners shampooed our oriental rug.               41   \n",
       "258520    The carpet cleaners shampooed our oriental rug.               34   \n",
       "\n",
       "        next_packet  packet_size phonemes words  \n",
       "0                35           30    (h#,)   (,)  \n",
       "1                43           35    (h#,)   (,)  \n",
       "2                26           43    (h#,)   (,)  \n",
       "3                30           26    (h#,)   (,)  \n",
       "4                31           30    (h#,)   (,)  \n",
       "...             ...          ...      ...   ...  \n",
       "258516           43           46    (h#,)   (,)  \n",
       "258517           41           43    (h#,)   (,)  \n",
       "258518           34           41    (h#,)   (,)  \n",
       "258519           33           34    (h#,)   (,)  \n",
       "258520            0           33    (h#,)   (,)  \n",
       "\n",
       "[258521 rows x 10 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skype_data_train = load_files_with_prev_next(\"./../data/skype_train_data/\")\n",
    "skype_data_test = load_files_with_prev_next(\"./../data/skype_test_data/\")\n",
    "convert_types(skype_data_train)\n",
    "convert_types(skype_data_test)\n",
    "skype_data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>dialect</th>\n",
       "      <th>speaker</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>previous_packet</th>\n",
       "      <th>next_packet</th>\n",
       "      <th>packet_size</th>\n",
       "      <th>prev_curr</th>\n",
       "      <th>next_curr</th>\n",
       "      <th>packet_surrounding</th>\n",
       "      <th>phonemes</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DR1-FCJF0-SA1.CSV</td>\n",
       "      <td>DR1</td>\n",
       "      <td>FCJF0</td>\n",
       "      <td>SA1</td>\n",
       "      <td>She had your dark suit in greasy wash water al...</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>(0, 32)</td>\n",
       "      <td>(32, 32)</td>\n",
       "      <td>(0, 32, 32)</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DR1-FCJF0-SA1.CSV</td>\n",
       "      <td>DR1</td>\n",
       "      <td>FCJF0</td>\n",
       "      <td>SA1</td>\n",
       "      <td>She had your dark suit in greasy wash water al...</td>\n",
       "      <td>32</td>\n",
       "      <td>31</td>\n",
       "      <td>32</td>\n",
       "      <td>(32, 32)</td>\n",
       "      <td>(31, 32)</td>\n",
       "      <td>(32, 32, 31)</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DR1-FCJF0-SA1.CSV</td>\n",
       "      <td>DR1</td>\n",
       "      <td>FCJF0</td>\n",
       "      <td>SA1</td>\n",
       "      <td>She had your dark suit in greasy wash water al...</td>\n",
       "      <td>32</td>\n",
       "      <td>28</td>\n",
       "      <td>31</td>\n",
       "      <td>(32, 31)</td>\n",
       "      <td>(28, 31)</td>\n",
       "      <td>(32, 31, 28)</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DR1-FCJF0-SA1.CSV</td>\n",
       "      <td>DR1</td>\n",
       "      <td>FCJF0</td>\n",
       "      <td>SA1</td>\n",
       "      <td>She had your dark suit in greasy wash water al...</td>\n",
       "      <td>31</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>(31, 28)</td>\n",
       "      <td>(28, 28)</td>\n",
       "      <td>(31, 28, 28)</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DR1-FCJF0-SA1.CSV</td>\n",
       "      <td>DR1</td>\n",
       "      <td>FCJF0</td>\n",
       "      <td>SA1</td>\n",
       "      <td>She had your dark suit in greasy wash water al...</td>\n",
       "      <td>28</td>\n",
       "      <td>36</td>\n",
       "      <td>28</td>\n",
       "      <td>(28, 28)</td>\n",
       "      <td>(36, 28)</td>\n",
       "      <td>(28, 28, 36)</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707433</th>\n",
       "      <td>DR8-MTCS0-SX82.CSV</td>\n",
       "      <td>DR8</td>\n",
       "      <td>MTCS0</td>\n",
       "      <td>SX82</td>\n",
       "      <td>Good service should be rewarded by big tips.</td>\n",
       "      <td>47</td>\n",
       "      <td>34</td>\n",
       "      <td>32</td>\n",
       "      <td>(47, 32)</td>\n",
       "      <td>(34, 32)</td>\n",
       "      <td>(47, 32, 34)</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707434</th>\n",
       "      <td>DR8-MTCS0-SX82.CSV</td>\n",
       "      <td>DR8</td>\n",
       "      <td>MTCS0</td>\n",
       "      <td>SX82</td>\n",
       "      <td>Good service should be rewarded by big tips.</td>\n",
       "      <td>32</td>\n",
       "      <td>39</td>\n",
       "      <td>34</td>\n",
       "      <td>(32, 34)</td>\n",
       "      <td>(39, 34)</td>\n",
       "      <td>(32, 34, 39)</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707435</th>\n",
       "      <td>DR8-MTCS0-SX82.CSV</td>\n",
       "      <td>DR8</td>\n",
       "      <td>MTCS0</td>\n",
       "      <td>SX82</td>\n",
       "      <td>Good service should be rewarded by big tips.</td>\n",
       "      <td>34</td>\n",
       "      <td>33</td>\n",
       "      <td>39</td>\n",
       "      <td>(34, 39)</td>\n",
       "      <td>(33, 39)</td>\n",
       "      <td>(34, 39, 33)</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707436</th>\n",
       "      <td>DR8-MTCS0-SX82.CSV</td>\n",
       "      <td>DR8</td>\n",
       "      <td>MTCS0</td>\n",
       "      <td>SX82</td>\n",
       "      <td>Good service should be rewarded by big tips.</td>\n",
       "      <td>39</td>\n",
       "      <td>36</td>\n",
       "      <td>33</td>\n",
       "      <td>(39, 33)</td>\n",
       "      <td>(36, 33)</td>\n",
       "      <td>(39, 33, 36)</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707437</th>\n",
       "      <td>DR8-MTCS0-SX82.CSV</td>\n",
       "      <td>DR8</td>\n",
       "      <td>MTCS0</td>\n",
       "      <td>SX82</td>\n",
       "      <td>Good service should be rewarded by big tips.</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>(33, 36)</td>\n",
       "      <td>(0, 36)</td>\n",
       "      <td>(33, 36, 0)</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>707438 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      file dialect speaker sentence_id  \\\n",
       "0        DR1-FCJF0-SA1.CSV     DR1   FCJF0         SA1   \n",
       "1        DR1-FCJF0-SA1.CSV     DR1   FCJF0         SA1   \n",
       "2        DR1-FCJF0-SA1.CSV     DR1   FCJF0         SA1   \n",
       "3        DR1-FCJF0-SA1.CSV     DR1   FCJF0         SA1   \n",
       "4        DR1-FCJF0-SA1.CSV     DR1   FCJF0         SA1   \n",
       "...                    ...     ...     ...         ...   \n",
       "707433  DR8-MTCS0-SX82.CSV     DR8   MTCS0        SX82   \n",
       "707434  DR8-MTCS0-SX82.CSV     DR8   MTCS0        SX82   \n",
       "707435  DR8-MTCS0-SX82.CSV     DR8   MTCS0        SX82   \n",
       "707436  DR8-MTCS0-SX82.CSV     DR8   MTCS0        SX82   \n",
       "707437  DR8-MTCS0-SX82.CSV     DR8   MTCS0        SX82   \n",
       "\n",
       "                                                 sentence  previous_packet  \\\n",
       "0       She had your dark suit in greasy wash water al...                0   \n",
       "1       She had your dark suit in greasy wash water al...               32   \n",
       "2       She had your dark suit in greasy wash water al...               32   \n",
       "3       She had your dark suit in greasy wash water al...               31   \n",
       "4       She had your dark suit in greasy wash water al...               28   \n",
       "...                                                   ...              ...   \n",
       "707433       Good service should be rewarded by big tips.               47   \n",
       "707434       Good service should be rewarded by big tips.               32   \n",
       "707435       Good service should be rewarded by big tips.               34   \n",
       "707436       Good service should be rewarded by big tips.               39   \n",
       "707437       Good service should be rewarded by big tips.               33   \n",
       "\n",
       "        next_packet  packet_size prev_curr next_curr packet_surrounding  \\\n",
       "0                32           32   (0, 32)  (32, 32)        (0, 32, 32)   \n",
       "1                31           32  (32, 32)  (31, 32)       (32, 32, 31)   \n",
       "2                28           31  (32, 31)  (28, 31)       (32, 31, 28)   \n",
       "3                28           28  (31, 28)  (28, 28)       (31, 28, 28)   \n",
       "4                36           28  (28, 28)  (36, 28)       (28, 28, 36)   \n",
       "...             ...          ...       ...       ...                ...   \n",
       "707433           34           32  (47, 32)  (34, 32)       (47, 32, 34)   \n",
       "707434           39           34  (32, 34)  (39, 34)       (32, 34, 39)   \n",
       "707435           33           39  (34, 39)  (33, 39)       (34, 39, 33)   \n",
       "707436           36           33  (39, 33)  (36, 33)       (39, 33, 36)   \n",
       "707437            0           36  (33, 36)   (0, 36)        (33, 36, 0)   \n",
       "\n",
       "       phonemes words  \n",
       "0         (h#,)   (,)  \n",
       "1         (h#,)   (,)  \n",
       "2         (h#,)   (,)  \n",
       "3         (h#,)   (,)  \n",
       "4         (h#,)   (,)  \n",
       "...         ...   ...  \n",
       "707433    (h#,)   (,)  \n",
       "707434    (h#,)   (,)  \n",
       "707435    (h#,)   (,)  \n",
       "707436    (h#,)   (,)  \n",
       "707437    (h#,)   (,)  \n",
       "\n",
       "[707438 rows x 13 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_surrounding(data_frame):\n",
    "    data_frame['prev_curr'] = list(zip(data_frame.previous_packet, data_frame.packet_size))\n",
    "    data_frame['next_curr'] = list(zip(data_frame.next_packet, data_frame.packet_size))\n",
    "    data_frame['packet_surrounding'] = list(zip(data_frame.previous_packet, data_frame.packet_size, data_frame.next_packet))\n",
    "    \n",
    "    #data_frame['prev_curr'] = data_frame['prev_curr'].astype('category')\n",
    "    #data_frame['next_curr'] = data_frame['next_curr'].astype('category')\n",
    "    #data_frame['packet_surrounding'] = data_frame['packet_surrounding'].astype('category')\n",
    "\n",
    "add_surrounding(skype_data_train)\n",
    "add_surrounding(skype_data_test)\n",
    "\n",
    "skype_data_train = skype_data_train[['file', 'dialect', 'speaker', 'sentence_id', 'sentence', 'previous_packet', 'next_packet','packet_size', 'prev_curr', 'next_curr', 'packet_surrounding', 'phonemes', 'words']]\n",
    "skype_data_test = skype_data_test[['file', 'dialect', 'speaker', 'sentence_id', 'sentence', 'previous_packet', 'next_packet','packet_size', 'prev_curr', 'next_curr', 'packet_surrounding', 'phonemes', 'words']]\n",
    "skype_data_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Something about preparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>previous_packet</th>\n",
       "      <th>packet_size</th>\n",
       "      <th>next_packet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32</td>\n",
       "      <td>31</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707433</th>\n",
       "      <td>47</td>\n",
       "      <td>32</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707434</th>\n",
       "      <td>32</td>\n",
       "      <td>34</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707435</th>\n",
       "      <td>34</td>\n",
       "      <td>39</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707436</th>\n",
       "      <td>39</td>\n",
       "      <td>33</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707437</th>\n",
       "      <td>33</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>707438 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        previous_packet  packet_size  next_packet\n",
       "0                     0           32           32\n",
       "1                    32           32           31\n",
       "2                    32           31           28\n",
       "3                    31           28           28\n",
       "4                    28           28           36\n",
       "...                 ...          ...          ...\n",
       "707433               47           32           34\n",
       "707434               32           34           39\n",
       "707435               34           39           33\n",
       "707436               39           33           36\n",
       "707437               33           36            0\n",
       "\n",
       "[707438 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skype_data_train.loc[:, [\"previous_packet\", \"packet_size\", \"next_packet\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add removal of labels for the test_dataset\n",
    "def get_labels(df, label=[\"words\"], feature=[\"previous_packet\", \"packet_size\", \"next_packet\"]):\n",
    "    labels = df.loc[:, label]\n",
    "    features = df.loc[:, feature]\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_labels(train_labels, test_labels, label=[\"words\"]):\n",
    "    train_labels = train_labels.astype('category')\n",
    "    test_labels = test_labels.astype('category')\n",
    "    \n",
    "    total_labels = train_labels.append(test_labels)\n",
    "    \n",
    "    lab_enc = LabelEncoder()\n",
    "    lab_enc.fit(total_labels[label])\n",
    "\n",
    "    train_labels = lab_enc.transform(train_labels[label])\n",
    "    test_labels = lab_enc.transform(test_labels[label])\n",
    "    \n",
    "    return train_labels, test_labels, lab_enc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>dialect</th>\n",
       "      <th>speaker</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>previous_packet</th>\n",
       "      <th>next_packet</th>\n",
       "      <th>packet_size</th>\n",
       "      <th>prev_curr</th>\n",
       "      <th>next_curr</th>\n",
       "      <th>packet_surrounding</th>\n",
       "      <th>phonemes</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DR1-FCJF0-SA1.CSV</td>\n",
       "      <td>DR1</td>\n",
       "      <td>FCJF0</td>\n",
       "      <td>SA1</td>\n",
       "      <td>She had your dark suit in greasy wash water al...</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>(0, 32)</td>\n",
       "      <td>(32, 32)</td>\n",
       "      <td>(0, 32, 32)</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DR1-FCJF0-SA1.CSV</td>\n",
       "      <td>DR1</td>\n",
       "      <td>FCJF0</td>\n",
       "      <td>SA1</td>\n",
       "      <td>She had your dark suit in greasy wash water al...</td>\n",
       "      <td>32</td>\n",
       "      <td>31</td>\n",
       "      <td>32</td>\n",
       "      <td>(32, 32)</td>\n",
       "      <td>(31, 32)</td>\n",
       "      <td>(32, 32, 31)</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DR1-FCJF0-SA1.CSV</td>\n",
       "      <td>DR1</td>\n",
       "      <td>FCJF0</td>\n",
       "      <td>SA1</td>\n",
       "      <td>She had your dark suit in greasy wash water al...</td>\n",
       "      <td>32</td>\n",
       "      <td>28</td>\n",
       "      <td>31</td>\n",
       "      <td>(32, 31)</td>\n",
       "      <td>(28, 31)</td>\n",
       "      <td>(32, 31, 28)</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DR1-FCJF0-SA1.CSV</td>\n",
       "      <td>DR1</td>\n",
       "      <td>FCJF0</td>\n",
       "      <td>SA1</td>\n",
       "      <td>She had your dark suit in greasy wash water al...</td>\n",
       "      <td>31</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>(31, 28)</td>\n",
       "      <td>(28, 28)</td>\n",
       "      <td>(31, 28, 28)</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DR1-FCJF0-SA1.CSV</td>\n",
       "      <td>DR1</td>\n",
       "      <td>FCJF0</td>\n",
       "      <td>SA1</td>\n",
       "      <td>She had your dark suit in greasy wash water al...</td>\n",
       "      <td>28</td>\n",
       "      <td>36</td>\n",
       "      <td>28</td>\n",
       "      <td>(28, 28)</td>\n",
       "      <td>(36, 28)</td>\n",
       "      <td>(28, 28, 36)</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533700</th>\n",
       "      <td>DR8-MTCS0-SX82.CSV</td>\n",
       "      <td>DR8</td>\n",
       "      <td>MTCS0</td>\n",
       "      <td>SX82</td>\n",
       "      <td>Good service should be rewarded by big tips.</td>\n",
       "      <td>47</td>\n",
       "      <td>34</td>\n",
       "      <td>32</td>\n",
       "      <td>(47, 32)</td>\n",
       "      <td>(34, 32)</td>\n",
       "      <td>(47, 32, 34)</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533701</th>\n",
       "      <td>DR8-MTCS0-SX82.CSV</td>\n",
       "      <td>DR8</td>\n",
       "      <td>MTCS0</td>\n",
       "      <td>SX82</td>\n",
       "      <td>Good service should be rewarded by big tips.</td>\n",
       "      <td>32</td>\n",
       "      <td>39</td>\n",
       "      <td>34</td>\n",
       "      <td>(32, 34)</td>\n",
       "      <td>(39, 34)</td>\n",
       "      <td>(32, 34, 39)</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533702</th>\n",
       "      <td>DR8-MTCS0-SX82.CSV</td>\n",
       "      <td>DR8</td>\n",
       "      <td>MTCS0</td>\n",
       "      <td>SX82</td>\n",
       "      <td>Good service should be rewarded by big tips.</td>\n",
       "      <td>34</td>\n",
       "      <td>33</td>\n",
       "      <td>39</td>\n",
       "      <td>(34, 39)</td>\n",
       "      <td>(33, 39)</td>\n",
       "      <td>(34, 39, 33)</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533703</th>\n",
       "      <td>DR8-MTCS0-SX82.CSV</td>\n",
       "      <td>DR8</td>\n",
       "      <td>MTCS0</td>\n",
       "      <td>SX82</td>\n",
       "      <td>Good service should be rewarded by big tips.</td>\n",
       "      <td>39</td>\n",
       "      <td>36</td>\n",
       "      <td>33</td>\n",
       "      <td>(39, 33)</td>\n",
       "      <td>(36, 33)</td>\n",
       "      <td>(39, 33, 36)</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533704</th>\n",
       "      <td>DR8-MTCS0-SX82.CSV</td>\n",
       "      <td>DR8</td>\n",
       "      <td>MTCS0</td>\n",
       "      <td>SX82</td>\n",
       "      <td>Good service should be rewarded by big tips.</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>(33, 36)</td>\n",
       "      <td>(0, 36)</td>\n",
       "      <td>(33, 36, 0)</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>533705 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      file dialect speaker sentence_id  \\\n",
       "0        DR1-FCJF0-SA1.CSV     DR1   FCJF0         SA1   \n",
       "1        DR1-FCJF0-SA1.CSV     DR1   FCJF0         SA1   \n",
       "2        DR1-FCJF0-SA1.CSV     DR1   FCJF0         SA1   \n",
       "3        DR1-FCJF0-SA1.CSV     DR1   FCJF0         SA1   \n",
       "4        DR1-FCJF0-SA1.CSV     DR1   FCJF0         SA1   \n",
       "...                    ...     ...     ...         ...   \n",
       "533700  DR8-MTCS0-SX82.CSV     DR8   MTCS0        SX82   \n",
       "533701  DR8-MTCS0-SX82.CSV     DR8   MTCS0        SX82   \n",
       "533702  DR8-MTCS0-SX82.CSV     DR8   MTCS0        SX82   \n",
       "533703  DR8-MTCS0-SX82.CSV     DR8   MTCS0        SX82   \n",
       "533704  DR8-MTCS0-SX82.CSV     DR8   MTCS0        SX82   \n",
       "\n",
       "                                                 sentence  previous_packet  \\\n",
       "0       She had your dark suit in greasy wash water al...                0   \n",
       "1       She had your dark suit in greasy wash water al...               32   \n",
       "2       She had your dark suit in greasy wash water al...               32   \n",
       "3       She had your dark suit in greasy wash water al...               31   \n",
       "4       She had your dark suit in greasy wash water al...               28   \n",
       "...                                                   ...              ...   \n",
       "533700       Good service should be rewarded by big tips.               47   \n",
       "533701       Good service should be rewarded by big tips.               32   \n",
       "533702       Good service should be rewarded by big tips.               34   \n",
       "533703       Good service should be rewarded by big tips.               39   \n",
       "533704       Good service should be rewarded by big tips.               33   \n",
       "\n",
       "        next_packet  packet_size prev_curr next_curr packet_surrounding  \\\n",
       "0                32           32   (0, 32)  (32, 32)        (0, 32, 32)   \n",
       "1                31           32  (32, 32)  (31, 32)       (32, 32, 31)   \n",
       "2                28           31  (32, 31)  (28, 31)       (32, 31, 28)   \n",
       "3                28           28  (31, 28)  (28, 28)       (31, 28, 28)   \n",
       "4                36           28  (28, 28)  (36, 28)       (28, 28, 36)   \n",
       "...             ...          ...       ...       ...                ...   \n",
       "533700           34           32  (47, 32)  (34, 32)       (47, 32, 34)   \n",
       "533701           39           34  (32, 34)  (39, 34)       (32, 34, 39)   \n",
       "533702           33           39  (34, 39)  (33, 39)       (34, 39, 33)   \n",
       "533703           36           33  (39, 33)  (36, 33)       (39, 33, 36)   \n",
       "533704            0           36  (33, 36)   (0, 36)        (33, 36, 0)   \n",
       "\n",
       "       phonemes words  \n",
       "0         (h#,)   (,)  \n",
       "1         (h#,)   (,)  \n",
       "2         (h#,)   (,)  \n",
       "3         (h#,)   (,)  \n",
       "4         (h#,)   (,)  \n",
       "...         ...   ...  \n",
       "533700    (h#,)   (,)  \n",
       "533701    (h#,)   (,)  \n",
       "533702    (h#,)   (,)  \n",
       "533703    (h#,)   (,)  \n",
       "533704    (h#,)   (,)  \n",
       "\n",
       "[533705 rows x 13 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# there are no \"empty\" phonemes\n",
    "single_phonemes_train = skype_data_train.loc[skype_data_train.phonemes.apply(len) == 1].reset_index(drop=True)\n",
    "single_phonemes_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pd.unique(single_phonemes_train.phonemes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([('h#',), ('sh',), ('ix',), ('hv',), ('eh',), ('jh',), ('ih',),\n",
       "       ('dcl',), ('ah',), ('kcl',), ('k',), ('s',), ('ux',), ('q',),\n",
       "       ('en',), ('r',), ('w',), ('ao',), ('axr',), ('l',), ('y',),\n",
       "       ('uh',), ('n',), ('ae',), ('dx',), ('oy',), ('ax',), ('gcl',),\n",
       "       ('dh',), ('tcl',), ('iy',), ('v',), ('t',), ('f',), ('ow',),\n",
       "       ('d',), ('hh',), ('ch',), ('bcl',), ('aa',), ('em',), ('ng',),\n",
       "       ('m',), ('ay',), ('th',), ('ax-h',), ('ey',), ('p',), ('pcl',),\n",
       "       ('aw',), ('er',), ('z',), ('epi',), ('el',), ('uw',), ('g',),\n",
       "       ('',), ('b',), ('pau',), ('zh',), ('nx',), ('eng',)], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.unique(single_phonemes_train.phonemes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taken from: https://github.com/jhasegaw/phonecodes/blob/master/src/phonecode_tables.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "arpa_to_ipa = {\n",
    "    'aa':'ɑ',\n",
    "    'ae':'æ',\n",
    "    'ah':'ʌ',\n",
    "    'ah0':'ə',\n",
    "    'ao':'ɔ',\n",
    "    'aw':'aʊ',\n",
    "    'ay':'aɪ',\n",
    "    'eh':'ɛ',\n",
    "    'er':'ɝ',\n",
    "    'er0':'ɚ',\n",
    "    'ey':'eɪ',\n",
    "    'ih':'ɪ',\n",
    "    'ih0':'ɨ',\n",
    "    'iy':'i',\n",
    "    'ow':'oʊ',\n",
    "    'oy':'ɔɪ',\n",
    "    'uh':'ʊ',\n",
    "    'uw':'u',\n",
    "    'b':'b',\n",
    "    'ch':'tʃ',\n",
    "    'd':'d',\n",
    "    'dh':'ð',\n",
    "    'el':'l̩',\n",
    "    'em':'m̩',\n",
    "    'en':'n̩',\n",
    "    'f':'f',\n",
    "    'g':'ɡ',\n",
    "    'hh':'h',\n",
    "    'jh':'dʒ',\n",
    "    'k':'k',\n",
    "    'l':'l',\n",
    "    'm':'m',\n",
    "    'n':'n',\n",
    "    'ng':'ŋ',\n",
    "    'p':'p',\n",
    "    'q':'ʔ',\n",
    "    'r':'ɹ',\n",
    "    's':'s',\n",
    "    'sh':'ʃ',\n",
    "    't':'t',\n",
    "    'th':'θ',\n",
    "    'v':'v',\n",
    "    'w':'w',\n",
    "    'wh':'ʍ',\n",
    "    'y':'j',\n",
    "    'z':'z',\n",
    "    'zh':'ʒ',\n",
    "\n",
    "    'ax':'ə',\n",
    "    'ax-h':'ə̥',\n",
    "    'axr':'ɚ',\n",
    "    'bcl':'b',\n",
    "    'dcl':'d',\n",
    "    'dx':'ɾ',\n",
    "    'eng':'ŋ̍',\n",
    "    'epi':'',\n",
    "    'gcl':'g',\n",
    "    'hv':'ɦ',\n",
    "    'h#':'',\n",
    "    'ix':'ɨ',\n",
    "    'kcl':'k',\n",
    "    'nx':'ɾ̃',\n",
    "    'pau':'',\n",
    "    'pcl':'p',\n",
    "    'tcl':'t',\n",
    "    'ux':'ʉ',\n",
    "    '':'',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(arpa_to_ipa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This modification is based on this: https://en.wikipedia.org/wiki/ARPABET (+ minor guessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipa_allophone = {\n",
    "    'ŋ̍':'n', #should be ŋ\n",
    "    'ə̥':'ɛ',\n",
    "    'ɨ':'ɪ',\n",
    "    'n̩':'n',\n",
    "    'm̩':'m',\n",
    "    'ŋ':'n',\n",
    "    'ɾ̃':'n',\n",
    "    'ð':'θ',\n",
    "    'ʉ':'u',\n",
    "    'ɾ':'d',\n",
    "    'l̩':'l',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', 'ʃ', 'ɪ', 'ɦ', 'ɛ', 'dʒ', 'ɪ', 'd', 'ʌ', 'k', 'k', 's', 'u',\n",
       "       'ʔ', 'n', 'ɹ', 'w', 'ɔ', 'ɚ', 'l', 'j', 'ʊ', 'n', 'æ', 'd', 'ɔɪ',\n",
       "       'ə', 'g', 'θ', 't', 'i', 'v', 't', 'f', 'oʊ', 'd', 'h', 'tʃ', 'b',\n",
       "       'ɑ', 'm', 'n', 'm', 'aɪ', 'θ', 'ɛ', 'eɪ', 'p', 'p', 'aʊ', 'ɝ', 'z',\n",
       "       '', 'l', 'u', 'ɡ', '', 'b', '', 'ʒ', 'n', 'n'], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniq_phon = pd.unique(single_phonemes_train.phonemes)\n",
    "for i in range(len(uniq_phon)):\n",
    "    uniq_phon[i] = arpa_to_ipa.get(uniq_phon[i][0], uniq_phon[i][0])\n",
    "    uniq_phon[i] = ipa_allophone.get(uniq_phon[i], uniq_phon[i])\n",
    "    \n",
    "uniq_phon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(uniq_phon))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now modifying our input dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input is expected to be a tuple\n",
    "def convert_phoneme(phoneme):\n",
    "    tmp_1 = arpa_to_ipa.get(phoneme[0], phoneme[0])\n",
    "    tmp_2 = ipa_allophone.get(tmp_1, tmp_1)\n",
    "    return tmp_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>dialect</th>\n",
       "      <th>speaker</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>previous_packet</th>\n",
       "      <th>next_packet</th>\n",
       "      <th>packet_size</th>\n",
       "      <th>prev_curr</th>\n",
       "      <th>next_curr</th>\n",
       "      <th>packet_surrounding</th>\n",
       "      <th>phonemes</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DR1-FAKS0-SA1.CSV</td>\n",
       "      <td>DR1</td>\n",
       "      <td>FAKS0</td>\n",
       "      <td>SA1</td>\n",
       "      <td>She had your dark suit in greasy wash water al...</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>30</td>\n",
       "      <td>(0, 30)</td>\n",
       "      <td>(35, 30)</td>\n",
       "      <td>(0, 30, 35)</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DR1-FAKS0-SA1.CSV</td>\n",
       "      <td>DR1</td>\n",
       "      <td>FAKS0</td>\n",
       "      <td>SA1</td>\n",
       "      <td>She had your dark suit in greasy wash water al...</td>\n",
       "      <td>30</td>\n",
       "      <td>43</td>\n",
       "      <td>35</td>\n",
       "      <td>(30, 35)</td>\n",
       "      <td>(43, 35)</td>\n",
       "      <td>(30, 35, 43)</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DR1-FAKS0-SA1.CSV</td>\n",
       "      <td>DR1</td>\n",
       "      <td>FAKS0</td>\n",
       "      <td>SA1</td>\n",
       "      <td>She had your dark suit in greasy wash water al...</td>\n",
       "      <td>35</td>\n",
       "      <td>26</td>\n",
       "      <td>43</td>\n",
       "      <td>(35, 43)</td>\n",
       "      <td>(26, 43)</td>\n",
       "      <td>(35, 43, 26)</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DR1-FAKS0-SA1.CSV</td>\n",
       "      <td>DR1</td>\n",
       "      <td>FAKS0</td>\n",
       "      <td>SA1</td>\n",
       "      <td>She had your dark suit in greasy wash water al...</td>\n",
       "      <td>43</td>\n",
       "      <td>30</td>\n",
       "      <td>26</td>\n",
       "      <td>(43, 26)</td>\n",
       "      <td>(30, 26)</td>\n",
       "      <td>(43, 26, 30)</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DR1-FAKS0-SA1.CSV</td>\n",
       "      <td>DR1</td>\n",
       "      <td>FAKS0</td>\n",
       "      <td>SA1</td>\n",
       "      <td>She had your dark suit in greasy wash water al...</td>\n",
       "      <td>26</td>\n",
       "      <td>31</td>\n",
       "      <td>30</td>\n",
       "      <td>(26, 30)</td>\n",
       "      <td>(31, 30)</td>\n",
       "      <td>(26, 30, 31)</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195608</th>\n",
       "      <td>DR8-MSLB0-SX383.CSV</td>\n",
       "      <td>DR8</td>\n",
       "      <td>MSLB0</td>\n",
       "      <td>SX383</td>\n",
       "      <td>The carpet cleaners shampooed our oriental rug.</td>\n",
       "      <td>40</td>\n",
       "      <td>43</td>\n",
       "      <td>46</td>\n",
       "      <td>(40, 46)</td>\n",
       "      <td>(43, 46)</td>\n",
       "      <td>(40, 46, 43)</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195609</th>\n",
       "      <td>DR8-MSLB0-SX383.CSV</td>\n",
       "      <td>DR8</td>\n",
       "      <td>MSLB0</td>\n",
       "      <td>SX383</td>\n",
       "      <td>The carpet cleaners shampooed our oriental rug.</td>\n",
       "      <td>46</td>\n",
       "      <td>41</td>\n",
       "      <td>43</td>\n",
       "      <td>(46, 43)</td>\n",
       "      <td>(41, 43)</td>\n",
       "      <td>(46, 43, 41)</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195610</th>\n",
       "      <td>DR8-MSLB0-SX383.CSV</td>\n",
       "      <td>DR8</td>\n",
       "      <td>MSLB0</td>\n",
       "      <td>SX383</td>\n",
       "      <td>The carpet cleaners shampooed our oriental rug.</td>\n",
       "      <td>43</td>\n",
       "      <td>34</td>\n",
       "      <td>41</td>\n",
       "      <td>(43, 41)</td>\n",
       "      <td>(34, 41)</td>\n",
       "      <td>(43, 41, 34)</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195611</th>\n",
       "      <td>DR8-MSLB0-SX383.CSV</td>\n",
       "      <td>DR8</td>\n",
       "      <td>MSLB0</td>\n",
       "      <td>SX383</td>\n",
       "      <td>The carpet cleaners shampooed our oriental rug.</td>\n",
       "      <td>41</td>\n",
       "      <td>33</td>\n",
       "      <td>34</td>\n",
       "      <td>(41, 34)</td>\n",
       "      <td>(33, 34)</td>\n",
       "      <td>(41, 34, 33)</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195612</th>\n",
       "      <td>DR8-MSLB0-SX383.CSV</td>\n",
       "      <td>DR8</td>\n",
       "      <td>MSLB0</td>\n",
       "      <td>SX383</td>\n",
       "      <td>The carpet cleaners shampooed our oriental rug.</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>(34, 33)</td>\n",
       "      <td>(0, 33)</td>\n",
       "      <td>(34, 33, 0)</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195613 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       file dialect speaker sentence_id  \\\n",
       "0         DR1-FAKS0-SA1.CSV     DR1   FAKS0         SA1   \n",
       "1         DR1-FAKS0-SA1.CSV     DR1   FAKS0         SA1   \n",
       "2         DR1-FAKS0-SA1.CSV     DR1   FAKS0         SA1   \n",
       "3         DR1-FAKS0-SA1.CSV     DR1   FAKS0         SA1   \n",
       "4         DR1-FAKS0-SA1.CSV     DR1   FAKS0         SA1   \n",
       "...                     ...     ...     ...         ...   \n",
       "195608  DR8-MSLB0-SX383.CSV     DR8   MSLB0       SX383   \n",
       "195609  DR8-MSLB0-SX383.CSV     DR8   MSLB0       SX383   \n",
       "195610  DR8-MSLB0-SX383.CSV     DR8   MSLB0       SX383   \n",
       "195611  DR8-MSLB0-SX383.CSV     DR8   MSLB0       SX383   \n",
       "195612  DR8-MSLB0-SX383.CSV     DR8   MSLB0       SX383   \n",
       "\n",
       "                                                 sentence  previous_packet  \\\n",
       "0       She had your dark suit in greasy wash water al...                0   \n",
       "1       She had your dark suit in greasy wash water al...               30   \n",
       "2       She had your dark suit in greasy wash water al...               35   \n",
       "3       She had your dark suit in greasy wash water al...               43   \n",
       "4       She had your dark suit in greasy wash water al...               26   \n",
       "...                                                   ...              ...   \n",
       "195608    The carpet cleaners shampooed our oriental rug.               40   \n",
       "195609    The carpet cleaners shampooed our oriental rug.               46   \n",
       "195610    The carpet cleaners shampooed our oriental rug.               43   \n",
       "195611    The carpet cleaners shampooed our oriental rug.               41   \n",
       "195612    The carpet cleaners shampooed our oriental rug.               34   \n",
       "\n",
       "        next_packet  packet_size prev_curr next_curr packet_surrounding  \\\n",
       "0                35           30   (0, 30)  (35, 30)        (0, 30, 35)   \n",
       "1                43           35  (30, 35)  (43, 35)       (30, 35, 43)   \n",
       "2                26           43  (35, 43)  (26, 43)       (35, 43, 26)   \n",
       "3                30           26  (43, 26)  (30, 26)       (43, 26, 30)   \n",
       "4                31           30  (26, 30)  (31, 30)       (26, 30, 31)   \n",
       "...             ...          ...       ...       ...                ...   \n",
       "195608           43           46  (40, 46)  (43, 46)       (40, 46, 43)   \n",
       "195609           41           43  (46, 43)  (41, 43)       (46, 43, 41)   \n",
       "195610           34           41  (43, 41)  (34, 41)       (43, 41, 34)   \n",
       "195611           33           34  (41, 34)  (33, 34)       (41, 34, 33)   \n",
       "195612            0           33  (34, 33)   (0, 33)        (34, 33, 0)   \n",
       "\n",
       "       phonemes words  \n",
       "0         (h#,)   (,)  \n",
       "1         (h#,)   (,)  \n",
       "2         (h#,)   (,)  \n",
       "3         (h#,)   (,)  \n",
       "4         (h#,)   (,)  \n",
       "...         ...   ...  \n",
       "195608    (h#,)   (,)  \n",
       "195609    (h#,)   (,)  \n",
       "195610    (h#,)   (,)  \n",
       "195611    (h#,)   (,)  \n",
       "195612    (h#,)   (,)  \n",
       "\n",
       "[195613 rows x 13 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_phonemes_train = skype_data_train.loc[skype_data_train.phonemes.apply(len) == 1].reset_index(drop=True)\n",
    "single_phonemes_test = skype_data_test.loc[skype_data_test.phonemes.apply(len) == 1].reset_index(drop=True)\n",
    "single_phonemes_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>dialect</th>\n",
       "      <th>speaker</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>previous_packet</th>\n",
       "      <th>next_packet</th>\n",
       "      <th>packet_size</th>\n",
       "      <th>prev_curr</th>\n",
       "      <th>next_curr</th>\n",
       "      <th>packet_surrounding</th>\n",
       "      <th>phonemes</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DR1-FAKS0-SA1.CSV</td>\n",
       "      <td>DR1</td>\n",
       "      <td>FAKS0</td>\n",
       "      <td>SA1</td>\n",
       "      <td>She had your dark suit in greasy wash water al...</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>30</td>\n",
       "      <td>(0, 30)</td>\n",
       "      <td>(35, 30)</td>\n",
       "      <td>(0, 30, 35)</td>\n",
       "      <td></td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DR1-FAKS0-SA1.CSV</td>\n",
       "      <td>DR1</td>\n",
       "      <td>FAKS0</td>\n",
       "      <td>SA1</td>\n",
       "      <td>She had your dark suit in greasy wash water al...</td>\n",
       "      <td>30</td>\n",
       "      <td>43</td>\n",
       "      <td>35</td>\n",
       "      <td>(30, 35)</td>\n",
       "      <td>(43, 35)</td>\n",
       "      <td>(30, 35, 43)</td>\n",
       "      <td></td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DR1-FAKS0-SA1.CSV</td>\n",
       "      <td>DR1</td>\n",
       "      <td>FAKS0</td>\n",
       "      <td>SA1</td>\n",
       "      <td>She had your dark suit in greasy wash water al...</td>\n",
       "      <td>35</td>\n",
       "      <td>26</td>\n",
       "      <td>43</td>\n",
       "      <td>(35, 43)</td>\n",
       "      <td>(26, 43)</td>\n",
       "      <td>(35, 43, 26)</td>\n",
       "      <td></td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DR1-FAKS0-SA1.CSV</td>\n",
       "      <td>DR1</td>\n",
       "      <td>FAKS0</td>\n",
       "      <td>SA1</td>\n",
       "      <td>She had your dark suit in greasy wash water al...</td>\n",
       "      <td>43</td>\n",
       "      <td>30</td>\n",
       "      <td>26</td>\n",
       "      <td>(43, 26)</td>\n",
       "      <td>(30, 26)</td>\n",
       "      <td>(43, 26, 30)</td>\n",
       "      <td></td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DR1-FAKS0-SA1.CSV</td>\n",
       "      <td>DR1</td>\n",
       "      <td>FAKS0</td>\n",
       "      <td>SA1</td>\n",
       "      <td>She had your dark suit in greasy wash water al...</td>\n",
       "      <td>26</td>\n",
       "      <td>31</td>\n",
       "      <td>30</td>\n",
       "      <td>(26, 30)</td>\n",
       "      <td>(31, 30)</td>\n",
       "      <td>(26, 30, 31)</td>\n",
       "      <td></td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195608</th>\n",
       "      <td>DR8-MSLB0-SX383.CSV</td>\n",
       "      <td>DR8</td>\n",
       "      <td>MSLB0</td>\n",
       "      <td>SX383</td>\n",
       "      <td>The carpet cleaners shampooed our oriental rug.</td>\n",
       "      <td>40</td>\n",
       "      <td>43</td>\n",
       "      <td>46</td>\n",
       "      <td>(40, 46)</td>\n",
       "      <td>(43, 46)</td>\n",
       "      <td>(40, 46, 43)</td>\n",
       "      <td></td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195609</th>\n",
       "      <td>DR8-MSLB0-SX383.CSV</td>\n",
       "      <td>DR8</td>\n",
       "      <td>MSLB0</td>\n",
       "      <td>SX383</td>\n",
       "      <td>The carpet cleaners shampooed our oriental rug.</td>\n",
       "      <td>46</td>\n",
       "      <td>41</td>\n",
       "      <td>43</td>\n",
       "      <td>(46, 43)</td>\n",
       "      <td>(41, 43)</td>\n",
       "      <td>(46, 43, 41)</td>\n",
       "      <td></td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195610</th>\n",
       "      <td>DR8-MSLB0-SX383.CSV</td>\n",
       "      <td>DR8</td>\n",
       "      <td>MSLB0</td>\n",
       "      <td>SX383</td>\n",
       "      <td>The carpet cleaners shampooed our oriental rug.</td>\n",
       "      <td>43</td>\n",
       "      <td>34</td>\n",
       "      <td>41</td>\n",
       "      <td>(43, 41)</td>\n",
       "      <td>(34, 41)</td>\n",
       "      <td>(43, 41, 34)</td>\n",
       "      <td></td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195611</th>\n",
       "      <td>DR8-MSLB0-SX383.CSV</td>\n",
       "      <td>DR8</td>\n",
       "      <td>MSLB0</td>\n",
       "      <td>SX383</td>\n",
       "      <td>The carpet cleaners shampooed our oriental rug.</td>\n",
       "      <td>41</td>\n",
       "      <td>33</td>\n",
       "      <td>34</td>\n",
       "      <td>(41, 34)</td>\n",
       "      <td>(33, 34)</td>\n",
       "      <td>(41, 34, 33)</td>\n",
       "      <td></td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195612</th>\n",
       "      <td>DR8-MSLB0-SX383.CSV</td>\n",
       "      <td>DR8</td>\n",
       "      <td>MSLB0</td>\n",
       "      <td>SX383</td>\n",
       "      <td>The carpet cleaners shampooed our oriental rug.</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>(34, 33)</td>\n",
       "      <td>(0, 33)</td>\n",
       "      <td>(34, 33, 0)</td>\n",
       "      <td></td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195613 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       file dialect speaker sentence_id  \\\n",
       "0         DR1-FAKS0-SA1.CSV     DR1   FAKS0         SA1   \n",
       "1         DR1-FAKS0-SA1.CSV     DR1   FAKS0         SA1   \n",
       "2         DR1-FAKS0-SA1.CSV     DR1   FAKS0         SA1   \n",
       "3         DR1-FAKS0-SA1.CSV     DR1   FAKS0         SA1   \n",
       "4         DR1-FAKS0-SA1.CSV     DR1   FAKS0         SA1   \n",
       "...                     ...     ...     ...         ...   \n",
       "195608  DR8-MSLB0-SX383.CSV     DR8   MSLB0       SX383   \n",
       "195609  DR8-MSLB0-SX383.CSV     DR8   MSLB0       SX383   \n",
       "195610  DR8-MSLB0-SX383.CSV     DR8   MSLB0       SX383   \n",
       "195611  DR8-MSLB0-SX383.CSV     DR8   MSLB0       SX383   \n",
       "195612  DR8-MSLB0-SX383.CSV     DR8   MSLB0       SX383   \n",
       "\n",
       "                                                 sentence  previous_packet  \\\n",
       "0       She had your dark suit in greasy wash water al...                0   \n",
       "1       She had your dark suit in greasy wash water al...               30   \n",
       "2       She had your dark suit in greasy wash water al...               35   \n",
       "3       She had your dark suit in greasy wash water al...               43   \n",
       "4       She had your dark suit in greasy wash water al...               26   \n",
       "...                                                   ...              ...   \n",
       "195608    The carpet cleaners shampooed our oriental rug.               40   \n",
       "195609    The carpet cleaners shampooed our oriental rug.               46   \n",
       "195610    The carpet cleaners shampooed our oriental rug.               43   \n",
       "195611    The carpet cleaners shampooed our oriental rug.               41   \n",
       "195612    The carpet cleaners shampooed our oriental rug.               34   \n",
       "\n",
       "        next_packet  packet_size prev_curr next_curr packet_surrounding  \\\n",
       "0                35           30   (0, 30)  (35, 30)        (0, 30, 35)   \n",
       "1                43           35  (30, 35)  (43, 35)       (30, 35, 43)   \n",
       "2                26           43  (35, 43)  (26, 43)       (35, 43, 26)   \n",
       "3                30           26  (43, 26)  (30, 26)       (43, 26, 30)   \n",
       "4                31           30  (26, 30)  (31, 30)       (26, 30, 31)   \n",
       "...             ...          ...       ...       ...                ...   \n",
       "195608           43           46  (40, 46)  (43, 46)       (40, 46, 43)   \n",
       "195609           41           43  (46, 43)  (41, 43)       (46, 43, 41)   \n",
       "195610           34           41  (43, 41)  (34, 41)       (43, 41, 34)   \n",
       "195611           33           34  (41, 34)  (33, 34)       (41, 34, 33)   \n",
       "195612            0           33  (34, 33)   (0, 33)        (34, 33, 0)   \n",
       "\n",
       "       phonemes words  \n",
       "0                 (,)  \n",
       "1                 (,)  \n",
       "2                 (,)  \n",
       "3                 (,)  \n",
       "4                 (,)  \n",
       "...         ...   ...  \n",
       "195608            (,)  \n",
       "195609            (,)  \n",
       "195610            (,)  \n",
       "195611            (,)  \n",
       "195612            (,)  \n",
       "\n",
       "[195613 rows x 13 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_phonemes_test['phonemes'] = single_phonemes_test[\"phonemes\"].apply(convert_phoneme)\n",
    "single_phonemes_train['phonemes'] = single_phonemes_train[\"phonemes\"].apply(convert_phoneme)\n",
    "single_phonemes_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['', 'ʃ', 'i', 'ɦ', 'æ', 'd', 'ɝ', 'ɑ', 'ɹ', 'k', 's', 'u', 'ɪ',\n",
       "       'n', 'g', 'ɡ', 'w', 'ʔ', 'ɔ', 'l', 'j', 'ɚ', 'oʊ', 't', 'ɛ', 'ɔɪ',\n",
       "       'aɪ', 'θ', 'h', 'z', 'p', 'ə', 'b', 'f', 'v', 'm', 'aʊ', 'ʌ', 'eɪ',\n",
       "       'tʃ', 'ʊ', 'dʒ', 'ʒ'], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = pd.unique(single_phonemes_test.phonemes)\n",
    "print(len(tmp))\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n",
      "43\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set, train_labels = get_labels(single_phonemes_train, label=['phonemes'])\n",
    "test_set, test_labels = get_labels(single_phonemes_test, label=['phonemes'])\n",
    "\n",
    "train_labels = train_labels.astype('category')\n",
    "test_labels = test_labels.astype('category')\n",
    "\n",
    "total_labels = train_labels.append(test_labels)\n",
    "print(len(pd.unique(train_labels.phonemes)))\n",
    "print(len(pd.unique(test_labels.phonemes)))\n",
    "total_unique_phonemes = len(pd.unique(total_labels.phonemes))\n",
    "total_unique_phonemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5104\n",
      "2464\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6387"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set, train_labels = get_labels(single_phonemes_train)\n",
    "test_set, test_labels = get_labels(single_phonemes_test)\n",
    "\n",
    "train_labels = train_labels.astype('category')\n",
    "test_labels = test_labels.astype('category')\n",
    "\n",
    "total_labels = train_labels.append(test_labels)\n",
    "print(len(pd.unique(train_labels.words)))\n",
    "print(len(pd.unique(test_labels.words)))\n",
    "total_unique_words = len(pd.unique(total_labels.words))\n",
    "total_unique_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_phonemes_train = skype_data_train.loc[skype_data_train.phonemes.apply(len) == 1].reset_index(drop=True)\n",
    "single_phonemes_test = skype_data_test.loc[skype_data_test.phonemes.apply(len) == 1].reset_index(drop=True)\n",
    "\n",
    "single_phonemes_test['phonemes'] = single_phonemes_test[\"phonemes\"].apply(convert_phoneme)\n",
    "single_phonemes_train['phonemes'] = single_phonemes_train[\"phonemes\"].apply(convert_phoneme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xkadlec6/.local/lib/python3.6/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "train_set, train_labels = get_labels(single_phonemes_train, label=['phonemes'])\n",
    "test_set, test_labels = get_labels(single_phonemes_test, label=['phonemes'])\n",
    "\n",
    "train_labels, test_labels, _ = prepare_labels(train_labels, test_labels, label=['phonemes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(533705, 3)\n",
      "(533705,)\n"
     ]
    }
   ],
   "source": [
    "print(train_set.shape)\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(533705, 43)\n"
     ]
    }
   ],
   "source": [
    "train_labels = to_categorical(train_labels, num_classes=total_unique_phonemes)\n",
    "test_labels = to_categorical(test_labels, num_classes=total_unique_phonemes)\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 43)                11051     \n",
      "=================================================================\n",
      "Total params: 144,427\n",
      "Trainable params: 144,427\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(units=512, activation='relu', input_dim=3*1))  # first hidden layer\n",
    "model.add(Dense(units=256, activation='relu'))  # second hidden layer\n",
    "# model.add(Dense(units=128, activation='relu'))  # third hidden layer\n",
    "model.add(Dense(units=total_unique_phonemes, activation='softmax'))  # output layer\n",
    "# model.add(Dense(units=128))  # output layer\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "2085/2085 [==============================] - 11s 5ms/step - loss: 3.2060 - accuracy: 0.2092\n",
      "Epoch 2/16\n",
      "2085/2085 [==============================] - 10s 5ms/step - loss: 2.8082 - accuracy: 0.2494\n",
      "Epoch 3/16\n",
      "2085/2085 [==============================] - 9s 5ms/step - loss: 2.7872 - accuracy: 0.2518\n",
      "Epoch 4/16\n",
      "2085/2085 [==============================] - 9s 5ms/step - loss: 2.7812 - accuracy: 0.2531\n",
      "Epoch 5/16\n",
      "2085/2085 [==============================] - 10s 5ms/step - loss: 2.7730 - accuracy: 0.2544\n",
      "Epoch 6/16\n",
      "2085/2085 [==============================] - 10s 5ms/step - loss: 2.7687 - accuracy: 0.2558\n",
      "Epoch 7/16\n",
      "2085/2085 [==============================] - 10s 5ms/step - loss: 2.7659 - accuracy: 0.2563\n",
      "Epoch 8/16\n",
      "2085/2085 [==============================] - 10s 5ms/step - loss: 2.7648 - accuracy: 0.2567\n",
      "Epoch 9/16\n",
      "2085/2085 [==============================] - 10s 5ms/step - loss: 2.7625 - accuracy: 0.2563\n",
      "Epoch 10/16\n",
      "2085/2085 [==============================] - 10s 5ms/step - loss: 2.7616 - accuracy: 0.2561\n",
      "Epoch 11/16\n",
      "2085/2085 [==============================] - 9s 5ms/step - loss: 2.7610 - accuracy: 0.2569\n",
      "Epoch 12/16\n",
      "2085/2085 [==============================] - 10s 5ms/step - loss: 2.7586 - accuracy: 0.2571\n",
      "Epoch 13/16\n",
      "2085/2085 [==============================] - 9s 4ms/step - loss: 2.7595 - accuracy: 0.2561\n",
      "Epoch 14/16\n",
      "2085/2085 [==============================] - 9s 4ms/step - loss: 2.7593 - accuracy: 0.2563\n",
      "Epoch 15/16\n",
      "2085/2085 [==============================] - 10s 5ms/step - loss: 2.7575 - accuracy: 0.2568\n",
      "Epoch 16/16\n",
      "2085/2085 [==============================] - 10s 5ms/step - loss: 2.7550 - accuracy: 0.2574\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f2619944048>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_set, train_labels, epochs=16, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6113/6113 [==============================] - 9s 1ms/step - loss: 2.7815 - accuracy: 0.2521\n",
      "test loss, test acc: [2.7815287113189697, 0.2520640194416046]\n"
     ]
    }
   ],
   "source": [
    "print(\"test loss, test acc:\", model.evaluate(test_set, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>previous_packet</th>\n",
       "      <th>packet_size</th>\n",
       "      <th>next_packet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.343137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.271739</td>\n",
       "      <td>0.421569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.343137</td>\n",
       "      <td>0.358696</td>\n",
       "      <td>0.254902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.421569</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.294118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.254902</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.303922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195608</th>\n",
       "      <td>0.392157</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>0.421569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195609</th>\n",
       "      <td>0.450980</td>\n",
       "      <td>0.358696</td>\n",
       "      <td>0.401961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195610</th>\n",
       "      <td>0.421569</td>\n",
       "      <td>0.336957</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195611</th>\n",
       "      <td>0.401961</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.323529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195612</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195613 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        previous_packet  packet_size  next_packet\n",
       "0              0.000000     0.217391     0.343137\n",
       "1              0.294118     0.271739     0.421569\n",
       "2              0.343137     0.358696     0.254902\n",
       "3              0.421569     0.173913     0.294118\n",
       "4              0.254902     0.217391     0.303922\n",
       "...                 ...          ...          ...\n",
       "195608         0.392157     0.391304     0.421569\n",
       "195609         0.450980     0.358696     0.401961\n",
       "195610         0.421569     0.336957     0.333333\n",
       "195611         0.401961     0.260870     0.323529\n",
       "195612         0.333333     0.250000     0.000000\n",
       "\n",
       "[195613 rows x 3 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "train_set[[\"previous_packet\", \"next_packet\", \"packet_size\"]] = scaler.fit_transform(train_set[[\"previous_packet\", \"next_packet\", \"packet_size\"]])\n",
    "test_set[[\"previous_packet\", \"next_packet\", \"packet_size\"]] = scaler.transform(test_set[[\"previous_packet\", \"next_packet\", \"packet_size\"]])\n",
    "test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 43)                11051     \n",
      "=================================================================\n",
      "Total params: 144,427\n",
      "Trainable params: 144,427\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(units=512, activation='relu', input_dim=3*1))  # first hidden layer\n",
    "model.add(Dense(units=256, activation='relu'))  # second hidden layer\n",
    "# model.add(Dense(units=128, activation='relu'))  # third hidden layer\n",
    "model.add(Dense(units=total_unique_phonemes, activation='softmax'))  # output layer\n",
    "# model.add(Dense(units=128))  # output layer\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "2085/2085 [==============================] - 10s 5ms/step - loss: 2.9338 - accuracy: 0.2338\n",
      "Epoch 2/16\n",
      "2085/2085 [==============================] - 9s 5ms/step - loss: 2.7836 - accuracy: 0.2525\n",
      "Epoch 3/16\n",
      "2085/2085 [==============================] - 10s 5ms/step - loss: 2.7717 - accuracy: 0.2547\n",
      "Epoch 4/16\n",
      "2085/2085 [==============================] - 10s 5ms/step - loss: 2.7625 - accuracy: 0.2576\n",
      "Epoch 5/16\n",
      "2085/2085 [==============================] - 10s 5ms/step - loss: 2.7586 - accuracy: 0.2575\n",
      "Epoch 6/16\n",
      "2085/2085 [==============================] - 10s 5ms/step - loss: 2.7552 - accuracy: 0.2573\n",
      "Epoch 7/16\n",
      "2085/2085 [==============================] - 10s 5ms/step - loss: 2.7536 - accuracy: 0.2579\n",
      "Epoch 8/16\n",
      "2085/2085 [==============================] - 10s 5ms/step - loss: 2.7523 - accuracy: 0.2587\n",
      "Epoch 9/16\n",
      "2085/2085 [==============================] - 10s 5ms/step - loss: 2.7507 - accuracy: 0.2587\n",
      "Epoch 10/16\n",
      "2085/2085 [==============================] - 10s 5ms/step - loss: 2.7444 - accuracy: 0.2603\n",
      "Epoch 11/16\n",
      "2085/2085 [==============================] - 10s 5ms/step - loss: 2.7491 - accuracy: 0.2591\n",
      "Epoch 12/16\n",
      "2085/2085 [==============================] - 10s 5ms/step - loss: 2.7508 - accuracy: 0.2586\n",
      "Epoch 13/16\n",
      "2085/2085 [==============================] - 10s 5ms/step - loss: 2.7514 - accuracy: 0.2581\n",
      "Epoch 14/16\n",
      "2085/2085 [==============================] - 9s 5ms/step - loss: 2.7499 - accuracy: 0.2587\n",
      "Epoch 15/16\n",
      "2085/2085 [==============================] - 10s 5ms/step - loss: 2.7487 - accuracy: 0.2592\n",
      "Epoch 16/16\n",
      "2085/2085 [==============================] - 10s 5ms/step - loss: 2.7469 - accuracy: 0.2593\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f26199bbc50>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_set, train_labels, epochs=16, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6113/6113 [==============================] - 8s 1ms/step - loss: 2.7804 - accuracy: 0.2518\n",
      "test loss, test acc: [2.7804369926452637, 0.25184932351112366]\n"
     ]
    }
   ],
   "source": [
    "print(\"test loss, test acc:\", model.evaluate(test_set, test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_lstm = Sequential()\n",
    "# model_lstm.add(LSTM(256, input_shape = (1, 3)))\n",
    "# model_lstm.add(Dense(units=total_unique_words))\n",
    "# model_lstm.compile(loss='categorical_crossentropy',\n",
    "#               optimizer='adam',\n",
    "#               metrics=['accuracy']\n",
    "#              )\n",
    "\n",
    "# model_lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Embedding\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import SpatialDropout1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 256)               266240    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 43)                11051     \n",
      "=================================================================\n",
      "Total params: 343,083\n",
      "Trainable params: 343,083\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#more elaborate model\n",
    "model_lstm = Sequential()\n",
    "\n",
    "#model_lstm.add(Embedding(input_dim = 3, output_dim = 2, input_length = 86497))\n",
    "#model_lstm.add(SpatialDropout1D(0.3))\n",
    "model_lstm.add(LSTM(256, input_shape = (1, 3), dropout = 0.3, recurrent_dropout = 0.3))\n",
    "model_lstm.add(Dense(256, activation = 'relu'))\n",
    "model_lstm.add(Dropout(0.3))\n",
    "model_lstm.add(Dense(total_unique_phonemes, activation = 'softmax'))\n",
    "\n",
    "model_lstm.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='Adam',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model_lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_phonemes_train = skype_data_train.loc[skype_data_train.phonemes.apply(len) == 1].reset_index(drop=True)\n",
    "single_phonemes_test = skype_data_test.loc[skype_data_test.phonemes.apply(len) == 1].reset_index(drop=True)\n",
    "\n",
    "single_phonemes_test['phonemes'] = single_phonemes_test[\"phonemes\"].apply(convert_phoneme)\n",
    "single_phonemes_train['phonemes'] = single_phonemes_train[\"phonemes\"].apply(convert_phoneme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xkadlec6/.local/lib/python3.6/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "train_set, train_labels = get_labels(single_phonemes_train, label=['phonemes'])\n",
    "test_set, test_labels = get_labels(single_phonemes_test, label=['phonemes'])\n",
    "\n",
    "train_labels, test_labels, _ = prepare_labels(train_labels, test_labels, label=['phonemes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(533705, 43)\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "train_labels = to_categorical(train_labels, num_classes=total_unique_phonemes)\n",
    "test_labels = to_categorical(test_labels, num_classes=total_unique_phonemes)\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0, 32, 32])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshaped_values = train_set.values.reshape(-1, 1, 3)\n",
    "reshaped_values[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "4170/4170 [==============================] - 28s 6ms/step - loss: 3.0098 - accuracy: 0.2207\n",
      "Epoch 2/16\n",
      "4170/4170 [==============================] - 24s 6ms/step - loss: 2.8634 - accuracy: 0.2403\n",
      "Epoch 3/16\n",
      "4170/4170 [==============================] - 24s 6ms/step - loss: 2.8541 - accuracy: 0.2405\n",
      "Epoch 4/16\n",
      "4170/4170 [==============================] - 24s 6ms/step - loss: 2.8472 - accuracy: 0.2423\n",
      "Epoch 5/16\n",
      "4170/4170 [==============================] - 24s 6ms/step - loss: 2.8406 - accuracy: 0.2439\n",
      "Epoch 6/16\n",
      "4170/4170 [==============================] - 25s 6ms/step - loss: 2.8352 - accuracy: 0.2448\n",
      "Epoch 7/16\n",
      "4170/4170 [==============================] - 26s 6ms/step - loss: 2.8292 - accuracy: 0.2459\n",
      "Epoch 8/16\n",
      "4170/4170 [==============================] - 28s 7ms/step - loss: 2.8279 - accuracy: 0.2457\n",
      "Epoch 9/16\n",
      "4170/4170 [==============================] - 25s 6ms/step - loss: 2.8281 - accuracy: 0.2463\n",
      "Epoch 10/16\n",
      "4170/4170 [==============================] - 26s 6ms/step - loss: 2.8267 - accuracy: 0.2455\n",
      "Epoch 11/16\n",
      "4170/4170 [==============================] - 24s 6ms/step - loss: 2.8269 - accuracy: 0.2457\n",
      "Epoch 12/16\n",
      "4170/4170 [==============================] - 25s 6ms/step - loss: 2.8262 - accuracy: 0.2461\n",
      "Epoch 13/16\n",
      "4170/4170 [==============================] - 26s 6ms/step - loss: 2.8247 - accuracy: 0.2462\n",
      "Epoch 14/16\n",
      "4170/4170 [==============================] - 25s 6ms/step - loss: 2.8228 - accuracy: 0.2462\n",
      "Epoch 15/16\n",
      "4170/4170 [==============================] - 25s 6ms/step - loss: 2.8201 - accuracy: 0.2473\n",
      "Epoch 16/16\n",
      "4170/4170 [==============================] - 24s 6ms/step - loss: 2.8201 - accuracy: 0.2473\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8ca99835c0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lstm.fit(reshaped_values, train_labels, epochs=16, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6113/6113 [==============================] - 13s 2ms/step - loss: 4.3564 - accuracy: 0.1769\n",
      "test loss, test acc: [4.356447696685791, 0.17691053450107574]\n"
     ]
    }
   ],
   "source": [
    "print(\"test loss, test acc:\", model_lstm.evaluate(test_set.values.reshape(-1, 1, 3), test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>previous_packet</th>\n",
       "      <th>packet_size</th>\n",
       "      <th>next_packet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.343137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.271739</td>\n",
       "      <td>0.421569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.343137</td>\n",
       "      <td>0.358696</td>\n",
       "      <td>0.254902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.421569</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.294118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.254902</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.303922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195608</th>\n",
       "      <td>0.392157</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>0.421569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195609</th>\n",
       "      <td>0.450980</td>\n",
       "      <td>0.358696</td>\n",
       "      <td>0.401961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195610</th>\n",
       "      <td>0.421569</td>\n",
       "      <td>0.336957</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195611</th>\n",
       "      <td>0.401961</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.323529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195612</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195613 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        previous_packet  packet_size  next_packet\n",
       "0              0.000000     0.217391     0.343137\n",
       "1              0.294118     0.271739     0.421569\n",
       "2              0.343137     0.358696     0.254902\n",
       "3              0.421569     0.173913     0.294118\n",
       "4              0.254902     0.217391     0.303922\n",
       "...                 ...          ...          ...\n",
       "195608         0.392157     0.391304     0.421569\n",
       "195609         0.450980     0.358696     0.401961\n",
       "195610         0.421569     0.336957     0.333333\n",
       "195611         0.401961     0.260870     0.323529\n",
       "195612         0.333333     0.250000     0.000000\n",
       "\n",
       "[195613 rows x 3 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "train_set[[\"previous_packet\", \"next_packet\", \"packet_size\"]] = scaler.fit_transform(train_set[[\"previous_packet\", \"next_packet\", \"packet_size\"]])\n",
    "test_set[[\"previous_packet\", \"next_packet\", \"packet_size\"]] = scaler.transform(test_set[[\"previous_packet\", \"next_packet\", \"packet_size\"]])\n",
    "test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (None, 256)               266240    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 43)                11051     \n",
      "=================================================================\n",
      "Total params: 343,083\n",
      "Trainable params: 343,083\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#more elaborate model\n",
    "model_lstm = Sequential()\n",
    "\n",
    "#model_lstm.add(Embedding(input_dim = 3, output_dim = 2, input_length = 86497))\n",
    "#model_lstm.add(SpatialDropout1D(0.3))\n",
    "model_lstm.add(LSTM(256, input_shape = (1, 3), dropout = 0.3, recurrent_dropout = 0.3))\n",
    "model_lstm.add(Dense(256, activation = 'relu'))\n",
    "model_lstm.add(Dropout(0.3))\n",
    "model_lstm.add(Dense(total_unique_phonemes, activation = 'softmax'))\n",
    "\n",
    "model_lstm.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='Adam',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model_lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.23913043, 0.31372549])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshaped_values = train_set.values.reshape(-1, 1, 3)\n",
    "reshaped_values[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "4170/4170 [==============================] - 28s 6ms/step - loss: 3.1329 - accuracy: 0.2100\n",
      "Epoch 2/16\n",
      "4170/4170 [==============================] - 25s 6ms/step - loss: 2.9663 - accuracy: 0.2297\n",
      "Epoch 3/16\n",
      "4170/4170 [==============================] - 27s 6ms/step - loss: 2.9388 - accuracy: 0.2318\n",
      "Epoch 4/16\n",
      "4170/4170 [==============================] - 24s 6ms/step - loss: 2.9156 - accuracy: 0.2343\n",
      "Epoch 5/16\n",
      "4170/4170 [==============================] - 24s 6ms/step - loss: 2.9051 - accuracy: 0.2365\n",
      "Epoch 6/16\n",
      "4170/4170 [==============================] - 24s 6ms/step - loss: 2.8884 - accuracy: 0.2375\n",
      "Epoch 7/16\n",
      "4170/4170 [==============================] - 24s 6ms/step - loss: 2.8732 - accuracy: 0.2402\n",
      "Epoch 8/16\n",
      "4170/4170 [==============================] - 26s 6ms/step - loss: 2.8576 - accuracy: 0.2415\n",
      "Epoch 9/16\n",
      "4170/4170 [==============================] - 24s 6ms/step - loss: 2.8467 - accuracy: 0.2426\n",
      "Epoch 10/16\n",
      "4170/4170 [==============================] - 25s 6ms/step - loss: 2.8349 - accuracy: 0.2444\n",
      "Epoch 11/16\n",
      "4170/4170 [==============================] - 25s 6ms/step - loss: 2.8284 - accuracy: 0.2452\n",
      "Epoch 12/16\n",
      "4170/4170 [==============================] - 27s 7ms/step - loss: 2.8249 - accuracy: 0.2451\n",
      "Epoch 13/16\n",
      "4170/4170 [==============================] - 25s 6ms/step - loss: 2.8216 - accuracy: 0.2458\n",
      "Epoch 14/16\n",
      "4170/4170 [==============================] - 25s 6ms/step - loss: 2.8190 - accuracy: 0.2468\n",
      "Epoch 15/16\n",
      "4170/4170 [==============================] - 25s 6ms/step - loss: 2.8152 - accuracy: 0.2473\n",
      "Epoch 16/16\n",
      "4170/4170 [==============================] - 24s 6ms/step - loss: 2.8131 - accuracy: 0.2471\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8ca9bc4f28>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lstm.fit(reshaped_values, train_labels, epochs=16, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6113/6113 [==============================] - 12s 2ms/step - loss: 4.7506 - accuracy: 0.1772\n",
      "test loss, test acc: [4.750559329986572, 0.17720703780651093]\n"
     ]
    }
   ],
   "source": [
    "print(\"test loss, test acc:\", model_lstm.evaluate(test_set.values.reshape(-1, 1, 3), test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KFold crossvalidation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(output_size):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(units=512, activation='relu', input_dim=3*1))  # first hidden layer\n",
    "    model.add(Dense(units=256, activation='relu'))  # second hidden layer\n",
    "    model.add(Dense(units=output_size, activation='softmax'))  # output layer\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_phonemes_train = skype_data_train.loc[skype_data_train.phonemes.apply(len) == 1].reset_index(drop=True)\n",
    "single_phonemes_test = skype_data_test.loc[skype_data_test.phonemes.apply(len) == 1].reset_index(drop=True)\n",
    "\n",
    "single_phonemes_test['phonemes'] = single_phonemes_test[\"phonemes\"].apply(convert_phoneme)\n",
    "single_phonemes_train['phonemes'] = single_phonemes_train[\"phonemes\"].apply(convert_phoneme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xkadlec6/.local/lib/python3.6/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "train_set, train_labels = get_labels(single_phonemes_train, label=['phonemes'])\n",
    "test_set, test_labels = get_labels(single_phonemes_test, label=['phonemes'])\n",
    "\n",
    "train_labels, test_labels, _ = prepare_labels(train_labels, test_labels, label=['phonemes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "train_set[[\"previous_packet\", \"next_packet\", \"packet_size\"]] = scaler.fit_transform(train_set[[\"previous_packet\", \"next_packet\", \"packet_size\"]])\n",
    "test_set[[\"previous_packet\", \"next_packet\", \"packet_size\"]] = scaler.transform(test_set[[\"previous_packet\", \"next_packet\", \"packet_size\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(533705, 43)\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "train_labels = to_categorical(train_labels, num_classes=total_unique_phonemes)\n",
    "test_labels = to_categorical(test_labels, num_classes=total_unique_phonemes)\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now validating on dialect: DR1\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_24 (Dense)             (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 43)                11051     \n",
      "=================================================================\n",
      "Total params: 144,427\n",
      "Trainable params: 144,427\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1916/1916 [==============================] - 9s 4ms/step - loss: 2.9524 - accuracy: 0.2304\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8b45ae0048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1352/1352 [==============================] - 2s 1ms/step - loss: 2.7844 - accuracy: 0.2584\n",
      "test loss, test acc: [2.78438138961792, 0.2584441006183624]\n",
      "Now validating on dialect: DR2\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_27 (Dense)             (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 43)                11051     \n",
      "=================================================================\n",
      "Total params: 144,427\n",
      "Trainable params: 144,427\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1750/1750 [==============================] - 8s 4ms/step - loss: 2.9564 - accuracy: 0.2298\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8b45a59eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2682/2682 [==============================] - 4s 1ms/step - loss: 2.7862 - accuracy: 0.2531\n",
      "test loss, test acc: [2.7862300872802734, 0.25312885642051697]\n",
      "Now validating on dialect: DR3\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_30 (Dense)             (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 43)                11051     \n",
      "=================================================================\n",
      "Total params: 144,427\n",
      "Trainable params: 144,427\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1749/1749 [==============================] - 8s 4ms/step - loss: 2.9626 - accuracy: 0.2292\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8b459d75f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2688/2688 [==============================] - 4s 1ms/step - loss: 2.7923 - accuracy: 0.2489\n",
      "test loss, test acc: [2.7923102378845215, 0.24886325001716614]\n",
      "Now validating on dialect: DR4\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_33 (Dense)             (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 43)                11051     \n",
      "=================================================================\n",
      "Total params: 144,427\n",
      "Trainable params: 144,427\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1771/1771 [==============================] - 8s 4ms/step - loss: 2.9459 - accuracy: 0.2322\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8b459485c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2517/2517 [==============================] - 4s 1ms/step - loss: 2.8334 - accuracy: 0.2345\n",
      "test loss, test acc: [2.833430767059326, 0.23450443148612976]\n",
      "Now validating on dialect: DR5\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_36 (Dense)             (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 43)                11051     \n",
      "=================================================================\n",
      "Total params: 144,427\n",
      "Trainable params: 144,427\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1748/1748 [==============================] - 8s 4ms/step - loss: 2.9550 - accuracy: 0.2303\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8b45b16b38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2701/2701 [==============================] - 4s 2ms/step - loss: 2.8149 - accuracy: 0.2482\n",
      "test loss, test acc: [2.814870595932007, 0.24815744161605835]\n",
      "Now validating on dialect: DR6\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_39 (Dense)             (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 43)                11051     \n",
      "=================================================================\n",
      "Total params: 144,427\n",
      "Trainable params: 144,427\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1923/1923 [==============================] - 9s 5ms/step - loss: 2.9490 - accuracy: 0.2302\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8b45bb3a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1295/1295 [==============================] - 2s 1ms/step - loss: 2.7960 - accuracy: 0.2525\n",
      "test loss, test acc: [2.795966863632202, 0.25247427821159363]\n",
      "Now validating on dialect: DR7\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_42 (Dense)             (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 43)                11051     \n",
      "=================================================================\n",
      "Total params: 144,427\n",
      "Trainable params: 144,427\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1747/1747 [==============================] - 8s 4ms/step - loss: 2.9548 - accuracy: 0.2278\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8b45bf2eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2707/2707 [==============================] - 4s 1ms/step - loss: 2.7659 - accuracy: 0.2557\n",
      "test loss, test acc: [2.7658674716949463, 0.2556726932525635]\n",
      "Now validating on dialect: DR8\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_45 (Dense)             (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 43)                11051     \n",
      "=================================================================\n",
      "Total params: 144,427\n",
      "Trainable params: 144,427\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1993/1993 [==============================] - 10s 5ms/step - loss: 2.9443 - accuracy: 0.2314\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8b45ce61d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "740/740 [==============================] - 1s 1ms/step - loss: 2.7727 - accuracy: 0.2582\n",
      "test loss, test acc: [2.7726612091064453, 0.2581544816493988]\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "dialects = pd.unique(skype_data_train.dialect)\n",
    "for dialect in dialects:\n",
    "    print(\"Now validating on dialect:\", dialect)\n",
    "    \n",
    "    set_train = train_set.loc[single_phonemes_train[\"dialect\"] != dialect]\n",
    "    label_train = train_labels[single_phonemes_train[\"dialect\"] != dialect]\n",
    "    \n",
    "    validation_set = train_set.loc[single_phonemes_train[\"dialect\"] == dialect]\n",
    "    validation_labels = train_labels[single_phonemes_train[\"dialect\"] == dialect]\n",
    "    \n",
    "    model = create_model(total_unique_phonemes)\n",
    "    \n",
    "    display(model.fit(set_train, label_train, epochs=1, batch_size=256))\n",
    "    \n",
    "    print(\"test loss, test acc:\", model.evaluate(validation_set, validation_labels))\n",
    "print(\"\\nDone!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
