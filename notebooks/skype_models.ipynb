{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replication of attack on VoIP end-to-end encrypted messengers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now try to explore various models on `skype` dataset. Bellow we will find loading and preprocessing that we have come up with in the analysis section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "sns.set()  # make plots nicer\n",
    "\n",
    "np.random.seed(42)  # set seed for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_parser_with_prev_next(path):\n",
    "    file = open(path, 'r')\n",
    "    lines = file.readlines()\n",
    "    \n",
    "    file_name = [path.split('/')[-1]]\n",
    "    sentence = \"\"\n",
    "    file_data = []\n",
    "    \n",
    "    has_value = False\n",
    "    previous = 0\n",
    "    \n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        \n",
    "        # if there are only 2 informations on line and second is h#, then ignore\n",
    "        # strip line, split primarly on ; secondary on ,\n",
    "        if (line.startswith('#')):\n",
    "            if (not sentence):\n",
    "                sentence = line[len('# Sentence: \"'): len(line) - 1]\n",
    "            continue\n",
    "        \n",
    "        line = line.split(';')\n",
    "        \n",
    "        if (len(line) == 1):\n",
    "            #lines containing only their packet size and nothing else, they should be added\n",
    "            #TODO\n",
    "            line += [\"\"]\n",
    "            line += [\"\"]\n",
    "            #continue\n",
    "        \n",
    "        if (len(line) == 2):\n",
    "            #this tries to remove most of the silence at the start of the recording\n",
    "            #potentionally harmfull as we shouldn't clean test data this way (we will be reading labels)\n",
    "            #if (line[1] == 'h#'):\n",
    "            #    continue\n",
    "            line += [\"\"]\n",
    "        \n",
    "        line[1] = tuple(line[1].split(','))\n",
    "        line[2] = tuple(list(map(lambda a: a.strip('\"'), line[2].split(','))))\n",
    "        \n",
    "        if (has_value):\n",
    "            file_data[-1][-4] = line[0]\n",
    "           \n",
    "        # file_type and sentence contain duplicate informations, but are kept for readability\n",
    "        split_filename = file_name[0].split('-')\n",
    "        \n",
    "        line = file_name + [split_filename[0]] + [split_filename[1]] + [split_filename[2][0:-4]] + [sentence] + [previous] + [0] + line\n",
    "        #adding previous as feature\n",
    "        previous = line[-3]\n",
    "        file_data += [line]\n",
    "        \n",
    "        #adding next frame as feature\n",
    "        has_value = True\n",
    "        \n",
    "    return pd.DataFrame(file_data, columns=['file', 'dialect', 'speaker', 'sentence_id', 'sentence', 'previous_packet', 'next_packet','packet_size', 'phonemes', 'words'])\n",
    "\n",
    "def load_files_with_prev_next(directory):\n",
    "    filelist = os.listdir(directory)\n",
    "    #read them into pandas\n",
    "    df_list = [file_parser_with_prev_next(directory+file) for file in filelist]\n",
    "    #concatenate them together\n",
    "    return pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "def convert_types(data_frame):\n",
    "    data_frame['packet_size'] = pd.to_numeric(data_frame['packet_size'])\n",
    "    data_frame['previous_packet'] = pd.to_numeric(data_frame['previous_packet'])\n",
    "    data_frame['next_packet'] = pd.to_numeric(data_frame['next_packet'])\n",
    "\n",
    "    data_frame['file'] = data_frame['file'].astype('category')\n",
    "    data_frame['sentence'] = data_frame['sentence'].astype('category')\n",
    "    \n",
    "    data_frame['dialect'] = data_frame['dialect'].astype('category')\n",
    "    data_frame['speaker'] = data_frame['speaker'].astype('category')\n",
    "    data_frame['sentence_id'] = data_frame['sentence_id'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>dialect</th>\n",
       "      <th>speaker</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>previous_packet</th>\n",
       "      <th>next_packet</th>\n",
       "      <th>packet_size</th>\n",
       "      <th>phonemes</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DR1-FAKS0-SA1.CSV</td>\n",
       "      <td>DR1</td>\n",
       "      <td>FAKS0</td>\n",
       "      <td>SA1</td>\n",
       "      <td>She had your dark suit in greasy wash water al...</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>30</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DR1-FAKS0-SA1.CSV</td>\n",
       "      <td>DR1</td>\n",
       "      <td>FAKS0</td>\n",
       "      <td>SA1</td>\n",
       "      <td>She had your dark suit in greasy wash water al...</td>\n",
       "      <td>30</td>\n",
       "      <td>43</td>\n",
       "      <td>35</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DR1-FAKS0-SA1.CSV</td>\n",
       "      <td>DR1</td>\n",
       "      <td>FAKS0</td>\n",
       "      <td>SA1</td>\n",
       "      <td>She had your dark suit in greasy wash water al...</td>\n",
       "      <td>35</td>\n",
       "      <td>26</td>\n",
       "      <td>43</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DR1-FAKS0-SA1.CSV</td>\n",
       "      <td>DR1</td>\n",
       "      <td>FAKS0</td>\n",
       "      <td>SA1</td>\n",
       "      <td>She had your dark suit in greasy wash water al...</td>\n",
       "      <td>43</td>\n",
       "      <td>30</td>\n",
       "      <td>26</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DR1-FAKS0-SA1.CSV</td>\n",
       "      <td>DR1</td>\n",
       "      <td>FAKS0</td>\n",
       "      <td>SA1</td>\n",
       "      <td>She had your dark suit in greasy wash water al...</td>\n",
       "      <td>26</td>\n",
       "      <td>31</td>\n",
       "      <td>30</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258516</th>\n",
       "      <td>DR8-MSLB0-SX383.CSV</td>\n",
       "      <td>DR8</td>\n",
       "      <td>MSLB0</td>\n",
       "      <td>SX383</td>\n",
       "      <td>The carpet cleaners shampooed our oriental rug.</td>\n",
       "      <td>40</td>\n",
       "      <td>43</td>\n",
       "      <td>46</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258517</th>\n",
       "      <td>DR8-MSLB0-SX383.CSV</td>\n",
       "      <td>DR8</td>\n",
       "      <td>MSLB0</td>\n",
       "      <td>SX383</td>\n",
       "      <td>The carpet cleaners shampooed our oriental rug.</td>\n",
       "      <td>46</td>\n",
       "      <td>41</td>\n",
       "      <td>43</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258518</th>\n",
       "      <td>DR8-MSLB0-SX383.CSV</td>\n",
       "      <td>DR8</td>\n",
       "      <td>MSLB0</td>\n",
       "      <td>SX383</td>\n",
       "      <td>The carpet cleaners shampooed our oriental rug.</td>\n",
       "      <td>43</td>\n",
       "      <td>34</td>\n",
       "      <td>41</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258519</th>\n",
       "      <td>DR8-MSLB0-SX383.CSV</td>\n",
       "      <td>DR8</td>\n",
       "      <td>MSLB0</td>\n",
       "      <td>SX383</td>\n",
       "      <td>The carpet cleaners shampooed our oriental rug.</td>\n",
       "      <td>41</td>\n",
       "      <td>33</td>\n",
       "      <td>34</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258520</th>\n",
       "      <td>DR8-MSLB0-SX383.CSV</td>\n",
       "      <td>DR8</td>\n",
       "      <td>MSLB0</td>\n",
       "      <td>SX383</td>\n",
       "      <td>The carpet cleaners shampooed our oriental rug.</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>258521 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       file dialect speaker sentence_id  \\\n",
       "0         DR1-FAKS0-SA1.CSV     DR1   FAKS0         SA1   \n",
       "1         DR1-FAKS0-SA1.CSV     DR1   FAKS0         SA1   \n",
       "2         DR1-FAKS0-SA1.CSV     DR1   FAKS0         SA1   \n",
       "3         DR1-FAKS0-SA1.CSV     DR1   FAKS0         SA1   \n",
       "4         DR1-FAKS0-SA1.CSV     DR1   FAKS0         SA1   \n",
       "...                     ...     ...     ...         ...   \n",
       "258516  DR8-MSLB0-SX383.CSV     DR8   MSLB0       SX383   \n",
       "258517  DR8-MSLB0-SX383.CSV     DR8   MSLB0       SX383   \n",
       "258518  DR8-MSLB0-SX383.CSV     DR8   MSLB0       SX383   \n",
       "258519  DR8-MSLB0-SX383.CSV     DR8   MSLB0       SX383   \n",
       "258520  DR8-MSLB0-SX383.CSV     DR8   MSLB0       SX383   \n",
       "\n",
       "                                                 sentence  previous_packet  \\\n",
       "0       She had your dark suit in greasy wash water al...                0   \n",
       "1       She had your dark suit in greasy wash water al...               30   \n",
       "2       She had your dark suit in greasy wash water al...               35   \n",
       "3       She had your dark suit in greasy wash water al...               43   \n",
       "4       She had your dark suit in greasy wash water al...               26   \n",
       "...                                                   ...              ...   \n",
       "258516    The carpet cleaners shampooed our oriental rug.               40   \n",
       "258517    The carpet cleaners shampooed our oriental rug.               46   \n",
       "258518    The carpet cleaners shampooed our oriental rug.               43   \n",
       "258519    The carpet cleaners shampooed our oriental rug.               41   \n",
       "258520    The carpet cleaners shampooed our oriental rug.               34   \n",
       "\n",
       "        next_packet  packet_size phonemes words  \n",
       "0                35           30    (h#,)   (,)  \n",
       "1                43           35    (h#,)   (,)  \n",
       "2                26           43    (h#,)   (,)  \n",
       "3                30           26    (h#,)   (,)  \n",
       "4                31           30    (h#,)   (,)  \n",
       "...             ...          ...      ...   ...  \n",
       "258516           43           46    (h#,)   (,)  \n",
       "258517           41           43    (h#,)   (,)  \n",
       "258518           34           41    (h#,)   (,)  \n",
       "258519           33           34    (h#,)   (,)  \n",
       "258520            0           33    (h#,)   (,)  \n",
       "\n",
       "[258521 rows x 10 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skype_data_train = load_files_with_prev_next(\"./../data/skype_train_data/\")\n",
    "skype_data_test = load_files_with_prev_next(\"./../data/skype_test_data/\")\n",
    "convert_types(skype_data_train)\n",
    "convert_types(skype_data_test)\n",
    "skype_data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>dialect</th>\n",
       "      <th>speaker</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>previous_packet</th>\n",
       "      <th>next_packet</th>\n",
       "      <th>packet_size</th>\n",
       "      <th>prev_curr</th>\n",
       "      <th>next_curr</th>\n",
       "      <th>packet_surrounding</th>\n",
       "      <th>phonemes</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DR1-FCJF0-SA1.CSV</td>\n",
       "      <td>DR1</td>\n",
       "      <td>FCJF0</td>\n",
       "      <td>SA1</td>\n",
       "      <td>She had your dark suit in greasy wash water al...</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>(0, 32)</td>\n",
       "      <td>(32, 32)</td>\n",
       "      <td>(0, 32, 32)</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DR1-FCJF0-SA1.CSV</td>\n",
       "      <td>DR1</td>\n",
       "      <td>FCJF0</td>\n",
       "      <td>SA1</td>\n",
       "      <td>She had your dark suit in greasy wash water al...</td>\n",
       "      <td>32</td>\n",
       "      <td>31</td>\n",
       "      <td>32</td>\n",
       "      <td>(32, 32)</td>\n",
       "      <td>(31, 32)</td>\n",
       "      <td>(32, 32, 31)</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DR1-FCJF0-SA1.CSV</td>\n",
       "      <td>DR1</td>\n",
       "      <td>FCJF0</td>\n",
       "      <td>SA1</td>\n",
       "      <td>She had your dark suit in greasy wash water al...</td>\n",
       "      <td>32</td>\n",
       "      <td>28</td>\n",
       "      <td>31</td>\n",
       "      <td>(32, 31)</td>\n",
       "      <td>(28, 31)</td>\n",
       "      <td>(32, 31, 28)</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DR1-FCJF0-SA1.CSV</td>\n",
       "      <td>DR1</td>\n",
       "      <td>FCJF0</td>\n",
       "      <td>SA1</td>\n",
       "      <td>She had your dark suit in greasy wash water al...</td>\n",
       "      <td>31</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>(31, 28)</td>\n",
       "      <td>(28, 28)</td>\n",
       "      <td>(31, 28, 28)</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DR1-FCJF0-SA1.CSV</td>\n",
       "      <td>DR1</td>\n",
       "      <td>FCJF0</td>\n",
       "      <td>SA1</td>\n",
       "      <td>She had your dark suit in greasy wash water al...</td>\n",
       "      <td>28</td>\n",
       "      <td>36</td>\n",
       "      <td>28</td>\n",
       "      <td>(28, 28)</td>\n",
       "      <td>(36, 28)</td>\n",
       "      <td>(28, 28, 36)</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707433</th>\n",
       "      <td>DR8-MTCS0-SX82.CSV</td>\n",
       "      <td>DR8</td>\n",
       "      <td>MTCS0</td>\n",
       "      <td>SX82</td>\n",
       "      <td>Good service should be rewarded by big tips.</td>\n",
       "      <td>47</td>\n",
       "      <td>34</td>\n",
       "      <td>32</td>\n",
       "      <td>(47, 32)</td>\n",
       "      <td>(34, 32)</td>\n",
       "      <td>(47, 32, 34)</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707434</th>\n",
       "      <td>DR8-MTCS0-SX82.CSV</td>\n",
       "      <td>DR8</td>\n",
       "      <td>MTCS0</td>\n",
       "      <td>SX82</td>\n",
       "      <td>Good service should be rewarded by big tips.</td>\n",
       "      <td>32</td>\n",
       "      <td>39</td>\n",
       "      <td>34</td>\n",
       "      <td>(32, 34)</td>\n",
       "      <td>(39, 34)</td>\n",
       "      <td>(32, 34, 39)</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707435</th>\n",
       "      <td>DR8-MTCS0-SX82.CSV</td>\n",
       "      <td>DR8</td>\n",
       "      <td>MTCS0</td>\n",
       "      <td>SX82</td>\n",
       "      <td>Good service should be rewarded by big tips.</td>\n",
       "      <td>34</td>\n",
       "      <td>33</td>\n",
       "      <td>39</td>\n",
       "      <td>(34, 39)</td>\n",
       "      <td>(33, 39)</td>\n",
       "      <td>(34, 39, 33)</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707436</th>\n",
       "      <td>DR8-MTCS0-SX82.CSV</td>\n",
       "      <td>DR8</td>\n",
       "      <td>MTCS0</td>\n",
       "      <td>SX82</td>\n",
       "      <td>Good service should be rewarded by big tips.</td>\n",
       "      <td>39</td>\n",
       "      <td>36</td>\n",
       "      <td>33</td>\n",
       "      <td>(39, 33)</td>\n",
       "      <td>(36, 33)</td>\n",
       "      <td>(39, 33, 36)</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707437</th>\n",
       "      <td>DR8-MTCS0-SX82.CSV</td>\n",
       "      <td>DR8</td>\n",
       "      <td>MTCS0</td>\n",
       "      <td>SX82</td>\n",
       "      <td>Good service should be rewarded by big tips.</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>(33, 36)</td>\n",
       "      <td>(0, 36)</td>\n",
       "      <td>(33, 36, 0)</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>707438 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      file dialect speaker sentence_id  \\\n",
       "0        DR1-FCJF0-SA1.CSV     DR1   FCJF0         SA1   \n",
       "1        DR1-FCJF0-SA1.CSV     DR1   FCJF0         SA1   \n",
       "2        DR1-FCJF0-SA1.CSV     DR1   FCJF0         SA1   \n",
       "3        DR1-FCJF0-SA1.CSV     DR1   FCJF0         SA1   \n",
       "4        DR1-FCJF0-SA1.CSV     DR1   FCJF0         SA1   \n",
       "...                    ...     ...     ...         ...   \n",
       "707433  DR8-MTCS0-SX82.CSV     DR8   MTCS0        SX82   \n",
       "707434  DR8-MTCS0-SX82.CSV     DR8   MTCS0        SX82   \n",
       "707435  DR8-MTCS0-SX82.CSV     DR8   MTCS0        SX82   \n",
       "707436  DR8-MTCS0-SX82.CSV     DR8   MTCS0        SX82   \n",
       "707437  DR8-MTCS0-SX82.CSV     DR8   MTCS0        SX82   \n",
       "\n",
       "                                                 sentence  previous_packet  \\\n",
       "0       She had your dark suit in greasy wash water al...                0   \n",
       "1       She had your dark suit in greasy wash water al...               32   \n",
       "2       She had your dark suit in greasy wash water al...               32   \n",
       "3       She had your dark suit in greasy wash water al...               31   \n",
       "4       She had your dark suit in greasy wash water al...               28   \n",
       "...                                                   ...              ...   \n",
       "707433       Good service should be rewarded by big tips.               47   \n",
       "707434       Good service should be rewarded by big tips.               32   \n",
       "707435       Good service should be rewarded by big tips.               34   \n",
       "707436       Good service should be rewarded by big tips.               39   \n",
       "707437       Good service should be rewarded by big tips.               33   \n",
       "\n",
       "        next_packet  packet_size prev_curr next_curr packet_surrounding  \\\n",
       "0                32           32   (0, 32)  (32, 32)        (0, 32, 32)   \n",
       "1                31           32  (32, 32)  (31, 32)       (32, 32, 31)   \n",
       "2                28           31  (32, 31)  (28, 31)       (32, 31, 28)   \n",
       "3                28           28  (31, 28)  (28, 28)       (31, 28, 28)   \n",
       "4                36           28  (28, 28)  (36, 28)       (28, 28, 36)   \n",
       "...             ...          ...       ...       ...                ...   \n",
       "707433           34           32  (47, 32)  (34, 32)       (47, 32, 34)   \n",
       "707434           39           34  (32, 34)  (39, 34)       (32, 34, 39)   \n",
       "707435           33           39  (34, 39)  (33, 39)       (34, 39, 33)   \n",
       "707436           36           33  (39, 33)  (36, 33)       (39, 33, 36)   \n",
       "707437            0           36  (33, 36)   (0, 36)        (33, 36, 0)   \n",
       "\n",
       "       phonemes words  \n",
       "0         (h#,)   (,)  \n",
       "1         (h#,)   (,)  \n",
       "2         (h#,)   (,)  \n",
       "3         (h#,)   (,)  \n",
       "4         (h#,)   (,)  \n",
       "...         ...   ...  \n",
       "707433    (h#,)   (,)  \n",
       "707434    (h#,)   (,)  \n",
       "707435    (h#,)   (,)  \n",
       "707436    (h#,)   (,)  \n",
       "707437    (h#,)   (,)  \n",
       "\n",
       "[707438 rows x 13 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_surrounding(data_frame):\n",
    "    data_frame['prev_curr'] = list(zip(data_frame.previous_packet, data_frame.packet_size))\n",
    "    data_frame['next_curr'] = list(zip(data_frame.next_packet, data_frame.packet_size))\n",
    "    data_frame['packet_surrounding'] = list(zip(data_frame.previous_packet, data_frame.packet_size, data_frame.next_packet))\n",
    "    \n",
    "    #data_frame['prev_curr'] = data_frame['prev_curr'].astype('category')\n",
    "    #data_frame['next_curr'] = data_frame['next_curr'].astype('category')\n",
    "    #data_frame['packet_surrounding'] = data_frame['packet_surrounding'].astype('category')\n",
    "\n",
    "add_surrounding(skype_data_train)\n",
    "add_surrounding(skype_data_test)\n",
    "\n",
    "skype_data_train = skype_data_train[['file', 'dialect', 'speaker', 'sentence_id', 'sentence', 'previous_packet', 'next_packet','packet_size', 'prev_curr', 'next_curr', 'packet_surrounding', 'phonemes', 'words']]\n",
    "skype_data_test = skype_data_test[['file', 'dialect', 'speaker', 'sentence_id', 'sentence', 'previous_packet', 'next_packet','packet_size', 'prev_curr', 'next_curr', 'packet_surrounding', 'phonemes', 'words']]\n",
    "skype_data_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add removal of labels for the test_dataset\n",
    "def get_labels(df, label=[\"words\"], feature=[\"previous_packet\", \"packet_size\", \"next_packet\"]):\n",
    "    labels = df.loc[:, label]\n",
    "    features = df.loc[:, feature]\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_labels(train_labels, test_labels, label=[\"words\"]):\n",
    "    train_labels = train_labels.astype('category')\n",
    "    test_labels = test_labels.astype('category')\n",
    "    \n",
    "    total_labels = train_labels.append(test_labels)\n",
    "    \n",
    "    lab_enc = LabelEncoder()\n",
    "    lab_enc.fit(total_labels[label])\n",
    "\n",
    "    train_labels = lab_enc.transform(train_labels[label])\n",
    "    test_labels = lab_enc.transform(test_labels[label])\n",
    "    \n",
    "    return train_labels, test_labels, lab_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15713\n",
      "6626\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20568"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set, train_labels = get_labels(skype_data_train)\n",
    "test_set, test_labels = get_labels(skype_data_test)\n",
    "\n",
    "train_labels = train_labels.astype('category')\n",
    "test_labels = test_labels.astype('category')\n",
    "\n",
    "total_labels = train_labels.append(test_labels)\n",
    "print(len(pd.unique(train_labels.words)))\n",
    "print(len(pd.unique(test_labels.words)))\n",
    "total_unique_words = len(pd.unique(total_labels.words))\n",
    "total_unique_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can see that we have a really big problem => there are 4855 new words that we have never seen. As we saw in our analysis we can't really generalise on never seen words before => this will hinder our results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3083\n",
      "2363\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3281"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set, train_labels = get_labels(skype_data_train, label=['phonemes'])\n",
    "test_set, test_labels = get_labels(skype_data_test, label=['phonemes'])\n",
    "\n",
    "train_labels = train_labels.astype('category')\n",
    "test_labels = test_labels.astype('category')\n",
    "\n",
    "total_labels = train_labels.append(test_labels)\n",
    "print(len(pd.unique(train_labels.phonemes)))\n",
    "print(len(pd.unique(test_labels.phonemes)))\n",
    "total_unique_phonemes = len(pd.unique(total_labels.phonemes))\n",
    "total_unique_phonemes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But this is really promissing. There are only 198 new phonemes, that we haven't seen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_dialect_splitter():\n",
    "    for dialect in np.unique(skype_data_train.dialect):\n",
    "        yield (skype_data_train.index[skype_data_train[\"dialect\"] != dialect],\n",
    "               skype_data_train.index[skype_data_train[\"dialect\"] == dialect])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First model that we will be trying is tree classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xkadlec6/.local/lib/python3.6/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "train_set, train_labels = get_labels(skype_data_train, label=[\"words\"])\n",
    "test_set, test_labels = get_labels(skype_data_test, label=[\"words\"])\n",
    "\n",
    "train_labels, test_labels, _ = prepare_labels(train_labels, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'criterion':['gini', 'entropy'], 'max_depth':[12,None], 'splitter':['best'],\n",
    "              'min_samples_split':[2], 'random_state':[42]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_clf = DecisionTreeClassifier()\n",
    "gscv_clf = GridSearchCV(orig_clf, parameters, n_jobs = -1, cv=cv_dialect_splitter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting!\n",
      "Finished!\n",
      "Best: 0.143448 using {'criterion': 'gini', 'max_depth': 12, 'min_samples_split': 2, 'random_state': 42, 'splitter': 'best'}\n",
      "Train accuracy: 0.1515\n",
      "Test accuracy : 0.1411\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting!\")\n",
    "gscv_clf.fit(train_set, train_labels)\n",
    "print(\"Finished!\")\n",
    "\n",
    "print(\"Best: %f using %s\" % (gscv_clf.best_score_, gscv_clf.best_params_))\n",
    "print(f\"Train accuracy: {gscv_clf.score(train_set, train_labels):.4f}\")\n",
    "print(f\"Test accuracy : {gscv_clf.score(test_set, test_labels):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_clf_pipeline = Pipeline(\n",
    "    [\n",
    "        (\n",
    "            \"clf\",\n",
    "            DecisionTreeClassifier(criterion=\"entropy\", max_depth=None, splitter=\"best\",\n",
    "                                   min_samples_split=2, random_state=42),\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting!\n",
      "Finished!\n",
      "Train accuracy: 0.2925\n",
      "Test accuracy : 0.1195\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting!\")\n",
    "tree_clf_pipeline.fit(train_set, train_labels)\n",
    "print(\"Finished!\")\n",
    "\n",
    "print(f\"Train accuracy: {tree_clf_pipeline.score(train_set, train_labels):.4f}\")\n",
    "print(f\"Test accuracy : {tree_clf_pipeline.score(test_set, test_labels):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Phonemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, train_labels = get_labels(skype_data_train, label=[\"phonemes\"])\n",
    "test_set, test_labels = get_labels(skype_data_test, label=[\"phonemes\"])\n",
    "\n",
    "train_labels, test_labels, _ = prepare_labels(train_labels, test_labels, label=[\"phonemes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_clf = DecisionTreeClassifier()\n",
    "gscv_clf = GridSearchCV(orig_clf, parameters, n_jobs = -1, cv=cv_dialect_splitter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting!\n",
      "Finished!\n",
      "Best: 0.143448 using {'criterion': 'gini', 'max_depth': 12, 'min_samples_split': 2, 'random_state': 42, 'splitter': 'best'}\n",
      "Train accuracy: 0.1515\n",
      "Test accuracy : 0.1411\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting!\")\n",
    "gscv_clf.fit(train_set, train_labels)\n",
    "print(\"Finished!\")\n",
    "\n",
    "print(\"Best: %f using %s\" % (gscv_clf.best_score_, gscv_clf.best_params_))\n",
    "print(f\"Train accuracy: {gscv_clf.score(train_set, train_labels):.4f}\")\n",
    "print(f\"Test accuracy : {gscv_clf.score(test_set, test_labels):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_clf_pipeline = Pipeline(\n",
    "    [\n",
    "        (\n",
    "            \"clf\",\n",
    "            DecisionTreeClassifier(criterion=\"entropy\", max_depth=None, splitter=\"best\",\n",
    "                                   min_samples_split=2, random_state=42),\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting!\n",
      "Finished!\n",
      "Train accuracy: 0.2925\n",
      "Test accuracy : 0.1195\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting!\")\n",
    "tree_clf_pipeline.fit(train_set, train_labels)\n",
    "print(\"Finished!\")\n",
    "\n",
    "print(f\"Train accuracy: {tree_clf_pipeline.score(train_set, train_labels):.4f}\")\n",
    "print(f\"Test accuracy : {tree_clf_pipeline.score(test_set, test_labels):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is already quite a promissing success rate for \"just a simple\" tree classifier. Also as we can see, `phonemes` give better results in skype dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look a different kind of classifier => k nearest neighbours. This classifier shouldn't need that much RAM and that much of a computational power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xkadlec6/.local/lib/python3.6/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "train_set, train_labels = get_labels(skype_data_train, label=[\"words\"])\n",
    "test_set, test_labels = get_labels(skype_data_test, label=[\"words\"])\n",
    "\n",
    "train_labels, test_labels, _ = prepare_labels(train_labels, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'n_neighbors':[16,32], 'weights':['uniform', 'distance'], 'n_jobs':[-1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_clf = KNeighborsClassifier()\n",
    "gscv_clf = GridSearchCV(orig_clf, parameters, n_jobs = -1, cv=cv_dialect_splitter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting!\n",
      "Finished!\n",
      "Best: 0.136635 using {'n_jobs': -1, 'n_neighbors': 32, 'weights': 'uniform'}\n",
      "Train accuracy: 0.1700\n",
      "Test accuracy : 0.1343\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting!\")\n",
    "gscv_clf.fit(train_set, train_labels)\n",
    "print(\"Finished!\")\n",
    "\n",
    "print(\"Best: %f using %s\" % (gscv_clf.best_score_, gscv_clf.best_params_))\n",
    "print(f\"Train accuracy: {gscv_clf.score(train_set, train_labels):.4f}\")\n",
    "print(f\"Test accuracy : {gscv_clf.score(test_set, test_labels):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_clf_pipeline = Pipeline(\n",
    "    [\n",
    "        (\n",
    "            \"scaler\",\n",
    "            StandardScaler()\n",
    "        ),\n",
    "        (\n",
    "            \"clf\",\n",
    "            KNeighborsClassifier(32, weights='distance', n_jobs=-1)\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 20, distance => 0.2887, 0.1203\n",
    "# 32, uniform => 0.1700, 0.1343\n",
    "# 32, distance => 0.2912, 0.1216"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting!\n",
      "Finished!\n",
      "Train accuracy: 0.2911\n",
      "Test accuracy : 0.1213\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting!\")\n",
    "knn_clf_pipeline.fit(train_set, train_labels)\n",
    "print(\"Finished!\")\n",
    "\n",
    "print(f\"Train accuracy: {knn_clf_pipeline.score(train_set, train_labels):.4f}\")\n",
    "print(f\"Test accuracy : {knn_clf_pipeline.score(test_set, test_labels):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the search space of 32 nearest neighbours we get around 12% success rate on our test data (which is around 31436 words). I have listed other parameters and their resulting percentages in the comments in the code cell. Also worth noting is that \"StandardScaler\" only worsens (not tested on skype) our predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try our luck with phonemes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xkadlec6/.local/lib/python3.6/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "train_set, train_labels = get_labels(skype_data_train, label=[\"phonemes\"])\n",
    "test_set, test_labels = get_labels(skype_data_test, label=[\"phonemes\"])\n",
    "\n",
    "train_labels, test_labels, _ = prepare_labels(train_labels, test_labels, label=[\"phonemes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'n_neighbors':[16,32], 'weights':['uniform', 'distance'], 'n_jobs':[-1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_clf = KNeighborsClassifier()\n",
    "gscv_clf = GridSearchCV(orig_clf, parameters, n_jobs = -1, cv=cv_dialect_splitter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting!\n",
      "Finished!\n",
      "Best: 0.136635 using {'n_jobs': -1, 'n_neighbors': 32, 'weights': 'uniform'}\n",
      "Train accuracy: 0.1700\n",
      "Test accuracy : 0.1343\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting!\")\n",
    "gscv_clf.fit(train_set, train_labels)\n",
    "print(\"Finished!\")\n",
    "\n",
    "print(\"Best: %f using %s\" % (gscv_clf.best_score_, gscv_clf.best_params_))\n",
    "print(f\"Train accuracy: {gscv_clf.score(train_set, train_labels):.4f}\")\n",
    "print(f\"Test accuracy : {gscv_clf.score(test_set, test_labels):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_clf_pipeline = Pipeline(\n",
    "    [\n",
    "        (\n",
    "            \"clf\",\n",
    "            KNeighborsClassifier(32, weights='distance', n_jobs=-1)\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "# 20, distance => 0.3221, 0.1377\n",
    "# 32, uniform => 0.2093, 0.1574\n",
    "# 32, distance => 0.3265, 0.1410"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting!\n",
      "Finished!\n",
      "Train accuracy: 0.3265\n",
      "Test accuracy : 0.1410\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting!\")\n",
    "knn_clf_pipeline.fit(train_set, train_labels)\n",
    "print(\"Finished!\")\n",
    "\n",
    "print(f\"Train accuracy: {knn_clf_pipeline.score(train_set, train_labels):.4f}\")\n",
    "print(f\"Test accuracy : {knn_clf_pipeline.score(test_set, test_labels):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can clearly see that phonemes are indeed actually better than just words and help us get better predictions. But of course there is also adds the complication of how to make words from these phonemes / make something, that makes sense."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xkadlec6/.local/lib/python3.6/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "train_set, train_labels = get_labels(skype_data_train, label=[\"phonemes\"])\n",
    "test_set, test_labels = get_labels(skype_data_test, label=[\"phonemes\"])\n",
    "\n",
    "train_labels, test_labels, _ = prepare_labels(train_labels, test_labels, label=[\"phonemes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_pipeline = Pipeline(\n",
    "    [\n",
    "        (\n",
    "            \"clf\",\n",
    "            RandomForestClassifier(max_depth=12, random_state=42, criterion = 'entropy', n_jobs = -1, min_samples_split = 2)\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Starting!\")\n",
    "rfc_pipeline.fit(train_set, train_labels)\n",
    "print(\"Finished!\")\n",
    "\n",
    "print(f\"Train accuracy: {rfc_pipeline.score(train_set, train_labels):.4f}\")\n",
    "print(f\"Test accuracy : {rfc_pipeline.score(test_set, test_labels):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RAM :("
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xkadlec6/.local/lib/python3.6/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "train_set, train_labels = get_labels(skype_data_train, label=[\"words\"])\n",
    "test_set, test_labels = get_labels(skype_data_test, label=[\"words\"])\n",
    "\n",
    "train_labels, test_labels, _ = prepare_labels(train_labels, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "abc_pipeline = Pipeline(\n",
    "    [\n",
    "        (\n",
    "            \"clf\",\n",
    "            AdaBoostClassifier(random_state=1, n_estimators = 60, learning_rate=0.9)\n",
    "        ),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0505, 0.0471\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting!\")\n",
    "#abc_pipeline.fit(train_set, train_labels)\n",
    "print(\"Finished!\")\n",
    "\n",
    "#print(f\"Train accuracy: {abc_pipeline.score(train_set, train_labels):.4f}\")\n",
    "#print(f\"Test accuracy : {abc_pipeline.score(test_set, test_labels):.4f}\")\n",
    "\n",
    "print(\"0.0505, 0.0471\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This classifier ended in absolute failure as it wasn't able to get even acceptable results on the train data. And it even took 8 hours to learn (this is because it can only use 1 thread), so this classifier is pretty much worthless to us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's now try to bring out the big guns - neural networks. For this I've chosen to use TensorFlow and Keras (PyTorch could also be used). We are able to get reasonably better results but at the cost of long compute times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xkadlec6/.local/lib/python3.6/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "train_set, train_labels = get_labels(skype_data_train, label=[\"words\"])\n",
    "test_set, test_labels = get_labels(skype_data_test, label=[\"words\"])\n",
    "\n",
    "train_labels, test_labels, _ = prepare_labels(train_labels, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(707438, 3)\n",
      "(707438,)\n"
     ]
    }
   ],
   "source": [
    "print(train_set.shape)\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(707438, 20568)\n"
     ]
    }
   ],
   "source": [
    "train_labels = to_categorical(train_labels, num_classes=total_unique_words)\n",
    "test_labels = to_categorical(test_labels, num_classes=total_unique_words)\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "def build_clf(optimizer='adam', classes=total_unique_words):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(units=512, activation='relu', input_dim=3*1))  # first hidden layer\n",
    "    model.add(Dense(units=256, activation='relu'))  # second hidden layer\n",
    "    # model.add(Dense(units=128, activation='relu'))  # third hidden layer\n",
    "    model.add(Dense(units=classes, activation='softmax'))  # output layer\n",
    "    # model.add(Dense(units=128))  # output layer\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'batch_size':[64,128,256],\n",
    "          'nb_epoch':[16,32],\n",
    "          'optimizer':['adam', 'rmsprop']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_clf = KerasClassifier(build_fn=build_clf)\n",
    "gscv_clf = GridSearchCV(orig_clf, parameters, cv=cv_dialect_splitter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting!\n",
      "10157/10157 [==============================] - 130s 13ms/step - loss: 6.9524 - accuracy: 0.1376\n",
      "898/898 [==============================] - 5s 6ms/step - loss: 7.3035 - accuracy: 0.1495\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting!\")\n",
    "gscv_clf.fit(train_set, train_labels)\n",
    "print(\"Finished!\")\n",
    "\n",
    "print(\"Best: %f using %s\" % (gscv_clf.best_score_, gscv_clf.best_params_))\n",
    "print(f\"Train accuracy: {gscv_clf.score(train_set, train_labels):.4f}\")\n",
    "print(f\"Test accuracy : {gscv_clf.score(test_set, test_labels):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 20568)             5285976   \n",
      "=================================================================\n",
      "Total params: 5,419,352\n",
      "Trainable params: 5,419,352\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(units=512, activation='relu', input_dim=3*1))  # first hidden layer\n",
    "model.add(Dense(units=256, activation='relu'))  # second hidden layer\n",
    "# model.add(Dense(units=128, activation='relu'))  # third hidden layer\n",
    "model.add(Dense(units=total_unique_words, activation='softmax'))  # output layer\n",
    "# model.add(Dense(units=128))  # output layer\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "2764/2764 [==============================] - 94s 34ms/step - loss: 7.0402 - accuracy: 0.1368\n",
      "Epoch 2/64\n",
      "2764/2764 [==============================] - 93s 34ms/step - loss: 6.6146 - accuracy: 0.1428\n",
      "Epoch 3/64\n",
      "2764/2764 [==============================] - 91s 33ms/step - loss: 6.5617 - accuracy: 0.1434\n",
      "Epoch 4/64\n",
      "2764/2764 [==============================] - 92s 33ms/step - loss: 6.5379 - accuracy: 0.1431\n",
      "Epoch 5/64\n",
      "2764/2764 [==============================] - 90s 33ms/step - loss: 6.5101 - accuracy: 0.1435\n",
      "Epoch 6/64\n",
      "2764/2764 [==============================] - 91s 33ms/step - loss: 6.4904 - accuracy: 0.1443\n",
      "Epoch 7/64\n",
      "2764/2764 [==============================] - 91s 33ms/step - loss: 6.4705 - accuracy: 0.1445\n",
      "Epoch 8/64\n",
      "2764/2764 [==============================] - 91s 33ms/step - loss: 6.4563 - accuracy: 0.1448\n",
      "Epoch 9/64\n",
      "2764/2764 [==============================] - 92s 33ms/step - loss: 6.4492 - accuracy: 0.1446\n",
      "Epoch 10/64\n",
      "2764/2764 [==============================] - 92s 33ms/step - loss: 6.4355 - accuracy: 0.1447\n",
      "Epoch 11/64\n",
      "2764/2764 [==============================] - 93s 34ms/step - loss: 6.4279 - accuracy: 0.1447\n",
      "Epoch 12/64\n",
      "2764/2764 [==============================] - 91s 33ms/step - loss: 6.4191 - accuracy: 0.1448\n",
      "Epoch 13/64\n",
      "2764/2764 [==============================] - 91s 33ms/step - loss: 6.4111 - accuracy: 0.1448\n",
      "Epoch 14/64\n",
      "2764/2764 [==============================] - 92s 33ms/step - loss: 6.4001 - accuracy: 0.1449\n",
      "Epoch 15/64\n",
      "2764/2764 [==============================] - 92s 33ms/step - loss: 6.3993 - accuracy: 0.1451\n",
      "Epoch 16/64\n",
      "2764/2764 [==============================] - 92s 33ms/step - loss: 6.3958 - accuracy: 0.1447\n",
      "Epoch 17/64\n",
      "2764/2764 [==============================] - 91s 33ms/step - loss: 6.3827 - accuracy: 0.1448\n",
      "Epoch 18/64\n",
      "2764/2764 [==============================] - 94s 34ms/step - loss: 6.3807 - accuracy: 0.1452\n",
      "Epoch 19/64\n",
      "2764/2764 [==============================] - 94s 34ms/step - loss: 6.3735 - accuracy: 0.1453\n",
      "Epoch 20/64\n",
      "2764/2764 [==============================] - 90s 32ms/step - loss: 6.3754 - accuracy: 0.1446\n",
      "Epoch 21/64\n",
      "2764/2764 [==============================] - 90s 33ms/step - loss: 6.3712 - accuracy: 0.1449\n",
      "Epoch 22/64\n",
      "2764/2764 [==============================] - 91s 33ms/step - loss: 6.3667 - accuracy: 0.1444\n",
      "Epoch 23/64\n",
      "2764/2764 [==============================] - 90s 33ms/step - loss: 6.3593 - accuracy: 0.1450\n",
      "Epoch 24/64\n",
      "2764/2764 [==============================] - 91s 33ms/step - loss: 6.3597 - accuracy: 0.1447\n",
      "Epoch 25/64\n",
      "2764/2764 [==============================] - 90s 32ms/step - loss: 6.3519 - accuracy: 0.1451\n",
      "Epoch 26/64\n",
      "2764/2764 [==============================] - 92s 33ms/step - loss: 6.3482 - accuracy: 0.1455\n",
      "Epoch 27/64\n",
      "2764/2764 [==============================] - 91s 33ms/step - loss: 6.3439 - accuracy: 0.1452\n",
      "Epoch 28/64\n",
      "2764/2764 [==============================] - 91s 33ms/step - loss: 6.3436 - accuracy: 0.1447\n",
      "Epoch 29/64\n",
      "2764/2764 [==============================] - 90s 33ms/step - loss: 6.3381 - accuracy: 0.1462\n",
      "Epoch 30/64\n",
      "2764/2764 [==============================] - 91s 33ms/step - loss: 6.3403 - accuracy: 0.1449\n",
      "Epoch 31/64\n",
      "2764/2764 [==============================] - 91s 33ms/step - loss: 6.3320 - accuracy: 0.1454\n",
      "Epoch 32/64\n",
      "2764/2764 [==============================] - 90s 33ms/step - loss: 6.3391 - accuracy: 0.1451\n",
      "Epoch 33/64\n",
      "2764/2764 [==============================] - 91s 33ms/step - loss: 6.3357 - accuracy: 0.1445\n",
      "Epoch 34/64\n",
      "2764/2764 [==============================] - 90s 33ms/step - loss: 6.3272 - accuracy: 0.1456\n",
      "Epoch 35/64\n",
      "2764/2764 [==============================] - 90s 33ms/step - loss: 6.3272 - accuracy: 0.1452\n",
      "Epoch 36/64\n",
      "2764/2764 [==============================] - 90s 33ms/step - loss: 6.3294 - accuracy: 0.1450\n",
      "Epoch 37/64\n",
      "2764/2764 [==============================] - 90s 33ms/step - loss: 6.3278 - accuracy: 0.1449\n",
      "Epoch 38/64\n",
      "2764/2764 [==============================] - 91s 33ms/step - loss: 6.3243 - accuracy: 0.1451\n",
      "Epoch 39/64\n",
      "2764/2764 [==============================] - 91s 33ms/step - loss: 6.3156 - accuracy: 0.1458\n",
      "Epoch 40/64\n",
      "2764/2764 [==============================] - 90s 33ms/step - loss: 6.3182 - accuracy: 0.1450\n",
      "Epoch 41/64\n",
      "2764/2764 [==============================] - 91s 33ms/step - loss: 6.3186 - accuracy: 0.1447\n",
      "Epoch 42/64\n",
      "2764/2764 [==============================] - 92s 33ms/step - loss: 6.3155 - accuracy: 0.1453\n",
      "Epoch 43/64\n",
      "2764/2764 [==============================] - 91s 33ms/step - loss: 6.3127 - accuracy: 0.1454\n",
      "Epoch 44/64\n",
      "2764/2764 [==============================] - 91s 33ms/step - loss: 6.3155 - accuracy: 0.1447\n",
      "Epoch 45/64\n",
      "2764/2764 [==============================] - 90s 32ms/step - loss: 6.3125 - accuracy: 0.1452\n",
      "Epoch 46/64\n",
      "2764/2764 [==============================] - 91s 33ms/step - loss: 6.3107 - accuracy: 0.1454\n",
      "Epoch 47/64\n",
      "2764/2764 [==============================] - 91s 33ms/step - loss: 6.3071 - accuracy: 0.1456\n",
      "Epoch 48/64\n",
      "2764/2764 [==============================] - 92s 33ms/step - loss: 6.3028 - accuracy: 0.1457\n",
      "Epoch 49/64\n",
      "2764/2764 [==============================] - 93s 34ms/step - loss: 6.3074 - accuracy: 0.1458\n",
      "Epoch 50/64\n",
      "2764/2764 [==============================] - 91s 33ms/step - loss: 6.3054 - accuracy: 0.1443\n",
      "Epoch 51/64\n",
      "2764/2764 [==============================] - 91s 33ms/step - loss: 6.3081 - accuracy: 0.1447\n",
      "Epoch 52/64\n",
      "2764/2764 [==============================] - 90s 33ms/step - loss: 6.2999 - accuracy: 0.1460\n",
      "Epoch 53/64\n",
      "2764/2764 [==============================] - 91s 33ms/step - loss: 6.3049 - accuracy: 0.1447\n",
      "Epoch 54/64\n",
      "2764/2764 [==============================] - 91s 33ms/step - loss: 6.2981 - accuracy: 0.1452\n",
      "Epoch 55/64\n",
      "2764/2764 [==============================] - 92s 33ms/step - loss: 6.3018 - accuracy: 0.1445\n",
      "Epoch 56/64\n",
      "2764/2764 [==============================] - 92s 33ms/step - loss: 6.2991 - accuracy: 0.1453\n",
      "Epoch 57/64\n",
      "2764/2764 [==============================] - 91s 33ms/step - loss: 6.2982 - accuracy: 0.1449\n",
      "Epoch 58/64\n",
      "2764/2764 [==============================] - 91s 33ms/step - loss: 6.2937 - accuracy: 0.1457\n",
      "Epoch 59/64\n",
      "2764/2764 [==============================] - 92s 33ms/step - loss: 6.2912 - accuracy: 0.1460\n",
      "Epoch 60/64\n",
      "2764/2764 [==============================] - 91s 33ms/step - loss: 6.3016 - accuracy: 0.1445\n",
      "Epoch 61/64\n",
      "2764/2764 [==============================] - 91s 33ms/step - loss: 6.2927 - accuracy: 0.1454\n",
      "Epoch 62/64\n",
      "2764/2764 [==============================] - 91s 33ms/step - loss: 6.2940 - accuracy: 0.1446\n",
      "Epoch 63/64\n",
      "2764/2764 [==============================] - 90s 33ms/step - loss: 6.2974 - accuracy: 0.1445\n",
      "Epoch 64/64\n",
      "2764/2764 [==============================] - 90s 33ms/step - loss: 6.2945 - accuracy: 0.1451\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f0f97b186a0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_set, train_labels, epochs=64, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22108/22108 [==============================] - 88s 4ms/step - loss: 6.2811 - accuracy: 0.1452\n",
      "train loss, train acc: [6.281101703643799, 0.1451999992132187]\n"
     ]
    }
   ],
   "source": [
    "print(\"train loss, train acc:\", model.evaluate(train_set, train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8079/8079 [==============================] - 34s 4ms/step - loss: 10.7018 - accuracy: 0.1430\n",
      "test loss, test acc: [10.701821327209473, 0.14304447174072266]\n"
     ]
    }
   ],
   "source": [
    "print(\"test loss, test acc:\", model.evaluate(test_set, test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "batch size = 128:  \n",
    "test loss, test acc: [12.597193717956543, 0.1413850337266922] => 128 epochs  \n",
    "\n",
    "batch size = 256:  \n",
    "test loss, test acc: [9.740732192993164, 0.14129993319511414] => 4 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that changing epoch count doesn't change the results that much and we should try to explore different models / architectures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Phonemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xkadlec6/.local/lib/python3.6/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "train_set, train_labels = get_labels(skype_data_train, label=[\"phonemes\"])\n",
    "test_set, test_labels = get_labels(skype_data_test, label=[\"phonemes\"])\n",
    "\n",
    "train_labels, test_labels, _ = prepare_labels(train_labels, test_labels, label=[\"phonemes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(707438, 3)\n",
      "(707438,)\n"
     ]
    }
   ],
   "source": [
    "print(train_set.shape)\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(707438, 3281)\n"
     ]
    }
   ],
   "source": [
    "train_labels = to_categorical(train_labels, num_classes=total_unique_phonemes)\n",
    "test_labels = to_categorical(test_labels, num_classes=total_unique_phonemes)\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "def build_clf(optimizer='adam', classes=total_unique_phonemes):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(units=512, activation='relu', input_dim=3*1))  # first hidden layer\n",
    "    model.add(Dense(units=256, activation='relu'))  # second hidden layer\n",
    "    # model.add(Dense(units=128, activation='relu'))  # third hidden layer\n",
    "    model.add(Dense(units=classes, activation='softmax'))  # output layer\n",
    "    # model.add(Dense(units=128))  # output layer\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'batch_size':[64,128,256],\n",
    "          'nb_epoch':[16,32],\n",
    "          'optimizer':['adam', 'rmsprop']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_clf = KerasClassifier(build_fn=build_clf)\n",
    "gscv_clf = GridSearchCV(orig_clf, parameters, cv=cv_dialect_splitter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 3281)              843217    \n",
      "=================================================================\n",
      "Total params: 976,593\n",
      "Trainable params: 976,593\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(units=512, activation='relu', input_dim=3*1))  # first hidden layer\n",
    "model.add(Dense(units=256, activation='relu'))  # second hidden layer\n",
    "# model.add(Dense(units=128, activation='relu'))  # third hidden layer\n",
    "model.add(Dense(units=total_unique_phonemes, activation='softmax'))  # output layer\n",
    "# model.add(Dense(units=128))  # output layer\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "2764/2764 [==============================] - 30s 11ms/step - loss: 4.5438 - accuracy: 0.1533\n",
      "Epoch 2/64\n",
      "2764/2764 [==============================] - 31s 11ms/step - loss: 4.1470 - accuracy: 0.1776\n",
      "Epoch 3/64\n",
      "2764/2764 [==============================] - 30s 11ms/step - loss: 4.1222 - accuracy: 0.1786\n",
      "Epoch 4/64\n",
      "2764/2764 [==============================] - 29s 11ms/step - loss: 4.1013 - accuracy: 0.1809\n",
      "Epoch 5/64\n",
      "2764/2764 [==============================] - 30s 11ms/step - loss: 4.0866 - accuracy: 0.1813\n",
      "Epoch 6/64\n",
      "2764/2764 [==============================] - 29s 11ms/step - loss: 4.0820 - accuracy: 0.1814\n",
      "Epoch 7/64\n",
      "2764/2764 [==============================] - 29s 11ms/step - loss: 4.0782 - accuracy: 0.1810\n",
      "Epoch 8/64\n",
      "2764/2764 [==============================] - 30s 11ms/step - loss: 4.0718 - accuracy: 0.1818\n",
      "Epoch 9/64\n",
      "2764/2764 [==============================] - 31s 11ms/step - loss: 4.0741 - accuracy: 0.1814\n",
      "Epoch 10/64\n",
      "2764/2764 [==============================] - 30s 11ms/step - loss: 4.0671 - accuracy: 0.1824\n",
      "Epoch 11/64\n",
      "2764/2764 [==============================] - 30s 11ms/step - loss: 4.0629 - accuracy: 0.1820\n",
      "Epoch 12/64\n",
      "2764/2764 [==============================] - 29s 11ms/step - loss: 4.0630 - accuracy: 0.1823\n",
      "Epoch 13/64\n",
      "2764/2764 [==============================] - 30s 11ms/step - loss: 4.0578 - accuracy: 0.1824\n",
      "Epoch 14/64\n",
      "2764/2764 [==============================] - 30s 11ms/step - loss: 4.0566 - accuracy: 0.1825\n",
      "Epoch 15/64\n",
      "2764/2764 [==============================] - 30s 11ms/step - loss: 4.0596 - accuracy: 0.1815\n",
      "Epoch 16/64\n",
      "2764/2764 [==============================] - 30s 11ms/step - loss: 4.0506 - accuracy: 0.1828\n",
      "Epoch 17/64\n",
      "2764/2764 [==============================] - 30s 11ms/step - loss: 4.0531 - accuracy: 0.1830\n",
      "Epoch 18/64\n",
      "2764/2764 [==============================] - 31s 11ms/step - loss: 4.0488 - accuracy: 0.1831\n",
      "Epoch 19/64\n",
      "2764/2764 [==============================] - 30s 11ms/step - loss: 4.0443 - accuracy: 0.1832\n",
      "Epoch 20/64\n",
      "2764/2764 [==============================] - 30s 11ms/step - loss: 4.0532 - accuracy: 0.1829\n",
      "Epoch 21/64\n",
      "2764/2764 [==============================] - 30s 11ms/step - loss: 4.0445 - accuracy: 0.1827\n",
      "Epoch 22/64\n",
      "2764/2764 [==============================] - 31s 11ms/step - loss: 4.0472 - accuracy: 0.1825\n",
      "Epoch 23/64\n",
      "2764/2764 [==============================] - 30s 11ms/step - loss: 4.0408 - accuracy: 0.1830\n",
      "Epoch 24/64\n",
      "2764/2764 [==============================] - 30s 11ms/step - loss: 4.0449 - accuracy: 0.1828\n",
      "Epoch 25/64\n",
      "2764/2764 [==============================] - 30s 11ms/step - loss: 4.0504 - accuracy: 0.1826\n",
      "Epoch 26/64\n",
      "2764/2764 [==============================] - 31s 11ms/step - loss: 4.0412 - accuracy: 0.1834\n",
      "Epoch 27/64\n",
      "2764/2764 [==============================] - 30s 11ms/step - loss: 4.0442 - accuracy: 0.1830\n",
      "Epoch 28/64\n",
      "2764/2764 [==============================] - 30s 11ms/step - loss: 4.0371 - accuracy: 0.1837\n",
      "Epoch 29/64\n",
      "2764/2764 [==============================] - 30s 11ms/step - loss: 4.0415 - accuracy: 0.1829\n",
      "Epoch 30/64\n",
      "2764/2764 [==============================] - 29s 11ms/step - loss: 4.0435 - accuracy: 0.1828\n",
      "Epoch 31/64\n",
      "2764/2764 [==============================] - 29s 11ms/step - loss: 4.0395 - accuracy: 0.1829\n",
      "Epoch 32/64\n",
      "2764/2764 [==============================] - 29s 11ms/step - loss: 4.0396 - accuracy: 0.1838\n",
      "Epoch 33/64\n",
      "2764/2764 [==============================] - 30s 11ms/step - loss: 4.0386 - accuracy: 0.1829\n",
      "Epoch 34/64\n",
      "2764/2764 [==============================] - 30s 11ms/step - loss: 4.0359 - accuracy: 0.1827\n",
      "Epoch 35/64\n",
      "2764/2764 [==============================] - 29s 11ms/step - loss: 4.0372 - accuracy: 0.1841\n",
      "Epoch 36/64\n",
      "2764/2764 [==============================] - 30s 11ms/step - loss: 4.0364 - accuracy: 0.1828\n",
      "Epoch 37/64\n",
      "2764/2764 [==============================] - 30s 11ms/step - loss: 4.0381 - accuracy: 0.1831\n",
      "Epoch 38/64\n",
      "2764/2764 [==============================] - 29s 11ms/step - loss: 4.0345 - accuracy: 0.1828\n",
      "Epoch 39/64\n",
      "2764/2764 [==============================] - 30s 11ms/step - loss: 4.0334 - accuracy: 0.1837\n",
      "Epoch 40/64\n",
      "2764/2764 [==============================] - 31s 11ms/step - loss: 4.0303 - accuracy: 0.1835\n",
      "Epoch 41/64\n",
      "2764/2764 [==============================] - 29s 11ms/step - loss: 4.0394 - accuracy: 0.1830\n",
      "Epoch 42/64\n",
      "2764/2764 [==============================] - 30s 11ms/step - loss: 4.0326 - accuracy: 0.1835\n",
      "Epoch 43/64\n",
      "2764/2764 [==============================] - 31s 11ms/step - loss: 4.0351 - accuracy: 0.1829\n",
      "Epoch 44/64\n",
      "2764/2764 [==============================] - 30s 11ms/step - loss: 4.0334 - accuracy: 0.1833\n",
      "Epoch 45/64\n",
      "2764/2764 [==============================] - 30s 11ms/step - loss: 4.0304 - accuracy: 0.1833\n",
      "Epoch 46/64\n",
      "2764/2764 [==============================] - 31s 11ms/step - loss: 4.0332 - accuracy: 0.1828\n",
      "Epoch 47/64\n",
      "2764/2764 [==============================] - 30s 11ms/step - loss: 4.0395 - accuracy: 0.1825\n",
      "Epoch 48/64\n",
      "2764/2764 [==============================] - 31s 11ms/step - loss: 4.0294 - accuracy: 0.1842\n",
      "Epoch 49/64\n",
      "2764/2764 [==============================] - 32s 11ms/step - loss: 4.0295 - accuracy: 0.1832\n",
      "Epoch 50/64\n",
      "2764/2764 [==============================] - 31s 11ms/step - loss: 4.0321 - accuracy: 0.1832\n",
      "Epoch 51/64\n",
      "2764/2764 [==============================] - 31s 11ms/step - loss: 4.0315 - accuracy: 0.1831\n",
      "Epoch 52/64\n",
      "2764/2764 [==============================] - 31s 11ms/step - loss: 4.0297 - accuracy: 0.1834\n",
      "Epoch 53/64\n",
      "2764/2764 [==============================] - 31s 11ms/step - loss: 4.0298 - accuracy: 0.1826\n",
      "Epoch 54/64\n",
      "2764/2764 [==============================] - 31s 11ms/step - loss: 4.0289 - accuracy: 0.1830\n",
      "Epoch 55/64\n",
      "2764/2764 [==============================] - 30s 11ms/step - loss: 4.0270 - accuracy: 0.1827\n",
      "Epoch 56/64\n",
      "2764/2764 [==============================] - 31s 11ms/step - loss: 4.0286 - accuracy: 0.1829\n",
      "Epoch 57/64\n",
      "2764/2764 [==============================] - 30s 11ms/step - loss: 4.0295 - accuracy: 0.1834\n",
      "Epoch 58/64\n",
      "2764/2764 [==============================] - 30s 11ms/step - loss: 4.0338 - accuracy: 0.1823\n",
      "Epoch 59/64\n",
      "2764/2764 [==============================] - 31s 11ms/step - loss: 4.0275 - accuracy: 0.1834\n",
      "Epoch 60/64\n",
      "2764/2764 [==============================] - 30s 11ms/step - loss: 4.0347 - accuracy: 0.1827\n",
      "Epoch 61/64\n",
      "2764/2764 [==============================] - 29s 11ms/step - loss: 4.0271 - accuracy: 0.1829\n",
      "Epoch 62/64\n",
      "2764/2764 [==============================] - 31s 11ms/step - loss: 4.0253 - accuracy: 0.1833\n",
      "Epoch 63/64\n",
      "2764/2764 [==============================] - 30s 11ms/step - loss: 4.0275 - accuracy: 0.1832\n",
      "Epoch 64/64\n",
      "2764/2764 [==============================] - 30s 11ms/step - loss: 4.0319 - accuracy: 0.1827\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f0f97c75fd0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_set, train_labels, epochs=64, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22108/22108 [==============================] - 49s 2ms/step - loss: 4.0201 - accuracy: 0.1835\n",
      "train loss, train acc: [4.020120620727539, 0.18351855874061584]\n"
     ]
    }
   ],
   "source": [
    "print(\"train loss, train acc:\", model.evaluate(train_set, train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8079/8079 [==============================] - 18s 2ms/step - loss: 4.2246 - accuracy: 0.1769\n",
      "test loss, test acc: [4.224584579467773, 0.17687150835990906]\n"
     ]
    }
   ],
   "source": [
    "print(\"test loss, test acc:\", model.evaluate(test_set, test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "batch size = 256:  \n",
    "test loss, test acc: [4.276370048522949, 0.17660073935985565] => 128 epochs  \n",
    "test loss, test acc: [4.16491174697876, 0.17395879328250885] => 4 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that changing epoch count doesn't change the results that much and we should try to explore different models / architectures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_lstm = Sequential()\n",
    "# model_lstm.add(LSTM(256, input_shape = (1, 3)))\n",
    "# model_lstm.add(Dense(units=total_unique_words))\n",
    "# model_lstm.compile(loss='categorical_crossentropy',\n",
    "#               optimizer='adam',\n",
    "#               metrics=['accuracy']\n",
    "#              )\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Embedding\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import SpatialDropout1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xkadlec6/.local/lib/python3.6/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "train_set, train_labels = get_labels(skype_data_train, label=[\"words\"])\n",
    "test_set, test_labels = get_labels(skype_data_test, label=[\"words\"])\n",
    "\n",
    "train_labels, test_labels, _ = prepare_labels(train_labels, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(707438, 20568)\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "train_labels = to_categorical(train_labels, num_classes=total_unique_words)\n",
    "test_labels = to_categorical(test_labels, num_classes=total_unique_words)\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0, 32, 32])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshaped_values = train_set.values.reshape(-1, 1, 3)\n",
    "reshaped_values[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "def build_lstm_clf(optimizer='adam', classes=total_unique_words):\n",
    "    model = Sequential()\n",
    "\n",
    "    model_lstm.add(LSTM(256, input_shape = (1, 3), dropout = 0.3, recurrent_dropout = 0.3))\n",
    "    model_lstm.add(Dense(256, activation = 'relu'))\n",
    "    model_lstm.add(Dropout(0.3))\n",
    "    model_lstm.add(Dense(classes, activation = 'softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'batch_size':[64,128,256],\n",
    "          'nb_epoch':[16,32],\n",
    "          'optimizer':['adam', 'rmsprop']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_clf = KerasClassifier(build_fn=build_clf)\n",
    "gscv_clf = GridSearchCV(orig_clf, parameters, cv=cv_dialect_splitter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting!\n",
      "1242/1242 [==============================] - 23s 18ms/step - loss: 8.7184 - accuracy: 0.0474\n",
      "110/110 [==============================] - 1s 6ms/step - loss: 8.6063 - accuracy: 0.0587\n",
      "1134/1134 [==============================] - 21s 18ms/step - loss: 8.7687 - accuracy: 0.0475\n",
      "219/219 [==============================] - 2s 7ms/step - loss: 8.6525 - accuracy: 0.0509\n",
      "1134/1134 [==============================] - 19s 17ms/step - loss: 8.7338 - accuracy: 0.0492\n",
      "219/219 [==============================] - 2s 7ms/step - loss: 8.6538 - accuracy: 0.0519\n",
      "1149/1149 [==============================] - 20s 17ms/step - loss: 8.7412 - accuracy: 0.0499\n",
      "203/203 [==============================] - 2s 7ms/step - loss: 8.5547 - accuracy: 0.0433\n",
      "1136/1136 [==============================] - 19s 16ms/step - loss: 8.7790 - accuracy: 0.0456\n",
      "217/217 [==============================] - 2s 6ms/step - loss: 8.6529 - accuracy: 0.0526\n",
      "1248/1248 [==============================] - 20s 16ms/step - loss: 8.7471 - accuracy: 0.0498\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 8.6892 - accuracy: 0.0610\n",
      "1131/1131 [==============================] - 20s 17ms/step - loss: 8.8528 - accuracy: 0.0460\n",
      "221/221 [==============================] - 2s 7ms/step - loss: 8.8989 - accuracy: 0.0515\n",
      "1291/1291 [==============================] - 21s 16ms/step - loss: 8.8269 - accuracy: 0.0459\n",
      "61/61 [==============================] - 1s 7ms/step - loss: 8.7650 - accuracy: 0.0414\n",
      "1242/1242 [==============================] - 28s 22ms/step - loss: 8.8047 - accuracy: 0.0429\n",
      "110/110 [==============================] - 1s 8ms/step - loss: 8.3598 - accuracy: 0.0572\n",
      "1134/1134 [==============================] - 31s 22ms/step - loss: 8.8707 - accuracy: 0.0440\n",
      "219/219 [==============================] - 2s 6ms/step - loss: 8.7146 - accuracy: 0.0490\n",
      "1134/1134 [==============================] - 25s 22ms/step - loss: 8.8320 - accuracy: 0.0468\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 8.4151 - accuracy: 0.0487\n",
      "1149/1149 [==============================] - 25s 21ms/step - loss: 8.8690 - accuracy: 0.0479\n",
      "203/203 [==============================] - 1s 6ms/step - loss: 8.4598 - accuracy: 0.0433\n",
      "1136/1136 [==============================] - 25s 22ms/step - loss: 8.8809 - accuracy: 0.0442\n",
      "217/217 [==============================] - 1s 6ms/step - loss: 8.7523 - accuracy: 0.0526\n",
      "1248/1248 [==============================] - 26s 20ms/step - loss: 8.8476 - accuracy: 0.0463\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 9.0772 - accuracy: 0.0610\n",
      "1131/1131 [==============================] - 23s 20ms/step - loss: 8.8486 - accuracy: 0.0448\n",
      "221/221 [==============================] - 2s 6ms/step - loss: 8.9625 - accuracy: 0.0515\n",
      "1291/1291 [==============================] - 26s 20ms/step - loss: 8.8155 - accuracy: 0.0481\n",
      "61/61 [==============================] - 1s 8ms/step - loss: 8.4451 - accuracy: 0.0424\n",
      "1242/1242 [==============================] - 19s 15ms/step - loss: 8.7108 - accuracy: 0.0461\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 8.6368 - accuracy: 0.0569\n",
      "1134/1134 [==============================] - 17s 15ms/step - loss: 8.7110 - accuracy: 0.0471\n",
      "219/219 [==============================] - 8s 6ms/step - loss: 8.7445 - accuracy: 0.0482\n",
      "1134/1134 [==============================] - 21s 18ms/step - loss: 8.7104 - accuracy: 0.0481\n",
      "219/219 [==============================] - 2s 6ms/step - loss: 8.6088 - accuracy: 0.0501\n",
      "1149/1149 [==============================] - 19s 16ms/step - loss: 8.7724 - accuracy: 0.0470\n",
      "203/203 [==============================] - 2s 10ms/step - loss: 8.7240 - accuracy: 0.0433\n",
      "1136/1136 [==============================] - 19s 16ms/step - loss: 8.8139 - accuracy: 0.0463\n",
      "217/217 [==============================] - 2s 7ms/step - loss: 8.6251 - accuracy: 0.0537\n",
      "1248/1248 [==============================] - 20s 16ms/step - loss: 8.7602 - accuracy: 0.0468\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 8.6171 - accuracy: 0.0598\n",
      "1131/1131 [==============================] - 19s 17ms/step - loss: 8.7454 - accuracy: 0.0474\n",
      "221/221 [==============================] - 2s 7ms/step - loss: 8.7481 - accuracy: 0.0520\n",
      "1291/1291 [==============================] - 21s 15ms/step - loss: 8.7142 - accuracy: 0.0481\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 8.7593 - accuracy: 0.0424\n",
      "1242/1242 [==============================] - 30s 23ms/step - loss: 8.8469 - accuracy: 0.0447\n",
      "110/110 [==============================] - 1s 8ms/step - loss: 8.6025 - accuracy: 0.0572\n",
      "1134/1134 [==============================] - 30s 26ms/step - loss: 8.8852 - accuracy: 0.0446\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 8.6956 - accuracy: 0.0490\n",
      "1134/1134 [==============================] - 28s 25ms/step - loss: 8.8529 - accuracy: 0.0447\n",
      "219/219 [==============================] - 2s 6ms/step - loss: 9.0870 - accuracy: 0.0487\n",
      "1149/1149 [==============================] - 32s 23ms/step - loss: 8.9572 - accuracy: 0.0457\n",
      "203/203 [==============================] - 1s 6ms/step - loss: 8.3963 - accuracy: 0.0433\n",
      "1136/1136 [==============================] - 24s 21ms/step - loss: 8.8241 - accuracy: 0.0433\n",
      "217/217 [==============================] - 2s 6ms/step - loss: 9.0540 - accuracy: 0.0526\n",
      "1248/1248 [==============================] - 28s 22ms/step - loss: 8.8288 - accuracy: 0.0434\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 9.0365 - accuracy: 0.0610\n",
      "1131/1131 [==============================] - 25s 22ms/step - loss: 8.8059 - accuracy: 0.0455\n",
      "221/221 [==============================] - 2s 7ms/step - loss: 8.3813 - accuracy: 0.0515\n",
      "1291/1291 [==============================] - 27s 21ms/step - loss: 8.8221 - accuracy: 0.0456\n",
      "61/61 [==============================] - 1s 11ms/step - loss: 8.5084 - accuracy: 0.0424\n",
      "1352/1352 [==============================] - 21s 15ms/step - loss: 8.7474 - accuracy: 0.0457\n",
      "Finished!\n",
      "Best: 0.051422 using {'batch_size': 64, 'nb_epoch': 1, 'optimizer': 'adam'}\n",
      "1352/1352 [==============================] - 8s 6ms/step - loss: 8.2757 - accuracy: 0.0506\n",
      "Train accuracy: 0.0506\n",
      "494/494 [==============================] - 3s 6ms/step - loss: 11.2806 - accuracy: 0.0465\n",
      "Test accuracy : 0.0465\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting!\")\n",
    "gscv_clf.fit(reshaped_values, train_labels)\n",
    "print(\"Finished!\")\n",
    "\n",
    "print(\"Best: %f using %s\" % (gscv_clf.best_score_, gscv_clf.best_params_))\n",
    "print(f\"Train accuracy: {gscv_clf.score(reshaped_values, train_labels):.4f}\")\n",
    "print(f\"Test accuracy : {gscv_clf.score(test_set.values.reshape(-1, 1, 3), test_labels):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 256)               266240    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 20568)             5285976   \n",
      "=================================================================\n",
      "Total params: 5,618,008\n",
      "Trainable params: 5,618,008\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#more elaborate model\n",
    "model_lstm = Sequential()\n",
    "\n",
    "#model_lstm.add(Embedding(input_dim = 3, output_dim = 2, input_length = 86497))\n",
    "#model_lstm.add(SpatialDropout1D(0.3))\n",
    "model_lstm.add(LSTM(256, input_shape = (1, 3), dropout = 0.3, recurrent_dropout = 0.3))\n",
    "model_lstm.add(Dense(256, activation = 'relu'))\n",
    "model_lstm.add(Dropout(0.3))\n",
    "model_lstm.add(Dense(total_unique_words, activation = 'softmax'))\n",
    "\n",
    "model_lstm.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='Adam',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model_lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "2764/2764 [==============================] - 142s 51ms/step - loss: 7.0211 - accuracy: 0.1367\n",
      "Epoch 2/64\n",
      "2764/2764 [==============================] - 139s 50ms/step - loss: 6.7186 - accuracy: 0.1404\n",
      "Epoch 3/64\n",
      "2764/2764 [==============================] - 136s 49ms/step - loss: 6.6844 - accuracy: 0.1413\n",
      "Epoch 4/64\n",
      "2764/2764 [==============================] - 137s 50ms/step - loss: 6.6685 - accuracy: 0.1407\n",
      "Epoch 5/64\n",
      "2764/2764 [==============================] - 140s 51ms/step - loss: 6.6478 - accuracy: 0.1414\n",
      "Epoch 6/64\n",
      "2764/2764 [==============================] - 139s 50ms/step - loss: 6.6358 - accuracy: 0.1409\n",
      "Epoch 7/64\n",
      "2764/2764 [==============================] - 136s 49ms/step - loss: 6.6237 - accuracy: 0.1411\n",
      "Epoch 8/64\n",
      "2764/2764 [==============================] - 139s 50ms/step - loss: 6.6143 - accuracy: 0.1416\n",
      "Epoch 9/64\n",
      "2764/2764 [==============================] - 137s 50ms/step - loss: 6.6013 - accuracy: 0.1422\n",
      "Epoch 10/64\n",
      "2764/2764 [==============================] - 136s 49ms/step - loss: 6.6049 - accuracy: 0.1414\n",
      "Epoch 11/64\n",
      "2764/2764 [==============================] - 136s 49ms/step - loss: 6.6014 - accuracy: 0.1407\n",
      "Epoch 12/64\n",
      "2764/2764 [==============================] - 137s 49ms/step - loss: 6.5906 - accuracy: 0.1420\n",
      "Epoch 13/64\n",
      "2764/2764 [==============================] - 138s 50ms/step - loss: 6.5940 - accuracy: 0.1411\n",
      "Epoch 14/64\n",
      "2764/2764 [==============================] - 136s 49ms/step - loss: 6.5878 - accuracy: 0.1418\n",
      "Epoch 15/64\n",
      "2764/2764 [==============================] - 134s 49ms/step - loss: 6.5859 - accuracy: 0.1410\n",
      "Epoch 16/64\n",
      "2764/2764 [==============================] - 136s 49ms/step - loss: 6.5773 - accuracy: 0.1412\n",
      "Epoch 17/64\n",
      "2764/2764 [==============================] - 118s 43ms/step - loss: 6.5713 - accuracy: 0.1417\n",
      "Epoch 18/64\n",
      "2764/2764 [==============================] - 134s 48ms/step - loss: 6.5686 - accuracy: 0.1417\n",
      "Epoch 19/64\n",
      "2764/2764 [==============================] - 133s 48ms/step - loss: 6.5752 - accuracy: 0.1408\n",
      "Epoch 20/64\n",
      "2764/2764 [==============================] - 131s 48ms/step - loss: 6.5664 - accuracy: 0.1419\n",
      "Epoch 21/64\n",
      "2764/2764 [==============================] - 132s 48ms/step - loss: 6.5620 - accuracy: 0.1421\n",
      "Epoch 22/64\n",
      "2764/2764 [==============================] - 132s 48ms/step - loss: 6.5603 - accuracy: 0.1414\n",
      "Epoch 23/64\n",
      "2764/2764 [==============================] - 131s 48ms/step - loss: 6.5532 - accuracy: 0.1422\n",
      "Epoch 24/64\n",
      "2764/2764 [==============================] - 129s 47ms/step - loss: 6.5612 - accuracy: 0.1419\n",
      "Epoch 25/64\n",
      "2764/2764 [==============================] - 134s 48ms/step - loss: 6.5601 - accuracy: 0.1414\n",
      "Epoch 26/64\n",
      "2764/2764 [==============================] - 133s 48ms/step - loss: 6.5574 - accuracy: 0.1415\n",
      "Epoch 27/64\n",
      "2764/2764 [==============================] - 133s 48ms/step - loss: 6.5615 - accuracy: 0.1410\n",
      "Epoch 28/64\n",
      "2764/2764 [==============================] - 104s 38ms/step - loss: 6.5605 - accuracy: 0.1411\n",
      "Epoch 29/64\n",
      "2764/2764 [==============================] - 93s 34ms/step - loss: 6.5501 - accuracy: 0.1417\n",
      "Epoch 30/64\n",
      "2764/2764 [==============================] - 93s 34ms/step - loss: 6.5526 - accuracy: 0.1421\n",
      "Epoch 31/64\n",
      "2764/2764 [==============================] - 93s 34ms/step - loss: 6.5527 - accuracy: 0.1414\n",
      "Epoch 32/64\n",
      "2764/2764 [==============================] - 94s 34ms/step - loss: 6.5513 - accuracy: 0.1417\n",
      "Epoch 33/64\n",
      "2764/2764 [==============================] - 95s 34ms/step - loss: 6.5533 - accuracy: 0.1412\n",
      "Epoch 34/64\n",
      "2764/2764 [==============================] - 94s 34ms/step - loss: 6.5463 - accuracy: 0.1417\n",
      "Epoch 35/64\n",
      "2764/2764 [==============================] - 94s 34ms/step - loss: 6.5493 - accuracy: 0.1416\n",
      "Epoch 36/64\n",
      "2764/2764 [==============================] - 93s 34ms/step - loss: 6.5441 - accuracy: 0.1418\n",
      "Epoch 37/64\n",
      "2764/2764 [==============================] - 95s 34ms/step - loss: 6.5475 - accuracy: 0.1414\n",
      "Epoch 38/64\n",
      "2764/2764 [==============================] - 96s 35ms/step - loss: 6.5425 - accuracy: 0.1417\n",
      "Epoch 39/64\n",
      "2764/2764 [==============================] - 95s 34ms/step - loss: 6.5403 - accuracy: 0.1427\n",
      "Epoch 40/64\n",
      "2764/2764 [==============================] - 94s 34ms/step - loss: 6.5388 - accuracy: 0.1422\n",
      "Epoch 41/64\n",
      "2764/2764 [==============================] - 93s 34ms/step - loss: 6.5419 - accuracy: 0.1417\n",
      "Epoch 42/64\n",
      "2764/2764 [==============================] - 94s 34ms/step - loss: 6.5355 - accuracy: 0.1424\n",
      "Epoch 43/64\n",
      "2764/2764 [==============================] - 92s 33ms/step - loss: 6.5430 - accuracy: 0.1413\n",
      "Epoch 44/64\n",
      "2764/2764 [==============================] - 95s 34ms/step - loss: 6.5341 - accuracy: 0.1414\n",
      "Epoch 45/64\n",
      "2764/2764 [==============================] - 94s 34ms/step - loss: 6.5383 - accuracy: 0.1414\n",
      "Epoch 46/64\n",
      "2764/2764 [==============================] - 93s 34ms/step - loss: 6.5459 - accuracy: 0.1407\n",
      "Epoch 47/64\n",
      "2764/2764 [==============================] - 93s 34ms/step - loss: 6.5342 - accuracy: 0.1421\n",
      "Epoch 48/64\n",
      "2764/2764 [==============================] - 93s 34ms/step - loss: 6.5348 - accuracy: 0.1426\n",
      "Epoch 49/64\n",
      "2764/2764 [==============================] - 94s 34ms/step - loss: 6.5302 - accuracy: 0.1427\n",
      "Epoch 50/64\n",
      "2764/2764 [==============================] - 94s 34ms/step - loss: 6.5294 - accuracy: 0.1423\n",
      "Epoch 51/64\n",
      "2764/2764 [==============================] - 94s 34ms/step - loss: 6.5395 - accuracy: 0.1415\n",
      "Epoch 52/64\n",
      "2764/2764 [==============================] - 94s 34ms/step - loss: 6.5316 - accuracy: 0.1422\n",
      "Epoch 53/64\n",
      "2764/2764 [==============================] - 94s 34ms/step - loss: 6.5289 - accuracy: 0.1427\n",
      "Epoch 54/64\n",
      "2764/2764 [==============================] - 93s 34ms/step - loss: 6.5331 - accuracy: 0.1417\n",
      "Epoch 55/64\n",
      "2764/2764 [==============================] - 93s 34ms/step - loss: 6.5347 - accuracy: 0.1419\n",
      "Epoch 56/64\n",
      "2764/2764 [==============================] - 93s 34ms/step - loss: 6.5239 - accuracy: 0.1426\n",
      "Epoch 57/64\n",
      "2764/2764 [==============================] - 93s 33ms/step - loss: 6.5244 - accuracy: 0.1429\n",
      "Epoch 58/64\n",
      "2764/2764 [==============================] - 92s 33ms/step - loss: 6.5263 - accuracy: 0.1419\n",
      "Epoch 59/64\n",
      "2764/2764 [==============================] - 92s 33ms/step - loss: 6.5274 - accuracy: 0.1420\n",
      "Epoch 60/64\n",
      "2764/2764 [==============================] - 91s 33ms/step - loss: 6.5341 - accuracy: 0.1412\n",
      "Epoch 61/64\n",
      "2764/2764 [==============================] - 94s 34ms/step - loss: 6.5278 - accuracy: 0.1416\n",
      "Epoch 62/64\n",
      "2764/2764 [==============================] - 93s 33ms/step - loss: 6.5203 - accuracy: 0.1429\n",
      "Epoch 63/64\n",
      "2764/2764 [==============================] - 93s 34ms/step - loss: 6.5248 - accuracy: 0.1428\n",
      "Epoch 64/64\n",
      "2764/2764 [==============================] - 93s 34ms/step - loss: 6.5272 - accuracy: 0.1420\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fed7f1cf7b8>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lstm.fit(reshaped_values, train_labels, epochs=64, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22108/22108 [==============================] - 100s 5ms/step - loss: 8.3823 - accuracy: 0.1353\n",
      "train loss, train acc: [8.382338523864746, 0.13532210886478424]\n"
     ]
    }
   ],
   "source": [
    "print(\"train loss, train acc:\", model_lstm.evaluate(reshaped_values, train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8079/8079 [==============================] - 37s 5ms/step - loss: 11.3905 - accuracy: 0.1336\n",
      "test loss, test acc: [11.390458106994629, 0.13362550735473633]\n"
     ]
    }
   ],
   "source": [
    "print(\"test loss, test acc:\", model_lstm.evaluate(test_set.values.reshape(-1, 1, 3), test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Phonemes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(707438, 3281)\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "train_set, train_labels = get_labels(skype_data_train, label=['phonemes'])\n",
    "test_set, test_labels = get_labels(skype_data_test, label=['phonemes'])\n",
    "\n",
    "train_labels, test_labels, _ = prepare_labels(train_labels, test_labels, label=['phonemes'])\n",
    "\n",
    "train_labels = to_categorical(train_labels, num_classes=total_unique_phonemes)\n",
    "test_labels = to_categorical(test_labels, num_classes=total_unique_phonemes)\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0, 32, 32])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshaped_values = train_set.values.reshape(-1, 1, 3)\n",
    "reshaped_values[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "def build_lstm_clf(optimizer='adam', classes=total_unique_phonemes):\n",
    "    model = Sequential()\n",
    "\n",
    "    model_lstm.add(LSTM(256, input_shape = (1, 3), dropout = 0.3, recurrent_dropout = 0.3))\n",
    "    model_lstm.add(Dense(256, activation = 'relu'))\n",
    "    model_lstm.add(Dropout(0.3))\n",
    "    model_lstm.add(Dense(classes, activation = 'softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'batch_size':[64,128,256],\n",
    "          'nb_epoch':[16,32],\n",
    "          'optimizer':['adam', 'rmsprop']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_clf = KerasClassifier(build_fn=build_clf)\n",
    "gscv_clf = GridSearchCV(orig_clf, parameters, cv=cv_dialect_splitter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting!\n",
      "1242/1242 [==============================] - 23s 18ms/step - loss: 8.7184 - accuracy: 0.0474\n",
      "110/110 [==============================] - 1s 6ms/step - loss: 8.6063 - accuracy: 0.0587\n",
      "1134/1134 [==============================] - 21s 18ms/step - loss: 8.7687 - accuracy: 0.0475\n",
      "219/219 [==============================] - 2s 7ms/step - loss: 8.6525 - accuracy: 0.0509\n",
      "1134/1134 [==============================] - 19s 17ms/step - loss: 8.7338 - accuracy: 0.0492\n",
      "219/219 [==============================] - 2s 7ms/step - loss: 8.6538 - accuracy: 0.0519\n",
      "1149/1149 [==============================] - 20s 17ms/step - loss: 8.7412 - accuracy: 0.0499\n",
      "203/203 [==============================] - 2s 7ms/step - loss: 8.5547 - accuracy: 0.0433\n",
      "1136/1136 [==============================] - 19s 16ms/step - loss: 8.7790 - accuracy: 0.0456\n",
      "217/217 [==============================] - 2s 6ms/step - loss: 8.6529 - accuracy: 0.0526\n",
      "1248/1248 [==============================] - 20s 16ms/step - loss: 8.7471 - accuracy: 0.0498\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 8.6892 - accuracy: 0.0610\n",
      "1131/1131 [==============================] - 20s 17ms/step - loss: 8.8528 - accuracy: 0.0460\n",
      "221/221 [==============================] - 2s 7ms/step - loss: 8.8989 - accuracy: 0.0515\n",
      "1291/1291 [==============================] - 21s 16ms/step - loss: 8.8269 - accuracy: 0.0459\n",
      "61/61 [==============================] - 1s 7ms/step - loss: 8.7650 - accuracy: 0.0414\n",
      "1242/1242 [==============================] - 28s 22ms/step - loss: 8.8047 - accuracy: 0.0429\n",
      "110/110 [==============================] - 1s 8ms/step - loss: 8.3598 - accuracy: 0.0572\n",
      "1134/1134 [==============================] - 31s 22ms/step - loss: 8.8707 - accuracy: 0.0440\n",
      "219/219 [==============================] - 2s 6ms/step - loss: 8.7146 - accuracy: 0.0490\n",
      "1134/1134 [==============================] - 25s 22ms/step - loss: 8.8320 - accuracy: 0.0468\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 8.4151 - accuracy: 0.0487\n",
      "1149/1149 [==============================] - 25s 21ms/step - loss: 8.8690 - accuracy: 0.0479\n",
      "203/203 [==============================] - 1s 6ms/step - loss: 8.4598 - accuracy: 0.0433\n",
      "1136/1136 [==============================] - 25s 22ms/step - loss: 8.8809 - accuracy: 0.0442\n",
      "217/217 [==============================] - 1s 6ms/step - loss: 8.7523 - accuracy: 0.0526\n",
      "1248/1248 [==============================] - 26s 20ms/step - loss: 8.8476 - accuracy: 0.0463\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 9.0772 - accuracy: 0.0610\n",
      "1131/1131 [==============================] - 23s 20ms/step - loss: 8.8486 - accuracy: 0.0448\n",
      "221/221 [==============================] - 2s 6ms/step - loss: 8.9625 - accuracy: 0.0515\n",
      "1291/1291 [==============================] - 26s 20ms/step - loss: 8.8155 - accuracy: 0.0481\n",
      "61/61 [==============================] - 1s 8ms/step - loss: 8.4451 - accuracy: 0.0424\n",
      "1242/1242 [==============================] - 19s 15ms/step - loss: 8.7108 - accuracy: 0.0461\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 8.6368 - accuracy: 0.0569\n",
      "1134/1134 [==============================] - 17s 15ms/step - loss: 8.7110 - accuracy: 0.0471\n",
      "219/219 [==============================] - 8s 6ms/step - loss: 8.7445 - accuracy: 0.0482\n",
      "1134/1134 [==============================] - 21s 18ms/step - loss: 8.7104 - accuracy: 0.0481\n",
      "219/219 [==============================] - 2s 6ms/step - loss: 8.6088 - accuracy: 0.0501\n",
      "1149/1149 [==============================] - 19s 16ms/step - loss: 8.7724 - accuracy: 0.0470\n",
      "203/203 [==============================] - 2s 10ms/step - loss: 8.7240 - accuracy: 0.0433\n",
      "1136/1136 [==============================] - 19s 16ms/step - loss: 8.8139 - accuracy: 0.0463\n",
      "217/217 [==============================] - 2s 7ms/step - loss: 8.6251 - accuracy: 0.0537\n",
      "1248/1248 [==============================] - 20s 16ms/step - loss: 8.7602 - accuracy: 0.0468\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 8.6171 - accuracy: 0.0598\n",
      "1131/1131 [==============================] - 19s 17ms/step - loss: 8.7454 - accuracy: 0.0474\n",
      "221/221 [==============================] - 2s 7ms/step - loss: 8.7481 - accuracy: 0.0520\n",
      "1291/1291 [==============================] - 21s 15ms/step - loss: 8.7142 - accuracy: 0.0481\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 8.7593 - accuracy: 0.0424\n",
      "1242/1242 [==============================] - 30s 23ms/step - loss: 8.8469 - accuracy: 0.0447\n",
      "110/110 [==============================] - 1s 8ms/step - loss: 8.6025 - accuracy: 0.0572\n",
      "1134/1134 [==============================] - 30s 26ms/step - loss: 8.8852 - accuracy: 0.0446\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 8.6956 - accuracy: 0.0490\n",
      "1134/1134 [==============================] - 28s 25ms/step - loss: 8.8529 - accuracy: 0.0447\n",
      "219/219 [==============================] - 2s 6ms/step - loss: 9.0870 - accuracy: 0.0487\n",
      "1149/1149 [==============================] - 32s 23ms/step - loss: 8.9572 - accuracy: 0.0457\n",
      "203/203 [==============================] - 1s 6ms/step - loss: 8.3963 - accuracy: 0.0433\n",
      "1136/1136 [==============================] - 24s 21ms/step - loss: 8.8241 - accuracy: 0.0433\n",
      "217/217 [==============================] - 2s 6ms/step - loss: 9.0540 - accuracy: 0.0526\n",
      "1248/1248 [==============================] - 28s 22ms/step - loss: 8.8288 - accuracy: 0.0434\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 9.0365 - accuracy: 0.0610\n",
      "1131/1131 [==============================] - 25s 22ms/step - loss: 8.8059 - accuracy: 0.0455\n",
      "221/221 [==============================] - 2s 7ms/step - loss: 8.3813 - accuracy: 0.0515\n",
      "1291/1291 [==============================] - 27s 21ms/step - loss: 8.8221 - accuracy: 0.0456\n",
      "61/61 [==============================] - 1s 11ms/step - loss: 8.5084 - accuracy: 0.0424\n",
      "1352/1352 [==============================] - 21s 15ms/step - loss: 8.7474 - accuracy: 0.0457\n",
      "Finished!\n",
      "Best: 0.051422 using {'batch_size': 64, 'nb_epoch': 1, 'optimizer': 'adam'}\n",
      "1352/1352 [==============================] - 8s 6ms/step - loss: 8.2757 - accuracy: 0.0506\n",
      "Train accuracy: 0.0506\n",
      "494/494 [==============================] - 3s 6ms/step - loss: 11.2806 - accuracy: 0.0465\n",
      "Test accuracy : 0.0465\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting!\")\n",
    "gscv_clf.fit(reshaped_values, train_labels)\n",
    "print(\"Finished!\")\n",
    "\n",
    "print(\"Best: %f using %s\" % (gscv_clf.best_score_, gscv_clf.best_params_))\n",
    "print(f\"Train accuracy: {gscv_clf.score(reshaped_values, train_labels):.4f}\")\n",
    "print(f\"Test accuracy : {gscv_clf.score(test_set.values.reshape(-1, 1, 3), test_labels):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (None, 256)               266240    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 3281)              843217    \n",
      "=================================================================\n",
      "Total params: 1,175,249\n",
      "Trainable params: 1,175,249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#more elaborate model\n",
    "model_lstm = Sequential()\n",
    "\n",
    "#model_lstm.add(Embedding(input_dim = 3, output_dim = 2, input_length = 86497))\n",
    "#model_lstm.add(SpatialDropout1D(0.3))\n",
    "model_lstm.add(LSTM(256, input_shape = (1, 3), dropout = 0.3, recurrent_dropout = 0.3))\n",
    "model_lstm.add(Dense(256, activation = 'relu'))\n",
    "model_lstm.add(Dropout(0.3))\n",
    "model_lstm.add(Dense(total_unique_phonemes, activation = 'softmax'))\n",
    "\n",
    "model_lstm.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='Adam',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model_lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "2764/2764 [==============================] - 49s 17ms/step - loss: 4.6698 - accuracy: 0.1509\n",
      "Epoch 2/64\n",
      "2764/2764 [==============================] - 45s 16ms/step - loss: 4.2666 - accuracy: 0.1706\n",
      "Epoch 3/64\n",
      "2764/2764 [==============================] - 42s 15ms/step - loss: 4.2308 - accuracy: 0.1725\n",
      "Epoch 4/64\n",
      "2764/2764 [==============================] - 43s 15ms/step - loss: 4.2184 - accuracy: 0.1732\n",
      "Epoch 5/64\n",
      "2764/2764 [==============================] - 43s 16ms/step - loss: 4.2142 - accuracy: 0.1736\n",
      "Epoch 6/64\n",
      "2764/2764 [==============================] - 41s 15ms/step - loss: 4.2074 - accuracy: 0.1746\n",
      "Epoch 7/64\n",
      "2764/2764 [==============================] - 43s 15ms/step - loss: 4.1973 - accuracy: 0.1749\n",
      "Epoch 8/64\n",
      "2764/2764 [==============================] - 41s 15ms/step - loss: 4.1966 - accuracy: 0.1752\n",
      "Epoch 9/64\n",
      "2764/2764 [==============================] - 43s 16ms/step - loss: 4.1909 - accuracy: 0.1754\n",
      "Epoch 10/64\n",
      "2764/2764 [==============================] - 42s 15ms/step - loss: 4.1867 - accuracy: 0.1754\n",
      "Epoch 11/64\n",
      "2764/2764 [==============================] - 43s 15ms/step - loss: 4.1838 - accuracy: 0.1752\n",
      "Epoch 12/64\n",
      "2764/2764 [==============================] - 43s 15ms/step - loss: 4.1860 - accuracy: 0.1752\n",
      "Epoch 13/64\n",
      "2764/2764 [==============================] - 43s 16ms/step - loss: 4.1811 - accuracy: 0.1760\n",
      "Epoch 14/64\n",
      "2764/2764 [==============================] - 44s 16ms/step - loss: 4.1822 - accuracy: 0.1761\n",
      "Epoch 15/64\n",
      "2764/2764 [==============================] - 43s 16ms/step - loss: 4.1776 - accuracy: 0.1756\n",
      "Epoch 16/64\n",
      "2764/2764 [==============================] - 43s 15ms/step - loss: 4.1755 - accuracy: 0.1765\n",
      "Epoch 17/64\n",
      "2764/2764 [==============================] - 43s 15ms/step - loss: 4.1783 - accuracy: 0.1758\n",
      "Epoch 18/64\n",
      "2764/2764 [==============================] - 42s 15ms/step - loss: 4.1767 - accuracy: 0.1754\n",
      "Epoch 19/64\n",
      "2764/2764 [==============================] - 41s 15ms/step - loss: 4.1731 - accuracy: 0.1758\n",
      "Epoch 20/64\n",
      "2764/2764 [==============================] - 42s 15ms/step - loss: 4.1771 - accuracy: 0.1758\n",
      "Epoch 21/64\n",
      "2764/2764 [==============================] - 43s 16ms/step - loss: 4.1715 - accuracy: 0.1757\n",
      "Epoch 22/64\n",
      "2764/2764 [==============================] - 44s 16ms/step - loss: 4.1725 - accuracy: 0.1764\n",
      "Epoch 23/64\n",
      "2764/2764 [==============================] - 43s 16ms/step - loss: 4.1724 - accuracy: 0.1761\n",
      "Epoch 24/64\n",
      "2764/2764 [==============================] - 43s 16ms/step - loss: 4.1686 - accuracy: 0.1762\n",
      "Epoch 25/64\n",
      "2764/2764 [==============================] - 41s 15ms/step - loss: 4.1699 - accuracy: 0.1759\n",
      "Epoch 26/64\n",
      "2764/2764 [==============================] - 43s 15ms/step - loss: 4.1711 - accuracy: 0.1766\n",
      "Epoch 27/64\n",
      "2764/2764 [==============================] - 42s 15ms/step - loss: 4.1691 - accuracy: 0.1759\n",
      "Epoch 28/64\n",
      "2764/2764 [==============================] - 42s 15ms/step - loss: 4.1698 - accuracy: 0.1762\n",
      "Epoch 29/64\n",
      "2764/2764 [==============================] - 41s 15ms/step - loss: 4.1679 - accuracy: 0.1760\n",
      "Epoch 30/64\n",
      "2764/2764 [==============================] - 41s 15ms/step - loss: 4.1657 - accuracy: 0.1766\n",
      "Epoch 31/64\n",
      "2764/2764 [==============================] - 42s 15ms/step - loss: 4.1643 - accuracy: 0.1766\n",
      "Epoch 32/64\n",
      "2764/2764 [==============================] - 42s 15ms/step - loss: 4.1653 - accuracy: 0.1759\n",
      "Epoch 33/64\n",
      "2764/2764 [==============================] - 41s 15ms/step - loss: 4.1635 - accuracy: 0.1764\n",
      "Epoch 34/64\n",
      "2764/2764 [==============================] - 40s 14ms/step - loss: 4.1717 - accuracy: 0.1760\n",
      "Epoch 35/64\n",
      "2764/2764 [==============================] - 41s 15ms/step - loss: 4.1680 - accuracy: 0.1760\n",
      "Epoch 36/64\n",
      "2764/2764 [==============================] - 41s 15ms/step - loss: 4.1574 - accuracy: 0.1763\n",
      "Epoch 37/64\n",
      "2764/2764 [==============================] - 41s 15ms/step - loss: 4.1661 - accuracy: 0.1763\n",
      "Epoch 38/64\n",
      "2764/2764 [==============================] - 42s 15ms/step - loss: 4.1622 - accuracy: 0.1767\n",
      "Epoch 39/64\n",
      "2764/2764 [==============================] - 42s 15ms/step - loss: 4.1655 - accuracy: 0.1762\n",
      "Epoch 40/64\n",
      "2764/2764 [==============================] - 41s 15ms/step - loss: 4.1637 - accuracy: 0.1759\n",
      "Epoch 41/64\n",
      "2764/2764 [==============================] - 41s 15ms/step - loss: 4.1631 - accuracy: 0.1765\n",
      "Epoch 42/64\n",
      "2764/2764 [==============================] - 41s 15ms/step - loss: 4.1646 - accuracy: 0.1764\n",
      "Epoch 43/64\n",
      "2764/2764 [==============================] - 41s 15ms/step - loss: 4.1635 - accuracy: 0.1764\n",
      "Epoch 44/64\n",
      "2764/2764 [==============================] - 42s 15ms/step - loss: 4.1578 - accuracy: 0.1776\n",
      "Epoch 45/64\n",
      "2764/2764 [==============================] - 41s 15ms/step - loss: 4.1663 - accuracy: 0.1764\n",
      "Epoch 46/64\n",
      "2764/2764 [==============================] - 42s 15ms/step - loss: 4.1622 - accuracy: 0.1769\n",
      "Epoch 47/64\n",
      "2764/2764 [==============================] - 44s 16ms/step - loss: 4.1594 - accuracy: 0.1770\n",
      "Epoch 48/64\n",
      "2764/2764 [==============================] - 43s 15ms/step - loss: 4.1614 - accuracy: 0.1770\n",
      "Epoch 49/64\n",
      "2764/2764 [==============================] - 43s 15ms/step - loss: 4.1594 - accuracy: 0.1769\n",
      "Epoch 50/64\n",
      "2764/2764 [==============================] - 41s 15ms/step - loss: 4.1600 - accuracy: 0.1766\n",
      "Epoch 51/64\n",
      "2764/2764 [==============================] - 43s 16ms/step - loss: 4.1603 - accuracy: 0.1764\n",
      "Epoch 52/64\n",
      "2764/2764 [==============================] - 45s 16ms/step - loss: 4.1615 - accuracy: 0.1774\n",
      "Epoch 53/64\n",
      "2764/2764 [==============================] - 44s 16ms/step - loss: 4.1628 - accuracy: 0.1760\n",
      "Epoch 54/64\n",
      "2764/2764 [==============================] - 44s 16ms/step - loss: 4.1571 - accuracy: 0.1772\n",
      "Epoch 55/64\n",
      "2764/2764 [==============================] - 41s 15ms/step - loss: 4.1580 - accuracy: 0.1774\n",
      "Epoch 56/64\n",
      "2764/2764 [==============================] - 45s 16ms/step - loss: 4.1563 - accuracy: 0.1772\n",
      "Epoch 57/64\n",
      "2764/2764 [==============================] - 44s 16ms/step - loss: 4.1649 - accuracy: 0.1760\n",
      "Epoch 58/64\n",
      "2764/2764 [==============================] - 43s 15ms/step - loss: 4.1625 - accuracy: 0.1764\n",
      "Epoch 59/64\n",
      "2764/2764 [==============================] - 44s 16ms/step - loss: 4.1629 - accuracy: 0.1757\n",
      "Epoch 60/64\n",
      "2764/2764 [==============================] - 43s 16ms/step - loss: 4.1634 - accuracy: 0.1763\n",
      "Epoch 61/64\n",
      "2764/2764 [==============================] - 42s 15ms/step - loss: 4.1620 - accuracy: 0.1768\n",
      "Epoch 62/64\n",
      "2764/2764 [==============================] - 43s 16ms/step - loss: 4.1609 - accuracy: 0.1772\n",
      "Epoch 63/64\n",
      "2764/2764 [==============================] - 43s 16ms/step - loss: 4.1613 - accuracy: 0.1766\n",
      "Epoch 64/64\n",
      "2764/2764 [==============================] - 43s 16ms/step - loss: 4.1637 - accuracy: 0.1768\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f58b7e112b0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lstm.fit(reshaped_values, train_labels, epochs=64, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8079/8079 [==============================] - 32s 3ms/step - loss: 7.0681 - accuracy: 0.1187\n",
      "test loss, test acc: [7.068105220794678, 0.118659608066082]\n"
     ]
    }
   ],
   "source": [
    "print(\"test loss, test acc:\", model_lstm.evaluate(test_set.values.reshape(-1, 1, 3), test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the 2 most spoken sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_1 = \"She had your dark suit in greasy wash water all year.\"\n",
    "sentence_2 = \"Don't ask me to carry an oily rag like that.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>file</th>\n",
       "      <th>speaker</th>\n",
       "      <th>sentence</th>\n",
       "      <th>previous_packet</th>\n",
       "      <th>next_packet</th>\n",
       "      <th>packet_size</th>\n",
       "      <th>prev_curr</th>\n",
       "      <th>next_curr</th>\n",
       "      <th>packet_surrounding</th>\n",
       "      <th>phonemes</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>DR1-FCJF0-SA1.CSV</td>\n",
       "      <td>DR1-FCJF0</td>\n",
       "      <td>She had your dark suit in greasy wash water al...</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>(0, 32)</td>\n",
       "      <td>(32, 32)</td>\n",
       "      <td>(0, 32, 32)</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>DR1-FCJF0-SA1.CSV</td>\n",
       "      <td>DR1-FCJF0</td>\n",
       "      <td>She had your dark suit in greasy wash water al...</td>\n",
       "      <td>32</td>\n",
       "      <td>31</td>\n",
       "      <td>32</td>\n",
       "      <td>(32, 32)</td>\n",
       "      <td>(31, 32)</td>\n",
       "      <td>(32, 32, 31)</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>DR1-FCJF0-SA1.CSV</td>\n",
       "      <td>DR1-FCJF0</td>\n",
       "      <td>She had your dark suit in greasy wash water al...</td>\n",
       "      <td>32</td>\n",
       "      <td>28</td>\n",
       "      <td>31</td>\n",
       "      <td>(32, 31)</td>\n",
       "      <td>(28, 31)</td>\n",
       "      <td>(32, 31, 28)</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>DR1-FCJF0-SA1.CSV</td>\n",
       "      <td>DR1-FCJF0</td>\n",
       "      <td>She had your dark suit in greasy wash water al...</td>\n",
       "      <td>31</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>(31, 28)</td>\n",
       "      <td>(28, 28)</td>\n",
       "      <td>(31, 28, 28)</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>DR1-FCJF0-SA1.CSV</td>\n",
       "      <td>DR1-FCJF0</td>\n",
       "      <td>She had your dark suit in greasy wash water al...</td>\n",
       "      <td>28</td>\n",
       "      <td>36</td>\n",
       "      <td>28</td>\n",
       "      <td>(28, 28)</td>\n",
       "      <td>(36, 28)</td>\n",
       "      <td>(28, 28, 36)</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142973</th>\n",
       "      <td>706238</td>\n",
       "      <td>DR8-MTCS0-SA2.CSV</td>\n",
       "      <td>DR8-MTCS0</td>\n",
       "      <td>Don't ask me to carry an oily rag like that.</td>\n",
       "      <td>30</td>\n",
       "      <td>47</td>\n",
       "      <td>27</td>\n",
       "      <td>(30, 27)</td>\n",
       "      <td>(47, 27)</td>\n",
       "      <td>(30, 27, 47)</td>\n",
       "      <td>(tcl,)</td>\n",
       "      <td>(that,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142974</th>\n",
       "      <td>706239</td>\n",
       "      <td>DR8-MTCS0-SA2.CSV</td>\n",
       "      <td>DR8-MTCS0</td>\n",
       "      <td>Don't ask me to carry an oily rag like that.</td>\n",
       "      <td>27</td>\n",
       "      <td>49</td>\n",
       "      <td>47</td>\n",
       "      <td>(27, 47)</td>\n",
       "      <td>(49, 47)</td>\n",
       "      <td>(27, 47, 49)</td>\n",
       "      <td>(tcl, h#)</td>\n",
       "      <td>(that,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142975</th>\n",
       "      <td>706240</td>\n",
       "      <td>DR8-MTCS0-SA2.CSV</td>\n",
       "      <td>DR8-MTCS0</td>\n",
       "      <td>Don't ask me to carry an oily rag like that.</td>\n",
       "      <td>47</td>\n",
       "      <td>40</td>\n",
       "      <td>49</td>\n",
       "      <td>(47, 49)</td>\n",
       "      <td>(40, 49)</td>\n",
       "      <td>(47, 49, 40)</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142976</th>\n",
       "      <td>706241</td>\n",
       "      <td>DR8-MTCS0-SA2.CSV</td>\n",
       "      <td>DR8-MTCS0</td>\n",
       "      <td>Don't ask me to carry an oily rag like that.</td>\n",
       "      <td>49</td>\n",
       "      <td>50</td>\n",
       "      <td>40</td>\n",
       "      <td>(49, 40)</td>\n",
       "      <td>(50, 40)</td>\n",
       "      <td>(49, 40, 50)</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142977</th>\n",
       "      <td>706242</td>\n",
       "      <td>DR8-MTCS0-SA2.CSV</td>\n",
       "      <td>DR8-MTCS0</td>\n",
       "      <td>Don't ask me to carry an oily rag like that.</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>(40, 50)</td>\n",
       "      <td>(0, 50)</td>\n",
       "      <td>(40, 50, 0)</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>142978 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         index               file    speaker  \\\n",
       "0            0  DR1-FCJF0-SA1.CSV  DR1-FCJF0   \n",
       "1            1  DR1-FCJF0-SA1.CSV  DR1-FCJF0   \n",
       "2            2  DR1-FCJF0-SA1.CSV  DR1-FCJF0   \n",
       "3            3  DR1-FCJF0-SA1.CSV  DR1-FCJF0   \n",
       "4            4  DR1-FCJF0-SA1.CSV  DR1-FCJF0   \n",
       "...        ...                ...        ...   \n",
       "142973  706238  DR8-MTCS0-SA2.CSV  DR8-MTCS0   \n",
       "142974  706239  DR8-MTCS0-SA2.CSV  DR8-MTCS0   \n",
       "142975  706240  DR8-MTCS0-SA2.CSV  DR8-MTCS0   \n",
       "142976  706241  DR8-MTCS0-SA2.CSV  DR8-MTCS0   \n",
       "142977  706242  DR8-MTCS0-SA2.CSV  DR8-MTCS0   \n",
       "\n",
       "                                                 sentence  previous_packet  \\\n",
       "0       She had your dark suit in greasy wash water al...                0   \n",
       "1       She had your dark suit in greasy wash water al...               32   \n",
       "2       She had your dark suit in greasy wash water al...               32   \n",
       "3       She had your dark suit in greasy wash water al...               31   \n",
       "4       She had your dark suit in greasy wash water al...               28   \n",
       "...                                                   ...              ...   \n",
       "142973       Don't ask me to carry an oily rag like that.               30   \n",
       "142974       Don't ask me to carry an oily rag like that.               27   \n",
       "142975       Don't ask me to carry an oily rag like that.               47   \n",
       "142976       Don't ask me to carry an oily rag like that.               49   \n",
       "142977       Don't ask me to carry an oily rag like that.               40   \n",
       "\n",
       "        next_packet  packet_size prev_curr next_curr packet_surrounding  \\\n",
       "0                32           32   (0, 32)  (32, 32)        (0, 32, 32)   \n",
       "1                31           32  (32, 32)  (31, 32)       (32, 32, 31)   \n",
       "2                28           31  (32, 31)  (28, 31)       (32, 31, 28)   \n",
       "3                28           28  (31, 28)  (28, 28)       (31, 28, 28)   \n",
       "4                36           28  (28, 28)  (36, 28)       (28, 28, 36)   \n",
       "...             ...          ...       ...       ...                ...   \n",
       "142973           47           27  (30, 27)  (47, 27)       (30, 27, 47)   \n",
       "142974           49           47  (27, 47)  (49, 47)       (27, 47, 49)   \n",
       "142975           40           49  (47, 49)  (40, 49)       (47, 49, 40)   \n",
       "142976           50           40  (49, 40)  (50, 40)       (49, 40, 50)   \n",
       "142977            0           50  (40, 50)   (0, 50)        (40, 50, 0)   \n",
       "\n",
       "         phonemes    words  \n",
       "0           (h#,)      (,)  \n",
       "1           (h#,)      (,)  \n",
       "2           (h#,)      (,)  \n",
       "3           (h#,)      (,)  \n",
       "4           (h#,)      (,)  \n",
       "...           ...      ...  \n",
       "142973     (tcl,)  (that,)  \n",
       "142974  (tcl, h#)  (that,)  \n",
       "142975      (h#,)      (,)  \n",
       "142976      (h#,)      (,)  \n",
       "142977      (h#,)      (,)  \n",
       "\n",
       "[142978 rows x 12 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_sentence_train = skype_data_train.loc[skype_data_train[\"sentence\"].isin([sentence_1, sentence_2])]\n",
    "two_sentence_train.reset_index(inplace=True)\n",
    "two_sentence_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>speaker</th>\n",
       "      <th>sentence</th>\n",
       "      <th>previous_packet</th>\n",
       "      <th>next_packet</th>\n",
       "      <th>packet_size</th>\n",
       "      <th>prev_curr</th>\n",
       "      <th>next_curr</th>\n",
       "      <th>packet_surrounding</th>\n",
       "      <th>phonemes</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DR1-FAKS0-SA1.CSV</td>\n",
       "      <td>DR1-FAKS0</td>\n",
       "      <td>She had your dark suit in greasy wash water al...</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>30</td>\n",
       "      <td>(0, 30)</td>\n",
       "      <td>(35, 30)</td>\n",
       "      <td>(0, 30, 35)</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DR1-FAKS0-SA1.CSV</td>\n",
       "      <td>DR1-FAKS0</td>\n",
       "      <td>She had your dark suit in greasy wash water al...</td>\n",
       "      <td>30</td>\n",
       "      <td>43</td>\n",
       "      <td>35</td>\n",
       "      <td>(30, 35)</td>\n",
       "      <td>(43, 35)</td>\n",
       "      <td>(30, 35, 43)</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DR1-FAKS0-SA1.CSV</td>\n",
       "      <td>DR1-FAKS0</td>\n",
       "      <td>She had your dark suit in greasy wash water al...</td>\n",
       "      <td>35</td>\n",
       "      <td>26</td>\n",
       "      <td>43</td>\n",
       "      <td>(35, 43)</td>\n",
       "      <td>(26, 43)</td>\n",
       "      <td>(35, 43, 26)</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DR1-FAKS0-SA1.CSV</td>\n",
       "      <td>DR1-FAKS0</td>\n",
       "      <td>She had your dark suit in greasy wash water al...</td>\n",
       "      <td>43</td>\n",
       "      <td>30</td>\n",
       "      <td>26</td>\n",
       "      <td>(43, 26)</td>\n",
       "      <td>(30, 26)</td>\n",
       "      <td>(43, 26, 30)</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DR1-FAKS0-SA1.CSV</td>\n",
       "      <td>DR1-FAKS0</td>\n",
       "      <td>She had your dark suit in greasy wash water al...</td>\n",
       "      <td>26</td>\n",
       "      <td>31</td>\n",
       "      <td>30</td>\n",
       "      <td>(26, 30)</td>\n",
       "      <td>(31, 30)</td>\n",
       "      <td>(26, 30, 31)</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52356</th>\n",
       "      <td>DR8-MSLB0-SA2.CSV</td>\n",
       "      <td>DR8-MSLB0</td>\n",
       "      <td>Don't ask me to carry an oily rag like that.</td>\n",
       "      <td>47</td>\n",
       "      <td>36</td>\n",
       "      <td>32</td>\n",
       "      <td>(47, 32)</td>\n",
       "      <td>(36, 32)</td>\n",
       "      <td>(47, 32, 36)</td>\n",
       "      <td>(tcl,)</td>\n",
       "      <td>(that,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52357</th>\n",
       "      <td>DR8-MSLB0-SA2.CSV</td>\n",
       "      <td>DR8-MSLB0</td>\n",
       "      <td>Don't ask me to carry an oily rag like that.</td>\n",
       "      <td>32</td>\n",
       "      <td>27</td>\n",
       "      <td>36</td>\n",
       "      <td>(32, 36)</td>\n",
       "      <td>(27, 36)</td>\n",
       "      <td>(32, 36, 27)</td>\n",
       "      <td>(tcl,)</td>\n",
       "      <td>(that,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52358</th>\n",
       "      <td>DR8-MSLB0-SA2.CSV</td>\n",
       "      <td>DR8-MSLB0</td>\n",
       "      <td>Don't ask me to carry an oily rag like that.</td>\n",
       "      <td>36</td>\n",
       "      <td>26</td>\n",
       "      <td>27</td>\n",
       "      <td>(36, 27)</td>\n",
       "      <td>(26, 27)</td>\n",
       "      <td>(36, 27, 26)</td>\n",
       "      <td>(tcl, h#)</td>\n",
       "      <td>(that,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52359</th>\n",
       "      <td>DR8-MSLB0-SA2.CSV</td>\n",
       "      <td>DR8-MSLB0</td>\n",
       "      <td>Don't ask me to carry an oily rag like that.</td>\n",
       "      <td>27</td>\n",
       "      <td>24</td>\n",
       "      <td>26</td>\n",
       "      <td>(27, 26)</td>\n",
       "      <td>(24, 26)</td>\n",
       "      <td>(27, 26, 24)</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52360</th>\n",
       "      <td>DR8-MSLB0-SA2.CSV</td>\n",
       "      <td>DR8-MSLB0</td>\n",
       "      <td>Don't ask me to carry an oily rag like that.</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>(26, 24)</td>\n",
       "      <td>(0, 24)</td>\n",
       "      <td>(26, 24, 0)</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>52361 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    file    speaker  \\\n",
       "0      DR1-FAKS0-SA1.CSV  DR1-FAKS0   \n",
       "1      DR1-FAKS0-SA1.CSV  DR1-FAKS0   \n",
       "2      DR1-FAKS0-SA1.CSV  DR1-FAKS0   \n",
       "3      DR1-FAKS0-SA1.CSV  DR1-FAKS0   \n",
       "4      DR1-FAKS0-SA1.CSV  DR1-FAKS0   \n",
       "...                  ...        ...   \n",
       "52356  DR8-MSLB0-SA2.CSV  DR8-MSLB0   \n",
       "52357  DR8-MSLB0-SA2.CSV  DR8-MSLB0   \n",
       "52358  DR8-MSLB0-SA2.CSV  DR8-MSLB0   \n",
       "52359  DR8-MSLB0-SA2.CSV  DR8-MSLB0   \n",
       "52360  DR8-MSLB0-SA2.CSV  DR8-MSLB0   \n",
       "\n",
       "                                                sentence  previous_packet  \\\n",
       "0      She had your dark suit in greasy wash water al...                0   \n",
       "1      She had your dark suit in greasy wash water al...               30   \n",
       "2      She had your dark suit in greasy wash water al...               35   \n",
       "3      She had your dark suit in greasy wash water al...               43   \n",
       "4      She had your dark suit in greasy wash water al...               26   \n",
       "...                                                  ...              ...   \n",
       "52356       Don't ask me to carry an oily rag like that.               47   \n",
       "52357       Don't ask me to carry an oily rag like that.               32   \n",
       "52358       Don't ask me to carry an oily rag like that.               36   \n",
       "52359       Don't ask me to carry an oily rag like that.               27   \n",
       "52360       Don't ask me to carry an oily rag like that.               26   \n",
       "\n",
       "       next_packet  packet_size prev_curr next_curr packet_surrounding  \\\n",
       "0               35           30   (0, 30)  (35, 30)        (0, 30, 35)   \n",
       "1               43           35  (30, 35)  (43, 35)       (30, 35, 43)   \n",
       "2               26           43  (35, 43)  (26, 43)       (35, 43, 26)   \n",
       "3               30           26  (43, 26)  (30, 26)       (43, 26, 30)   \n",
       "4               31           30  (26, 30)  (31, 30)       (26, 30, 31)   \n",
       "...            ...          ...       ...       ...                ...   \n",
       "52356           36           32  (47, 32)  (36, 32)       (47, 32, 36)   \n",
       "52357           27           36  (32, 36)  (27, 36)       (32, 36, 27)   \n",
       "52358           26           27  (36, 27)  (26, 27)       (36, 27, 26)   \n",
       "52359           24           26  (27, 26)  (24, 26)       (27, 26, 24)   \n",
       "52360            0           24  (26, 24)   (0, 24)        (26, 24, 0)   \n",
       "\n",
       "        phonemes    words  \n",
       "0          (h#,)      (,)  \n",
       "1          (h#,)      (,)  \n",
       "2          (h#,)      (,)  \n",
       "3          (h#,)      (,)  \n",
       "4          (h#,)      (,)  \n",
       "...          ...      ...  \n",
       "52356     (tcl,)  (that,)  \n",
       "52357     (tcl,)  (that,)  \n",
       "52358  (tcl, h#)  (that,)  \n",
       "52359      (h#,)      (,)  \n",
       "52360      (h#,)      (,)  \n",
       "\n",
       "[52361 rows x 11 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_sentence_test = skype_data_test.loc[skype_data_test[\"sentence\"].isin([sentence_1, sentence_2])]\n",
    "two_sentence_test.reset_index(inplace=True, drop=True)\n",
    "two_sentence_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, train_labels = get_labels(two_sentence_train, label=[\"words\"])\n",
    "test_set, test_labels = get_labels(two_sentence_test, label=[\"words\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n",
      "41\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_labels_2 = train_labels.append(test_labels)\n",
    "print(len(pd.unique(train_labels.words)))\n",
    "print(len(pd.unique(test_labels.words)))\n",
    "total_unique_words_2 = len(pd.unique(total_labels_2.words))\n",
    "total_unique_words_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xkadlec6/.local/lib/python3.6/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "train_labels, test_labels, _ = prepare_labels(train_labels, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(142978, 42)\n"
     ]
    }
   ],
   "source": [
    "train_labels = to_categorical(train_labels, num_classes=total_unique_words_2)\n",
    "test_labels = to_categorical(test_labels, num_classes=total_unique_words_2)\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BE CAREFUL ABOUT TOTAL WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "def build_clf(optimizer='adam', classes=total_unique_words_2):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(units=512, activation='relu', input_dim=3*1))  # first hidden layer\n",
    "    model.add(Dense(units=256, activation='relu'))  # second hidden layer\n",
    "    # model.add(Dense(units=128, activation='relu'))  # third hidden layer\n",
    "    model.add(Dense(units=classes, activation='softmax'))  # output layer\n",
    "    # model.add(Dense(units=128))  # output layer\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'batch_size':[64,128,256],\n",
    "          'nb_epoch':[16,32],\n",
    "          'optimizer':['adam', 'rmsprop']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_clf = KerasClassifier(build_fn=build_clf)\n",
    "gscv_clf = GridSearchCV(orig_clf, parameters, cv=cv_dialect_splitter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 42)                10794     \n",
      "=================================================================\n",
      "Total params: 144,170\n",
      "Trainable params: 144,170\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(units=512, activation='relu', input_dim=3*1))  # first hidden layer\n",
    "model.add(Dense(units=256, activation='relu'))  # second hidden layer\n",
    "# model.add(Dense(units=128, activation='relu'))  # third hidden layer\n",
    "model.add(Dense(units=total_unique_words_2, activation='softmax'))  # output layer\n",
    "# model.add(Dense(units=128))  # output layer\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "559/559 [==============================] - 3s 4ms/step - loss: 3.5795 - accuracy: 0.1208\n",
      "Epoch 2/64\n",
      "559/559 [==============================] - 2s 4ms/step - loss: 2.9167 - accuracy: 0.1817\n",
      "Epoch 3/64\n",
      "559/559 [==============================] - 2s 4ms/step - loss: 2.8285 - accuracy: 0.1941\n",
      "Epoch 4/64\n",
      "559/559 [==============================] - 2s 4ms/step - loss: 2.8107 - accuracy: 0.1965\n",
      "Epoch 5/64\n",
      "559/559 [==============================] - 2s 4ms/step - loss: 2.7893 - accuracy: 0.1997\n",
      "Epoch 6/64\n",
      "559/559 [==============================] - 2s 4ms/step - loss: 2.7794 - accuracy: 0.2021\n",
      "Epoch 7/64\n",
      "559/559 [==============================] - 2s 4ms/step - loss: 2.7655 - accuracy: 0.2047\n",
      "Epoch 8/64\n",
      "559/559 [==============================] - 2s 4ms/step - loss: 2.7634 - accuracy: 0.2054\n",
      "Epoch 9/64\n",
      "559/559 [==============================] - 2s 4ms/step - loss: 2.7544 - accuracy: 0.2071\n",
      "Epoch 10/64\n",
      "559/559 [==============================] - 2s 4ms/step - loss: 2.7511 - accuracy: 0.2077\n",
      "Epoch 11/64\n",
      "559/559 [==============================] - 2s 4ms/step - loss: 2.7469 - accuracy: 0.2089\n",
      "Epoch 12/64\n",
      "559/559 [==============================] - 2s 4ms/step - loss: 2.7433 - accuracy: 0.2095\n",
      "Epoch 13/64\n",
      "559/559 [==============================] - 2s 4ms/step - loss: 2.7374 - accuracy: 0.2116\n",
      "Epoch 14/64\n",
      "559/559 [==============================] - 2s 4ms/step - loss: 2.7307 - accuracy: 0.2116\n",
      "Epoch 15/64\n",
      "559/559 [==============================] - 2s 3ms/step - loss: 2.7285 - accuracy: 0.2132\n",
      "Epoch 16/64\n",
      "559/559 [==============================] - 2s 3ms/step - loss: 2.7318 - accuracy: 0.2125\n",
      "Epoch 17/64\n",
      "559/559 [==============================] - 2s 3ms/step - loss: 2.7275 - accuracy: 0.2150\n",
      "Epoch 18/64\n",
      "559/559 [==============================] - 2s 3ms/step - loss: 2.7282 - accuracy: 0.2129\n",
      "Epoch 19/64\n",
      "559/559 [==============================] - 2s 4ms/step - loss: 2.7209 - accuracy: 0.2147\n",
      "Epoch 20/64\n",
      "559/559 [==============================] - 2s 3ms/step - loss: 2.7281 - accuracy: 0.2110\n",
      "Epoch 21/64\n",
      "559/559 [==============================] - 2s 3ms/step - loss: 2.7286 - accuracy: 0.2146\n",
      "Epoch 22/64\n",
      "559/559 [==============================] - 2s 3ms/step - loss: 2.7157 - accuracy: 0.2160\n",
      "Epoch 23/64\n",
      "559/559 [==============================] - 2s 4ms/step - loss: 2.7212 - accuracy: 0.2146\n",
      "Epoch 24/64\n",
      "559/559 [==============================] - 2s 3ms/step - loss: 2.7261 - accuracy: 0.2138\n",
      "Epoch 25/64\n",
      "559/559 [==============================] - 2s 3ms/step - loss: 2.7173 - accuracy: 0.2161\n",
      "Epoch 26/64\n",
      "559/559 [==============================] - 2s 3ms/step - loss: 2.7205 - accuracy: 0.2132\n",
      "Epoch 27/64\n",
      "559/559 [==============================] - 2s 3ms/step - loss: 2.7135 - accuracy: 0.2166\n",
      "Epoch 28/64\n",
      "559/559 [==============================] - 2s 3ms/step - loss: 2.7200 - accuracy: 0.2141\n",
      "Epoch 29/64\n",
      "559/559 [==============================] - 2s 3ms/step - loss: 2.7172 - accuracy: 0.2137\n",
      "Epoch 30/64\n",
      "559/559 [==============================] - 2s 4ms/step - loss: 2.7207 - accuracy: 0.2139\n",
      "Epoch 31/64\n",
      "559/559 [==============================] - 2s 4ms/step - loss: 2.7163 - accuracy: 0.2157\n",
      "Epoch 32/64\n",
      "559/559 [==============================] - 2s 4ms/step - loss: 2.7209 - accuracy: 0.2151\n",
      "Epoch 33/64\n",
      "559/559 [==============================] - 2s 4ms/step - loss: 2.7230 - accuracy: 0.2135\n",
      "Epoch 34/64\n",
      "559/559 [==============================] - 2s 3ms/step - loss: 2.7223 - accuracy: 0.2133\n",
      "Epoch 35/64\n",
      "559/559 [==============================] - 2s 3ms/step - loss: 2.7187 - accuracy: 0.2171\n",
      "Epoch 36/64\n",
      "559/559 [==============================] - 2s 3ms/step - loss: 2.7146 - accuracy: 0.2168\n",
      "Epoch 37/64\n",
      "559/559 [==============================] - 2s 3ms/step - loss: 2.7169 - accuracy: 0.2138\n",
      "Epoch 38/64\n",
      "559/559 [==============================] - 2s 4ms/step - loss: 2.7135 - accuracy: 0.2161\n",
      "Epoch 39/64\n",
      "559/559 [==============================] - 2s 4ms/step - loss: 2.7110 - accuracy: 0.2159\n",
      "Epoch 40/64\n",
      "559/559 [==============================] - 2s 4ms/step - loss: 2.7178 - accuracy: 0.2161\n",
      "Epoch 41/64\n",
      "559/559 [==============================] - 2s 4ms/step - loss: 2.7159 - accuracy: 0.2152\n",
      "Epoch 42/64\n",
      "559/559 [==============================] - 2s 4ms/step - loss: 2.7083 - accuracy: 0.2174\n",
      "Epoch 43/64\n",
      "559/559 [==============================] - 2s 4ms/step - loss: 2.7073 - accuracy: 0.2175\n",
      "Epoch 44/64\n",
      "559/559 [==============================] - 2s 4ms/step - loss: 2.7150 - accuracy: 0.2154\n",
      "Epoch 45/64\n",
      "559/559 [==============================] - 2s 4ms/step - loss: 2.7095 - accuracy: 0.2186\n",
      "Epoch 46/64\n",
      "559/559 [==============================] - 2s 4ms/step - loss: 2.7093 - accuracy: 0.2174\n",
      "Epoch 47/64\n",
      "559/559 [==============================] - 2s 4ms/step - loss: 2.7046 - accuracy: 0.2178\n",
      "Epoch 48/64\n",
      "559/559 [==============================] - 2s 4ms/step - loss: 2.7110 - accuracy: 0.2170\n",
      "Epoch 49/64\n",
      "559/559 [==============================] - 2s 4ms/step - loss: 2.7092 - accuracy: 0.2174\n",
      "Epoch 50/64\n",
      "559/559 [==============================] - 2s 4ms/step - loss: 2.7114 - accuracy: 0.2161\n",
      "Epoch 51/64\n",
      "559/559 [==============================] - 2s 4ms/step - loss: 2.7199 - accuracy: 0.2139\n",
      "Epoch 52/64\n",
      "559/559 [==============================] - 2s 4ms/step - loss: 2.7095 - accuracy: 0.2173\n",
      "Epoch 53/64\n",
      "559/559 [==============================] - 2s 3ms/step - loss: 2.7158 - accuracy: 0.2166\n",
      "Epoch 54/64\n",
      "559/559 [==============================] - 2s 3ms/step - loss: 2.7105 - accuracy: 0.2179\n",
      "Epoch 55/64\n",
      "559/559 [==============================] - 2s 4ms/step - loss: 2.7115 - accuracy: 0.2177\n",
      "Epoch 56/64\n",
      "559/559 [==============================] - 2s 4ms/step - loss: 2.7053 - accuracy: 0.2172\n",
      "Epoch 57/64\n",
      "559/559 [==============================] - 2s 4ms/step - loss: 2.7068 - accuracy: 0.2169\n",
      "Epoch 58/64\n",
      "559/559 [==============================] - 2s 4ms/step - loss: 2.7119 - accuracy: 0.2149\n",
      "Epoch 59/64\n",
      "559/559 [==============================] - 2s 4ms/step - loss: 2.7064 - accuracy: 0.2193\n",
      "Epoch 60/64\n",
      "559/559 [==============================] - 2s 4ms/step - loss: 2.7111 - accuracy: 0.2176\n",
      "Epoch 61/64\n",
      "559/559 [==============================] - 2s 4ms/step - loss: 2.7111 - accuracy: 0.2157\n",
      "Epoch 62/64\n",
      "559/559 [==============================] - 1s 3ms/step - loss: 2.7064 - accuracy: 0.2189\n",
      "Epoch 63/64\n",
      "559/559 [==============================] - 1s 2ms/step - loss: 2.7056 - accuracy: 0.2178\n",
      "Epoch 64/64\n",
      "559/559 [==============================] - 1s 2ms/step - loss: 2.7075 - accuracy: 0.2163\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7faf92699fd0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_set, train_labels, epochs=64, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1637/1637 [==============================] - 2s 1ms/step - loss: 2.7361 - accuracy: 0.2101\n",
      "test loss, test acc: [2.7361292839050293, 0.21008002758026123]\n"
     ]
    }
   ],
   "source": [
    "print(\"test loss, test acc:\", model.evaluate(test_set, test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Phonemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, train_labels = get_labels(two_sentence_train, label=[\"phonemes\"])\n",
    "test_set, test_labels = get_labels(two_sentence_test, label=[\"phonemes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "587\n",
      "420\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "632"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_labels_2 = train_labels.append(test_labels)\n",
    "print(len(pd.unique(train_labels.phonemes)))\n",
    "print(len(pd.unique(test_labels.phonemes)))\n",
    "total_unique_phonemes_2 = len(pd.unique(total_labels_2.phonemes))\n",
    "total_unique_phonemes_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xkadlec6/.local/lib/python3.6/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "train_labels, test_labels, _ = prepare_labels(train_labels, test_labels, label=[\"phonemes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(142978, 632)\n"
     ]
    }
   ],
   "source": [
    "train_labels = to_categorical(train_labels, num_classes=total_unique_phonemes_2)\n",
    "test_labels = to_categorical(test_labels, num_classes=total_unique_phonemes_2)\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "def build_clf(optimizer='adam', classes=total_unique_phonemes_2):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(units=512, activation='relu', input_dim=3*1))  # first hidden layer\n",
    "    model.add(Dense(units=256, activation='relu'))  # second hidden layer\n",
    "    # model.add(Dense(units=128, activation='relu'))  # third hidden layer\n",
    "    model.add(Dense(units=classes, activation='softmax'))  # output layer\n",
    "    # model.add(Dense(units=128))  # output layer\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'batch_size':[64,128,256],\n",
    "          'nb_epoch':[16,32],\n",
    "          'optimizer':['adam', 'rmsprop']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_clf = KerasClassifier(build_fn=build_clf)\n",
    "gscv_clf = GridSearchCV(orig_clf, parameters, cv=cv_dialect_splitter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 632)               162424    \n",
      "=================================================================\n",
      "Total params: 295,800\n",
      "Trainable params: 295,800\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(units=512, activation='relu', input_dim=3*1))  # first hidden layer\n",
    "model.add(Dense(units=256, activation='relu'))  # second hidden layer\n",
    "# model.add(Dense(units=128, activation='relu'))  # third hidden layer\n",
    "model.add(Dense(units=total_unique_phonemes_2, activation='softmax'))  # output layer\n",
    "# model.add(Dense(units=128))  # output layer\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 4.2157 - accuracy: 0.1285\n",
      "Epoch 2/64\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 3.5007 - accuracy: 0.2033\n",
      "Epoch 3/64\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 3.4237 - accuracy: 0.2056\n",
      "Epoch 4/64\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 3.4048 - accuracy: 0.2058\n",
      "Epoch 5/64\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 3.3862 - accuracy: 0.2079\n",
      "Epoch 6/64\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 3.3688 - accuracy: 0.2098\n",
      "Epoch 7/64\n",
      "559/559 [==============================] - 3s 6ms/step - loss: 3.3715 - accuracy: 0.2101\n",
      "Epoch 8/64\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 3.3684 - accuracy: 0.2096\n",
      "Epoch 9/64\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 3.3523 - accuracy: 0.2125\n",
      "Epoch 10/64\n",
      "559/559 [==============================] - 3s 6ms/step - loss: 3.3504 - accuracy: 0.2140\n",
      "Epoch 11/64\n",
      "559/559 [==============================] - 3s 6ms/step - loss: 3.3495 - accuracy: 0.2127\n",
      "Epoch 12/64\n",
      "559/559 [==============================] - 3s 6ms/step - loss: 3.3422 - accuracy: 0.2138\n",
      "Epoch 13/64\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 3.3314 - accuracy: 0.2141\n",
      "Epoch 14/64\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 3.3312 - accuracy: 0.2140\n",
      "Epoch 15/64\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 3.3344 - accuracy: 0.2125\n",
      "Epoch 16/64\n",
      "559/559 [==============================] - 2s 4ms/step - loss: 3.3386 - accuracy: 0.2129\n",
      "Epoch 17/64\n",
      "559/559 [==============================] - 2s 4ms/step - loss: 3.3307 - accuracy: 0.2151\n",
      "Epoch 18/64\n",
      "559/559 [==============================] - 2s 4ms/step - loss: 3.3228 - accuracy: 0.2137\n",
      "Epoch 19/64\n",
      "559/559 [==============================] - 2s 4ms/step - loss: 3.3182 - accuracy: 0.2158\n",
      "Epoch 20/64\n",
      "559/559 [==============================] - 2s 4ms/step - loss: 3.3175 - accuracy: 0.2157\n",
      "Epoch 21/64\n",
      "559/559 [==============================] - 2s 4ms/step - loss: 3.3186 - accuracy: 0.2161\n",
      "Epoch 22/64\n",
      "559/559 [==============================] - 2s 4ms/step - loss: 3.3050 - accuracy: 0.2188\n",
      "Epoch 23/64\n",
      "559/559 [==============================] - 2s 4ms/step - loss: 3.3135 - accuracy: 0.2169\n",
      "Epoch 24/64\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 3.3148 - accuracy: 0.2149\n",
      "Epoch 25/64\n",
      "559/559 [==============================] - 2s 4ms/step - loss: 3.3028 - accuracy: 0.2178\n",
      "Epoch 26/64\n",
      "559/559 [==============================] - 2s 4ms/step - loss: 3.3151 - accuracy: 0.2145\n",
      "Epoch 27/64\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 3.3199 - accuracy: 0.2145\n",
      "Epoch 28/64\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 3.3107 - accuracy: 0.2160\n",
      "Epoch 29/64\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 3.3009 - accuracy: 0.2161\n",
      "Epoch 30/64\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 3.3032 - accuracy: 0.2161\n",
      "Epoch 31/64\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 3.3021 - accuracy: 0.2169\n",
      "Epoch 32/64\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 3.3046 - accuracy: 0.2171\n",
      "Epoch 33/64\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 3.2990 - accuracy: 0.2160\n",
      "Epoch 34/64\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 3.2996 - accuracy: 0.2176\n",
      "Epoch 35/64\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 3.2982 - accuracy: 0.2168\n",
      "Epoch 36/64\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 3.3052 - accuracy: 0.2175\n",
      "Epoch 37/64\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 3.2879 - accuracy: 0.2169\n",
      "Epoch 38/64\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 3.2944 - accuracy: 0.2201\n",
      "Epoch 39/64\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 3.2990 - accuracy: 0.2178\n",
      "Epoch 40/64\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 3.2943 - accuracy: 0.2182\n",
      "Epoch 41/64\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 3.2895 - accuracy: 0.2188\n",
      "Epoch 42/64\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 3.2978 - accuracy: 0.2175\n",
      "Epoch 43/64\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 3.2899 - accuracy: 0.2187\n",
      "Epoch 44/64\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 3.2906 - accuracy: 0.2187\n",
      "Epoch 45/64\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 3.2845 - accuracy: 0.2178\n",
      "Epoch 46/64\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 3.2926 - accuracy: 0.2170\n",
      "Epoch 47/64\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 3.2922 - accuracy: 0.2175\n",
      "Epoch 48/64\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 3.3008 - accuracy: 0.2162\n",
      "Epoch 49/64\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 3.2912 - accuracy: 0.2182\n",
      "Epoch 50/64\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 3.2931 - accuracy: 0.2170\n",
      "Epoch 51/64\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 3.2836 - accuracy: 0.2169\n",
      "Epoch 52/64\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 3.2990 - accuracy: 0.2156\n",
      "Epoch 53/64\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 3.2847 - accuracy: 0.2186\n",
      "Epoch 54/64\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 3.2918 - accuracy: 0.2168\n",
      "Epoch 55/64\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 3.2861 - accuracy: 0.2178\n",
      "Epoch 56/64\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 3.2914 - accuracy: 0.2173\n",
      "Epoch 57/64\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 3.2821 - accuracy: 0.2187\n",
      "Epoch 58/64\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 3.2896 - accuracy: 0.2170\n",
      "Epoch 59/64\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 3.2869 - accuracy: 0.2179\n",
      "Epoch 60/64\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 3.2849 - accuracy: 0.2169\n",
      "Epoch 61/64\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 3.2829 - accuracy: 0.2186\n",
      "Epoch 62/64\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 3.2876 - accuracy: 0.2183\n",
      "Epoch 63/64\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 3.2913 - accuracy: 0.2165\n",
      "Epoch 64/64\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 3.2805 - accuracy: 0.2190\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7faf927d8320>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_set, train_labels, epochs=64, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4469/4469 [==============================] - 5s 1ms/step - loss: 3.2719 - accuracy: 0.2198\n",
      "train loss, train acc: [3.2719388008117676, 0.21976108849048615]\n"
     ]
    }
   ],
   "source": [
    "print(\"train loss, train acc:\", model.evaluate(train_set, train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1637/1637 [==============================] - 2s 1ms/step - loss: 3.4595 - accuracy: 0.2135\n",
      "test loss, test acc: [3.459465980529785, 0.21346040070056915]\n"
     ]
    }
   ],
   "source": [
    "print(\"test loss, test acc:\", model.evaluate(test_set, test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_lstm = Sequential()\n",
    "# model_lstm.add(LSTM(256, input_shape = (1, 3)))\n",
    "# model_lstm.add(Dense(units=total_unique_words))\n",
    "# model_lstm.compile(loss='categorical_crossentropy',\n",
    "#               optimizer='adam',\n",
    "#               metrics=['accuracy']\n",
    "#              )\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Embedding\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import SpatialDropout1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, train_labels = get_labels(two_sentence_train, label=[\"words\"])\n",
    "test_set, test_labels = get_labels(two_sentence_test, label=[\"words\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n",
      "41\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_labels_2 = train_labels.append(test_labels)\n",
    "print(len(pd.unique(train_labels.words)))\n",
    "print(len(pd.unique(test_labels.words)))\n",
    "total_unique_words_2 = len(pd.unique(total_labels_2.words))\n",
    "total_unique_words_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xkadlec6/.local/lib/python3.6/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "train_labels, test_labels, _ = prepare_labels(train_labels, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(142978, 42)\n"
     ]
    }
   ],
   "source": [
    "train_labels = to_categorical(train_labels, num_classes=total_unique_words_2)\n",
    "test_labels = to_categorical(test_labels, num_classes=total_unique_words_2)\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0, 32, 32])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshaped_values = train_set.values.reshape(-1, 1, 3)\n",
    "reshaped_values[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "def build_lstm_clf(optimizer='adam', classes=total_unique_words_2):\n",
    "    model = Sequential()\n",
    "\n",
    "    model_lstm.add(LSTM(256, input_shape = (1, 3), dropout = 0.3, recurrent_dropout = 0.3))\n",
    "    model_lstm.add(Dense(256, activation = 'relu'))\n",
    "    model_lstm.add(Dropout(0.3))\n",
    "    model_lstm.add(Dense(classes, activation = 'softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'batch_size':[64,128,256],\n",
    "          'nb_epoch':[16,32],\n",
    "          'optimizer':['adam', 'rmsprop']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_clf = KerasClassifier(build_fn=build_clf)\n",
    "gscv_clf = GridSearchCV(orig_clf, parameters, cv=cv_dialect_splitter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting!\n",
      "1242/1242 [==============================] - 23s 18ms/step - loss: 8.7184 - accuracy: 0.0474\n",
      "110/110 [==============================] - 1s 6ms/step - loss: 8.6063 - accuracy: 0.0587\n",
      "1134/1134 [==============================] - 21s 18ms/step - loss: 8.7687 - accuracy: 0.0475\n",
      "219/219 [==============================] - 2s 7ms/step - loss: 8.6525 - accuracy: 0.0509\n",
      "1134/1134 [==============================] - 19s 17ms/step - loss: 8.7338 - accuracy: 0.0492\n",
      "219/219 [==============================] - 2s 7ms/step - loss: 8.6538 - accuracy: 0.0519\n",
      "1149/1149 [==============================] - 20s 17ms/step - loss: 8.7412 - accuracy: 0.0499\n",
      "203/203 [==============================] - 2s 7ms/step - loss: 8.5547 - accuracy: 0.0433\n",
      "1136/1136 [==============================] - 19s 16ms/step - loss: 8.7790 - accuracy: 0.0456\n",
      "217/217 [==============================] - 2s 6ms/step - loss: 8.6529 - accuracy: 0.0526\n",
      "1248/1248 [==============================] - 20s 16ms/step - loss: 8.7471 - accuracy: 0.0498\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 8.6892 - accuracy: 0.0610\n",
      "1131/1131 [==============================] - 20s 17ms/step - loss: 8.8528 - accuracy: 0.0460\n",
      "221/221 [==============================] - 2s 7ms/step - loss: 8.8989 - accuracy: 0.0515\n",
      "1291/1291 [==============================] - 21s 16ms/step - loss: 8.8269 - accuracy: 0.0459\n",
      "61/61 [==============================] - 1s 7ms/step - loss: 8.7650 - accuracy: 0.0414\n",
      "1242/1242 [==============================] - 28s 22ms/step - loss: 8.8047 - accuracy: 0.0429\n",
      "110/110 [==============================] - 1s 8ms/step - loss: 8.3598 - accuracy: 0.0572\n",
      "1134/1134 [==============================] - 31s 22ms/step - loss: 8.8707 - accuracy: 0.0440\n",
      "219/219 [==============================] - 2s 6ms/step - loss: 8.7146 - accuracy: 0.0490\n",
      "1134/1134 [==============================] - 25s 22ms/step - loss: 8.8320 - accuracy: 0.0468\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 8.4151 - accuracy: 0.0487\n",
      "1149/1149 [==============================] - 25s 21ms/step - loss: 8.8690 - accuracy: 0.0479\n",
      "203/203 [==============================] - 1s 6ms/step - loss: 8.4598 - accuracy: 0.0433\n",
      "1136/1136 [==============================] - 25s 22ms/step - loss: 8.8809 - accuracy: 0.0442\n",
      "217/217 [==============================] - 1s 6ms/step - loss: 8.7523 - accuracy: 0.0526\n",
      "1248/1248 [==============================] - 26s 20ms/step - loss: 8.8476 - accuracy: 0.0463\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 9.0772 - accuracy: 0.0610\n",
      "1131/1131 [==============================] - 23s 20ms/step - loss: 8.8486 - accuracy: 0.0448\n",
      "221/221 [==============================] - 2s 6ms/step - loss: 8.9625 - accuracy: 0.0515\n",
      "1291/1291 [==============================] - 26s 20ms/step - loss: 8.8155 - accuracy: 0.0481\n",
      "61/61 [==============================] - 1s 8ms/step - loss: 8.4451 - accuracy: 0.0424\n",
      "1242/1242 [==============================] - 19s 15ms/step - loss: 8.7108 - accuracy: 0.0461\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 8.6368 - accuracy: 0.0569\n",
      "1134/1134 [==============================] - 17s 15ms/step - loss: 8.7110 - accuracy: 0.0471\n",
      "219/219 [==============================] - 8s 6ms/step - loss: 8.7445 - accuracy: 0.0482\n",
      "1134/1134 [==============================] - 21s 18ms/step - loss: 8.7104 - accuracy: 0.0481\n",
      "219/219 [==============================] - 2s 6ms/step - loss: 8.6088 - accuracy: 0.0501\n",
      "1149/1149 [==============================] - 19s 16ms/step - loss: 8.7724 - accuracy: 0.0470\n",
      "203/203 [==============================] - 2s 10ms/step - loss: 8.7240 - accuracy: 0.0433\n",
      "1136/1136 [==============================] - 19s 16ms/step - loss: 8.8139 - accuracy: 0.0463\n",
      "217/217 [==============================] - 2s 7ms/step - loss: 8.6251 - accuracy: 0.0537\n",
      "1248/1248 [==============================] - 20s 16ms/step - loss: 8.7602 - accuracy: 0.0468\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 8.6171 - accuracy: 0.0598\n",
      "1131/1131 [==============================] - 19s 17ms/step - loss: 8.7454 - accuracy: 0.0474\n",
      "221/221 [==============================] - 2s 7ms/step - loss: 8.7481 - accuracy: 0.0520\n",
      "1291/1291 [==============================] - 21s 15ms/step - loss: 8.7142 - accuracy: 0.0481\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 8.7593 - accuracy: 0.0424\n",
      "1242/1242 [==============================] - 30s 23ms/step - loss: 8.8469 - accuracy: 0.0447\n",
      "110/110 [==============================] - 1s 8ms/step - loss: 8.6025 - accuracy: 0.0572\n",
      "1134/1134 [==============================] - 30s 26ms/step - loss: 8.8852 - accuracy: 0.0446\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 8.6956 - accuracy: 0.0490\n",
      "1134/1134 [==============================] - 28s 25ms/step - loss: 8.8529 - accuracy: 0.0447\n",
      "219/219 [==============================] - 2s 6ms/step - loss: 9.0870 - accuracy: 0.0487\n",
      "1149/1149 [==============================] - 32s 23ms/step - loss: 8.9572 - accuracy: 0.0457\n",
      "203/203 [==============================] - 1s 6ms/step - loss: 8.3963 - accuracy: 0.0433\n",
      "1136/1136 [==============================] - 24s 21ms/step - loss: 8.8241 - accuracy: 0.0433\n",
      "217/217 [==============================] - 2s 6ms/step - loss: 9.0540 - accuracy: 0.0526\n",
      "1248/1248 [==============================] - 28s 22ms/step - loss: 8.8288 - accuracy: 0.0434\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 9.0365 - accuracy: 0.0610\n",
      "1131/1131 [==============================] - 25s 22ms/step - loss: 8.8059 - accuracy: 0.0455\n",
      "221/221 [==============================] - 2s 7ms/step - loss: 8.3813 - accuracy: 0.0515\n",
      "1291/1291 [==============================] - 27s 21ms/step - loss: 8.8221 - accuracy: 0.0456\n",
      "61/61 [==============================] - 1s 11ms/step - loss: 8.5084 - accuracy: 0.0424\n",
      "1352/1352 [==============================] - 21s 15ms/step - loss: 8.7474 - accuracy: 0.0457\n",
      "Finished!\n",
      "Best: 0.051422 using {'batch_size': 64, 'nb_epoch': 1, 'optimizer': 'adam'}\n",
      "1352/1352 [==============================] - 8s 6ms/step - loss: 8.2757 - accuracy: 0.0506\n",
      "Train accuracy: 0.0506\n",
      "494/494 [==============================] - 3s 6ms/step - loss: 11.2806 - accuracy: 0.0465\n",
      "Test accuracy : 0.0465\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting!\")\n",
    "gscv_clf.fit(reshaped_values, train_labels)\n",
    "print(\"Finished!\")\n",
    "\n",
    "print(\"Best: %f using %s\" % (gscv_clf.best_score_, gscv_clf.best_params_))\n",
    "print(f\"Train accuracy: {gscv_clf.score(reshaped_values, train_labels):.4f}\")\n",
    "print(f\"Test accuracy : {gscv_clf.score(test_set.values.reshape(-1, 1, 3), test_labels):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 256)               266240    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 42)                10794     \n",
      "=================================================================\n",
      "Total params: 342,826\n",
      "Trainable params: 342,826\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#more elaborate model\n",
    "model_lstm = Sequential()\n",
    "\n",
    "#model_lstm.add(Embedding(input_dim = 3, output_dim = 2, input_length = 86497))\n",
    "#model_lstm.add(SpatialDropout1D(0.3))\n",
    "model_lstm.add(LSTM(256, input_shape = (1, 3), dropout = 0.3, recurrent_dropout = 0.3))\n",
    "model_lstm.add(Dense(256, activation = 'relu'))\n",
    "model_lstm.add(Dropout(0.3))\n",
    "model_lstm.add(Dense(total_unique_words_2, activation = 'softmax'))\n",
    "\n",
    "model_lstm.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='Adam',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model_lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "559/559 [==============================] - 7s 8ms/step - loss: 3.1252 - accuracy: 0.1517\n",
      "Epoch 2/64\n",
      "559/559 [==============================] - 4s 8ms/step - loss: 2.9146 - accuracy: 0.1792\n",
      "Epoch 3/64\n",
      "559/559 [==============================] - 4s 8ms/step - loss: 2.8637 - accuracy: 0.1912\n",
      "Epoch 4/64\n",
      "559/559 [==============================] - 4s 8ms/step - loss: 2.8551 - accuracy: 0.1916\n",
      "Epoch 5/64\n",
      "559/559 [==============================] - 4s 8ms/step - loss: 2.8421 - accuracy: 0.1922\n",
      "Epoch 6/64\n",
      "559/559 [==============================] - 4s 8ms/step - loss: 2.8217 - accuracy: 0.1973\n",
      "Epoch 7/64\n",
      "559/559 [==============================] - 4s 8ms/step - loss: 2.8315 - accuracy: 0.1937\n",
      "Epoch 8/64\n",
      "559/559 [==============================] - 4s 8ms/step - loss: 2.8187 - accuracy: 0.1974\n",
      "Epoch 9/64\n",
      "559/559 [==============================] - 4s 8ms/step - loss: 2.8167 - accuracy: 0.1966\n",
      "Epoch 10/64\n",
      "559/559 [==============================] - 4s 8ms/step - loss: 2.8145 - accuracy: 0.1979\n",
      "Epoch 11/64\n",
      "559/559 [==============================] - 4s 8ms/step - loss: 2.8101 - accuracy: 0.1965\n",
      "Epoch 12/64\n",
      "559/559 [==============================] - 4s 8ms/step - loss: 2.8105 - accuracy: 0.1980\n",
      "Epoch 13/64\n",
      "559/559 [==============================] - 4s 8ms/step - loss: 2.8047 - accuracy: 0.1972\n",
      "Epoch 14/64\n",
      "559/559 [==============================] - 4s 8ms/step - loss: 2.8061 - accuracy: 0.1981\n",
      "Epoch 15/64\n",
      "559/559 [==============================] - 4s 8ms/step - loss: 2.8066 - accuracy: 0.1966\n",
      "Epoch 16/64\n",
      "559/559 [==============================] - 4s 8ms/step - loss: 2.8019 - accuracy: 0.1998\n",
      "Epoch 17/64\n",
      "559/559 [==============================] - 5s 8ms/step - loss: 2.7975 - accuracy: 0.2003\n",
      "Epoch 18/64\n",
      "559/559 [==============================] - 4s 8ms/step - loss: 2.8052 - accuracy: 0.1999\n",
      "Epoch 19/64\n",
      "559/559 [==============================] - 4s 8ms/step - loss: 2.7962 - accuracy: 0.2011\n",
      "Epoch 20/64\n",
      "559/559 [==============================] - 4s 8ms/step - loss: 2.7971 - accuracy: 0.1975\n",
      "Epoch 21/64\n",
      "559/559 [==============================] - 4s 8ms/step - loss: 2.7993 - accuracy: 0.1977\n",
      "Epoch 22/64\n",
      "559/559 [==============================] - 4s 8ms/step - loss: 2.7957 - accuracy: 0.2013\n",
      "Epoch 23/64\n",
      "559/559 [==============================] - 4s 8ms/step - loss: 2.7960 - accuracy: 0.1979\n",
      "Epoch 24/64\n",
      "559/559 [==============================] - 4s 8ms/step - loss: 2.7932 - accuracy: 0.1993\n",
      "Epoch 25/64\n",
      "559/559 [==============================] - 4s 8ms/step - loss: 2.7908 - accuracy: 0.2000\n",
      "Epoch 26/64\n",
      "559/559 [==============================] - 4s 8ms/step - loss: 2.7970 - accuracy: 0.1989\n",
      "Epoch 27/64\n",
      "559/559 [==============================] - 4s 8ms/step - loss: 2.7958 - accuracy: 0.1989\n",
      "Epoch 28/64\n",
      "559/559 [==============================] - 4s 8ms/step - loss: 2.7914 - accuracy: 0.1996\n",
      "Epoch 29/64\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 2.7921 - accuracy: 0.2001\n",
      "Epoch 30/64\n",
      "559/559 [==============================] - 4s 8ms/step - loss: 2.7917 - accuracy: 0.2009\n",
      "Epoch 31/64\n",
      "559/559 [==============================] - 4s 8ms/step - loss: 2.7884 - accuracy: 0.2013\n",
      "Epoch 32/64\n",
      "559/559 [==============================] - 4s 8ms/step - loss: 2.7941 - accuracy: 0.1995\n",
      "Epoch 33/64\n",
      "559/559 [==============================] - 4s 8ms/step - loss: 2.7915 - accuracy: 0.2015\n",
      "Epoch 34/64\n",
      "559/559 [==============================] - 5s 8ms/step - loss: 2.7926 - accuracy: 0.1999\n",
      "Epoch 35/64\n",
      "559/559 [==============================] - 4s 8ms/step - loss: 2.7901 - accuracy: 0.2000\n",
      "Epoch 36/64\n",
      "559/559 [==============================] - 4s 8ms/step - loss: 2.7852 - accuracy: 0.2040\n",
      "Epoch 37/64\n",
      "559/559 [==============================] - 4s 8ms/step - loss: 2.7877 - accuracy: 0.2003\n",
      "Epoch 38/64\n",
      "559/559 [==============================] - 4s 8ms/step - loss: 2.7890 - accuracy: 0.2019\n",
      "Epoch 39/64\n",
      "559/559 [==============================] - 4s 8ms/step - loss: 2.7814 - accuracy: 0.2016\n",
      "Epoch 40/64\n",
      "559/559 [==============================] - 4s 8ms/step - loss: 2.7853 - accuracy: 0.2018\n",
      "Epoch 41/64\n",
      "559/559 [==============================] - 4s 8ms/step - loss: 2.7882 - accuracy: 0.2013\n",
      "Epoch 42/64\n",
      "559/559 [==============================] - 4s 8ms/step - loss: 2.7794 - accuracy: 0.2027\n",
      "Epoch 43/64\n",
      "559/559 [==============================] - 5s 8ms/step - loss: 2.7860 - accuracy: 0.2036\n",
      "Epoch 44/64\n",
      "559/559 [==============================] - 4s 8ms/step - loss: 2.7856 - accuracy: 0.2002\n",
      "Epoch 45/64\n",
      "559/559 [==============================] - 4s 8ms/step - loss: 2.7857 - accuracy: 0.2017\n",
      "Epoch 46/64\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 2.7862 - accuracy: 0.2029\n",
      "Epoch 47/64\n",
      "559/559 [==============================] - 4s 8ms/step - loss: 2.7862 - accuracy: 0.2019\n",
      "Epoch 48/64\n",
      "559/559 [==============================] - 4s 8ms/step - loss: 2.7829 - accuracy: 0.2024\n",
      "Epoch 49/64\n",
      "559/559 [==============================] - 4s 8ms/step - loss: 2.7884 - accuracy: 0.2008\n",
      "Epoch 50/64\n",
      "559/559 [==============================] - 4s 8ms/step - loss: 2.7869 - accuracy: 0.2009\n",
      "Epoch 51/64\n",
      "559/559 [==============================] - 4s 8ms/step - loss: 2.7838 - accuracy: 0.2018\n",
      "Epoch 52/64\n",
      "559/559 [==============================] - 4s 8ms/step - loss: 2.7831 - accuracy: 0.2021\n",
      "Epoch 53/64\n",
      "559/559 [==============================] - 4s 8ms/step - loss: 2.7862 - accuracy: 0.2016\n",
      "Epoch 54/64\n",
      "559/559 [==============================] - 4s 8ms/step - loss: 2.7830 - accuracy: 0.2034\n",
      "Epoch 55/64\n",
      "559/559 [==============================] - 4s 8ms/step - loss: 2.7857 - accuracy: 0.2009\n",
      "Epoch 56/64\n",
      "559/559 [==============================] - 4s 8ms/step - loss: 2.7842 - accuracy: 0.2018\n",
      "Epoch 57/64\n",
      "559/559 [==============================] - 4s 8ms/step - loss: 2.7866 - accuracy: 0.2012\n",
      "Epoch 58/64\n",
      "559/559 [==============================] - 4s 8ms/step - loss: 2.7838 - accuracy: 0.2024\n",
      "Epoch 59/64\n",
      "559/559 [==============================] - 4s 8ms/step - loss: 2.7724 - accuracy: 0.2034\n",
      "Epoch 60/64\n",
      "559/559 [==============================] - 4s 8ms/step - loss: 2.7792 - accuracy: 0.2016\n",
      "Epoch 61/64\n",
      "559/559 [==============================] - 4s 8ms/step - loss: 2.7818 - accuracy: 0.2028\n",
      "Epoch 62/64\n",
      "559/559 [==============================] - 4s 8ms/step - loss: 2.7757 - accuracy: 0.2035\n",
      "Epoch 63/64\n",
      "559/559 [==============================] - 4s 8ms/step - loss: 2.7802 - accuracy: 0.2026\n",
      "Epoch 64/64\n",
      "559/559 [==============================] - 4s 8ms/step - loss: 2.7781 - accuracy: 0.2035\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7faf92a0df98>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lstm.fit(reshaped_values, train_labels, epochs=64, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4469/4469 [==============================] - 6s 1ms/step - loss: 3.7271 - accuracy: 0.1391\n",
      "train loss, train acc: [3.7270686626434326, 0.13907034695148468]\n"
     ]
    }
   ],
   "source": [
    "print(\"train loss, train acc:\", model_lstm.evaluate(reshaped_values, train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1637/1637 [==============================] - 2s 1ms/step - loss: 3.8106 - accuracy: 0.1344\n",
      "test loss, test acc: [3.810607433319092, 0.13441301882266998]\n"
     ]
    }
   ],
   "source": [
    "print(\"test loss, test acc:\", model_lstm.evaluate(test_set.values.reshape(-1, 1, 3), test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Phonemes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, train_labels = get_labels(two_sentence_train, label=[\"phonemes\"])\n",
    "test_set, test_labels = get_labels(two_sentence_test, label=[\"phonemes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "587\n",
      "420\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "632"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_labels_2 = train_labels.append(test_labels)\n",
    "print(len(pd.unique(train_labels.phonemes)))\n",
    "print(len(pd.unique(test_labels.phonemes)))\n",
    "total_unique_phonemes_2 = len(pd.unique(total_labels_2.phonemes))\n",
    "total_unique_phonemes_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels, test_labels, _ = prepare_labels(train_labels, test_labels, label=[\"phonemes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(142978, 632)\n"
     ]
    }
   ],
   "source": [
    "train_labels = to_categorical(train_labels, num_classes=total_unique_phonemes_2)\n",
    "test_labels = to_categorical(test_labels, num_classes=total_unique_phonemes_2)\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0, 32, 32])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshaped_values = train_set.values.reshape(-1, 1, 3)\n",
    "reshaped_values[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "def build_lstm_clf(optimizer='adam', classes=total_unique_phonemes_2):\n",
    "    model = Sequential()\n",
    "\n",
    "    model_lstm.add(LSTM(256, input_shape = (1, 3), dropout = 0.3, recurrent_dropout = 0.3))\n",
    "    model_lstm.add(Dense(256, activation = 'relu'))\n",
    "    model_lstm.add(Dropout(0.3))\n",
    "    model_lstm.add(Dense(classes, activation = 'softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'batch_size':[64,128,256],\n",
    "          'nb_epoch':[16,32],\n",
    "          'optimizer':['adam', 'rmsprop']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_clf = KerasClassifier(build_fn=build_clf)\n",
    "gscv_clf = GridSearchCV(orig_clf, parameters, cv=cv_dialect_splitter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting!\n",
      "1242/1242 [==============================] - 23s 18ms/step - loss: 8.7184 - accuracy: 0.0474\n",
      "110/110 [==============================] - 1s 6ms/step - loss: 8.6063 - accuracy: 0.0587\n",
      "1134/1134 [==============================] - 21s 18ms/step - loss: 8.7687 - accuracy: 0.0475\n",
      "219/219 [==============================] - 2s 7ms/step - loss: 8.6525 - accuracy: 0.0509\n",
      "1134/1134 [==============================] - 19s 17ms/step - loss: 8.7338 - accuracy: 0.0492\n",
      "219/219 [==============================] - 2s 7ms/step - loss: 8.6538 - accuracy: 0.0519\n",
      "1149/1149 [==============================] - 20s 17ms/step - loss: 8.7412 - accuracy: 0.0499\n",
      "203/203 [==============================] - 2s 7ms/step - loss: 8.5547 - accuracy: 0.0433\n",
      "1136/1136 [==============================] - 19s 16ms/step - loss: 8.7790 - accuracy: 0.0456\n",
      "217/217 [==============================] - 2s 6ms/step - loss: 8.6529 - accuracy: 0.0526\n",
      "1248/1248 [==============================] - 20s 16ms/step - loss: 8.7471 - accuracy: 0.0498\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 8.6892 - accuracy: 0.0610\n",
      "1131/1131 [==============================] - 20s 17ms/step - loss: 8.8528 - accuracy: 0.0460\n",
      "221/221 [==============================] - 2s 7ms/step - loss: 8.8989 - accuracy: 0.0515\n",
      "1291/1291 [==============================] - 21s 16ms/step - loss: 8.8269 - accuracy: 0.0459\n",
      "61/61 [==============================] - 1s 7ms/step - loss: 8.7650 - accuracy: 0.0414\n",
      "1242/1242 [==============================] - 28s 22ms/step - loss: 8.8047 - accuracy: 0.0429\n",
      "110/110 [==============================] - 1s 8ms/step - loss: 8.3598 - accuracy: 0.0572\n",
      "1134/1134 [==============================] - 31s 22ms/step - loss: 8.8707 - accuracy: 0.0440\n",
      "219/219 [==============================] - 2s 6ms/step - loss: 8.7146 - accuracy: 0.0490\n",
      "1134/1134 [==============================] - 25s 22ms/step - loss: 8.8320 - accuracy: 0.0468\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 8.4151 - accuracy: 0.0487\n",
      "1149/1149 [==============================] - 25s 21ms/step - loss: 8.8690 - accuracy: 0.0479\n",
      "203/203 [==============================] - 1s 6ms/step - loss: 8.4598 - accuracy: 0.0433\n",
      "1136/1136 [==============================] - 25s 22ms/step - loss: 8.8809 - accuracy: 0.0442\n",
      "217/217 [==============================] - 1s 6ms/step - loss: 8.7523 - accuracy: 0.0526\n",
      "1248/1248 [==============================] - 26s 20ms/step - loss: 8.8476 - accuracy: 0.0463\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 9.0772 - accuracy: 0.0610\n",
      "1131/1131 [==============================] - 23s 20ms/step - loss: 8.8486 - accuracy: 0.0448\n",
      "221/221 [==============================] - 2s 6ms/step - loss: 8.9625 - accuracy: 0.0515\n",
      "1291/1291 [==============================] - 26s 20ms/step - loss: 8.8155 - accuracy: 0.0481\n",
      "61/61 [==============================] - 1s 8ms/step - loss: 8.4451 - accuracy: 0.0424\n",
      "1242/1242 [==============================] - 19s 15ms/step - loss: 8.7108 - accuracy: 0.0461\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 8.6368 - accuracy: 0.0569\n",
      "1134/1134 [==============================] - 17s 15ms/step - loss: 8.7110 - accuracy: 0.0471\n",
      "219/219 [==============================] - 8s 6ms/step - loss: 8.7445 - accuracy: 0.0482\n",
      "1134/1134 [==============================] - 21s 18ms/step - loss: 8.7104 - accuracy: 0.0481\n",
      "219/219 [==============================] - 2s 6ms/step - loss: 8.6088 - accuracy: 0.0501\n",
      "1149/1149 [==============================] - 19s 16ms/step - loss: 8.7724 - accuracy: 0.0470\n",
      "203/203 [==============================] - 2s 10ms/step - loss: 8.7240 - accuracy: 0.0433\n",
      "1136/1136 [==============================] - 19s 16ms/step - loss: 8.8139 - accuracy: 0.0463\n",
      "217/217 [==============================] - 2s 7ms/step - loss: 8.6251 - accuracy: 0.0537\n",
      "1248/1248 [==============================] - 20s 16ms/step - loss: 8.7602 - accuracy: 0.0468\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 8.6171 - accuracy: 0.0598\n",
      "1131/1131 [==============================] - 19s 17ms/step - loss: 8.7454 - accuracy: 0.0474\n",
      "221/221 [==============================] - 2s 7ms/step - loss: 8.7481 - accuracy: 0.0520\n",
      "1291/1291 [==============================] - 21s 15ms/step - loss: 8.7142 - accuracy: 0.0481\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 8.7593 - accuracy: 0.0424\n",
      "1242/1242 [==============================] - 30s 23ms/step - loss: 8.8469 - accuracy: 0.0447\n",
      "110/110 [==============================] - 1s 8ms/step - loss: 8.6025 - accuracy: 0.0572\n",
      "1134/1134 [==============================] - 30s 26ms/step - loss: 8.8852 - accuracy: 0.0446\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 8.6956 - accuracy: 0.0490\n",
      "1134/1134 [==============================] - 28s 25ms/step - loss: 8.8529 - accuracy: 0.0447\n",
      "219/219 [==============================] - 2s 6ms/step - loss: 9.0870 - accuracy: 0.0487\n",
      "1149/1149 [==============================] - 32s 23ms/step - loss: 8.9572 - accuracy: 0.0457\n",
      "203/203 [==============================] - 1s 6ms/step - loss: 8.3963 - accuracy: 0.0433\n",
      "1136/1136 [==============================] - 24s 21ms/step - loss: 8.8241 - accuracy: 0.0433\n",
      "217/217 [==============================] - 2s 6ms/step - loss: 9.0540 - accuracy: 0.0526\n",
      "1248/1248 [==============================] - 28s 22ms/step - loss: 8.8288 - accuracy: 0.0434\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 9.0365 - accuracy: 0.0610\n",
      "1131/1131 [==============================] - 25s 22ms/step - loss: 8.8059 - accuracy: 0.0455\n",
      "221/221 [==============================] - 2s 7ms/step - loss: 8.3813 - accuracy: 0.0515\n",
      "1291/1291 [==============================] - 27s 21ms/step - loss: 8.8221 - accuracy: 0.0456\n",
      "61/61 [==============================] - 1s 11ms/step - loss: 8.5084 - accuracy: 0.0424\n",
      "1352/1352 [==============================] - 21s 15ms/step - loss: 8.7474 - accuracy: 0.0457\n",
      "Finished!\n",
      "Best: 0.051422 using {'batch_size': 64, 'nb_epoch': 1, 'optimizer': 'adam'}\n",
      "1352/1352 [==============================] - 8s 6ms/step - loss: 8.2757 - accuracy: 0.0506\n",
      "Train accuracy: 0.0506\n",
      "494/494 [==============================] - 3s 6ms/step - loss: 11.2806 - accuracy: 0.0465\n",
      "Test accuracy : 0.0465\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting!\")\n",
    "gscv_clf.fit(reshaped_values, train_labels)\n",
    "print(\"Finished!\")\n",
    "\n",
    "print(\"Best: %f using %s\" % (gscv_clf.best_score_, gscv_clf.best_params_))\n",
    "print(f\"Train accuracy: {gscv_clf.score(reshaped_values, train_labels):.4f}\")\n",
    "print(f\"Test accuracy : {gscv_clf.score(test_set.values.reshape(-1, 1, 3), test_labels):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 256)               266240    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 632)               162424    \n",
      "=================================================================\n",
      "Total params: 494,456\n",
      "Trainable params: 494,456\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#more elaborate model\n",
    "model_lstm = Sequential()\n",
    "\n",
    "#model_lstm.add(Embedding(input_dim = 3, output_dim = 2, input_length = 86497))\n",
    "#model_lstm.add(SpatialDropout1D(0.3))\n",
    "model_lstm.add(LSTM(256, input_shape = (1, 3), dropout = 0.3, recurrent_dropout = 0.3))\n",
    "model_lstm.add(Dense(256, activation = 'relu'))\n",
    "model_lstm.add(Dropout(0.3))\n",
    "model_lstm.add(Dense(total_unique_phonemes_2, activation = 'softmax'))\n",
    "\n",
    "model_lstm.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='Adam',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model_lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "559/559 [==============================] - 8s 9ms/step - loss: 4.3042 - accuracy: 0.1477\n",
      "Epoch 2/64\n",
      "559/559 [==============================] - 5s 10ms/step - loss: 3.6041 - accuracy: 0.1932\n",
      "Epoch 3/64\n",
      "559/559 [==============================] - 5s 10ms/step - loss: 3.5532 - accuracy: 0.1968\n",
      "Epoch 4/64\n",
      "559/559 [==============================] - 5s 10ms/step - loss: 3.5304 - accuracy: 0.1976\n",
      "Epoch 5/64\n",
      "559/559 [==============================] - 5s 10ms/step - loss: 3.5055 - accuracy: 0.2006\n",
      "Epoch 6/64\n",
      "559/559 [==============================] - 5s 9ms/step - loss: 3.4850 - accuracy: 0.1992\n",
      "Epoch 7/64\n",
      "559/559 [==============================] - 5s 9ms/step - loss: 3.4791 - accuracy: 0.1999\n",
      "Epoch 8/64\n",
      "559/559 [==============================] - 5s 9ms/step - loss: 3.4683 - accuracy: 0.2011\n",
      "Epoch 9/64\n",
      "559/559 [==============================] - 5s 10ms/step - loss: 3.4767 - accuracy: 0.2004\n",
      "Epoch 10/64\n",
      "559/559 [==============================] - 5s 10ms/step - loss: 3.4561 - accuracy: 0.2031\n",
      "Epoch 11/64\n",
      "559/559 [==============================] - 5s 9ms/step - loss: 3.4529 - accuracy: 0.2031\n",
      "Epoch 12/64\n",
      "559/559 [==============================] - 5s 9ms/step - loss: 3.4576 - accuracy: 0.2029\n",
      "Epoch 13/64\n",
      "559/559 [==============================] - 5s 9ms/step - loss: 3.4513 - accuracy: 0.2042\n",
      "Epoch 14/64\n",
      "559/559 [==============================] - 5s 9ms/step - loss: 3.4545 - accuracy: 0.2037\n",
      "Epoch 15/64\n",
      "559/559 [==============================] - 7s 13ms/step - loss: 3.4500 - accuracy: 0.2031\n",
      "Epoch 16/64\n",
      "559/559 [==============================] - 8s 15ms/step - loss: 3.4304 - accuracy: 0.2073\n",
      "Epoch 17/64\n",
      "559/559 [==============================] - 5s 9ms/step - loss: 3.4452 - accuracy: 0.2039\n",
      "Epoch 18/64\n",
      "559/559 [==============================] - 5s 9ms/step - loss: 3.4400 - accuracy: 0.2056\n",
      "Epoch 19/64\n",
      "559/559 [==============================] - 5s 9ms/step - loss: 3.4412 - accuracy: 0.2039\n",
      "Epoch 20/64\n",
      "559/559 [==============================] - 5s 9ms/step - loss: 3.4380 - accuracy: 0.2051\n",
      "Epoch 21/64\n",
      "559/559 [==============================] - 5s 9ms/step - loss: 3.4200 - accuracy: 0.2064\n",
      "Epoch 22/64\n",
      "559/559 [==============================] - 5s 9ms/step - loss: 3.4290 - accuracy: 0.2062\n",
      "Epoch 23/64\n",
      "559/559 [==============================] - 5s 9ms/step - loss: 3.4258 - accuracy: 0.2059\n",
      "Epoch 24/64\n",
      "559/559 [==============================] - 5s 9ms/step - loss: 3.4214 - accuracy: 0.2053\n",
      "Epoch 25/64\n",
      "559/559 [==============================] - 5s 9ms/step - loss: 3.4258 - accuracy: 0.2070\n",
      "Epoch 26/64\n",
      "559/559 [==============================] - 5s 9ms/step - loss: 3.4296 - accuracy: 0.2054\n",
      "Epoch 27/64\n",
      "559/559 [==============================] - 5s 9ms/step - loss: 3.4216 - accuracy: 0.2058\n",
      "Epoch 28/64\n",
      "559/559 [==============================] - 5s 9ms/step - loss: 3.4135 - accuracy: 0.2065\n",
      "Epoch 29/64\n",
      "559/559 [==============================] - 5s 9ms/step - loss: 3.4248 - accuracy: 0.2041\n",
      "Epoch 30/64\n",
      "559/559 [==============================] - 5s 9ms/step - loss: 3.4236 - accuracy: 0.2051\n",
      "Epoch 31/64\n",
      "559/559 [==============================] - 5s 9ms/step - loss: 3.4219 - accuracy: 0.2064\n",
      "Epoch 32/64\n",
      "559/559 [==============================] - 5s 9ms/step - loss: 3.4146 - accuracy: 0.2072\n",
      "Epoch 33/64\n",
      "559/559 [==============================] - 5s 9ms/step - loss: 3.4151 - accuracy: 0.2074\n",
      "Epoch 34/64\n",
      "559/559 [==============================] - 5s 9ms/step - loss: 3.4213 - accuracy: 0.2049\n",
      "Epoch 35/64\n",
      "559/559 [==============================] - 5s 9ms/step - loss: 3.4133 - accuracy: 0.2072\n",
      "Epoch 36/64\n",
      "559/559 [==============================] - 5s 9ms/step - loss: 3.4114 - accuracy: 0.2078\n",
      "Epoch 37/64\n",
      "559/559 [==============================] - 5s 9ms/step - loss: 3.4151 - accuracy: 0.2078\n",
      "Epoch 38/64\n",
      "559/559 [==============================] - 5s 9ms/step - loss: 3.4029 - accuracy: 0.2102\n",
      "Epoch 39/64\n",
      "559/559 [==============================] - 5s 9ms/step - loss: 3.4159 - accuracy: 0.2074\n",
      "Epoch 40/64\n",
      "559/559 [==============================] - 5s 9ms/step - loss: 3.4086 - accuracy: 0.2088\n",
      "Epoch 41/64\n",
      "559/559 [==============================] - 5s 9ms/step - loss: 3.4073 - accuracy: 0.2075\n",
      "Epoch 42/64\n",
      "559/559 [==============================] - 5s 9ms/step - loss: 3.4044 - accuracy: 0.2082\n",
      "Epoch 43/64\n",
      "559/559 [==============================] - 5s 9ms/step - loss: 3.4143 - accuracy: 0.2070\n",
      "Epoch 44/64\n",
      "559/559 [==============================] - 5s 9ms/step - loss: 3.4250 - accuracy: 0.2053\n",
      "Epoch 45/64\n",
      "559/559 [==============================] - 5s 9ms/step - loss: 3.4110 - accuracy: 0.2075\n",
      "Epoch 46/64\n",
      "559/559 [==============================] - 5s 9ms/step - loss: 3.4143 - accuracy: 0.2065\n",
      "Epoch 47/64\n",
      "559/559 [==============================] - 5s 9ms/step - loss: 3.4092 - accuracy: 0.2076\n",
      "Epoch 48/64\n",
      "559/559 [==============================] - 5s 9ms/step - loss: 3.4111 - accuracy: 0.2075\n",
      "Epoch 49/64\n",
      "559/559 [==============================] - 5s 9ms/step - loss: 3.4069 - accuracy: 0.2089\n",
      "Epoch 50/64\n",
      "559/559 [==============================] - 5s 9ms/step - loss: 3.4078 - accuracy: 0.2068\n",
      "Epoch 51/64\n",
      "559/559 [==============================] - 5s 9ms/step - loss: 3.4083 - accuracy: 0.2070\n",
      "Epoch 52/64\n",
      "559/559 [==============================] - 5s 9ms/step - loss: 3.4046 - accuracy: 0.2101\n",
      "Epoch 53/64\n",
      "559/559 [==============================] - 5s 9ms/step - loss: 3.4011 - accuracy: 0.2083\n",
      "Epoch 54/64\n",
      "559/559 [==============================] - 5s 9ms/step - loss: 3.4058 - accuracy: 0.2077\n",
      "Epoch 55/64\n",
      "559/559 [==============================] - 5s 9ms/step - loss: 3.4094 - accuracy: 0.2073\n",
      "Epoch 56/64\n",
      "559/559 [==============================] - 5s 9ms/step - loss: 3.3990 - accuracy: 0.2078\n",
      "Epoch 57/64\n",
      "559/559 [==============================] - 5s 10ms/step - loss: 3.3985 - accuracy: 0.2084\n",
      "Epoch 58/64\n",
      "559/559 [==============================] - 5s 10ms/step - loss: 3.4025 - accuracy: 0.2097\n",
      "Epoch 59/64\n",
      "559/559 [==============================] - 5s 10ms/step - loss: 3.4068 - accuracy: 0.2072\n",
      "Epoch 60/64\n",
      "559/559 [==============================] - 5s 10ms/step - loss: 3.3909 - accuracy: 0.2098\n",
      "Epoch 61/64\n",
      "559/559 [==============================] - 5s 10ms/step - loss: 3.3982 - accuracy: 0.2081\n",
      "Epoch 62/64\n",
      "559/559 [==============================] - 5s 10ms/step - loss: 3.3951 - accuracy: 0.2092\n",
      "Epoch 63/64\n",
      "559/559 [==============================] - 5s 9ms/step - loss: 3.3911 - accuracy: 0.2094\n",
      "Epoch 64/64\n",
      "559/559 [==============================] - 5s 9ms/step - loss: 3.4057 - accuracy: 0.2079\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7faf930c6ef0>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lstm.fit(reshaped_values, train_labels, epochs=64, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4469/4469 [==============================] - 10s 2ms/step - loss: 6.4039 - accuracy: 0.1330\n",
      "train loss, train acc: [6.40390682220459, 0.13299249112606049]\n"
     ]
    }
   ],
   "source": [
    "print(\"train loss, train acc:\", model_lstm.evaluate(reshaped_values, train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1637/1637 [==============================] - 4s 2ms/step - loss: 6.6202 - accuracy: 0.1252\n",
      "test loss, test acc: [6.620239734649658, 0.12522679567337036]\n"
     ]
    }
   ],
   "source": [
    "print(\"test loss, test acc:\", model_lstm.evaluate(test_set.values.reshape(-1, 1, 3), test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decisions Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, train_labels = get_labels(two_sentence_train, label=[\"words\"])\n",
    "test_set, test_labels = get_labels(two_sentence_test, label=[\"words\"])\n",
    "\n",
    "train_labels, test_labels, _ = prepare_labels(train_labels, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'criterion':['gini', 'entropy'], 'max_depth':[12, None], 'splitter':['best'],\n",
    "              'min_samples_split':[2], 'random_state':[42]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_clf = DecisionTreeClassifier()\n",
    "gscv_clf = GridSearchCV(orig_clf, parameters, n_jobs = -1, cv=cv_dialect_splitter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting!\n",
      "Finished!\n",
      "Best: 0.143448 using {'criterion': 'gini', 'max_depth': 12, 'min_samples_split': 2, 'random_state': 42, 'splitter': 'best'}\n",
      "Train accuracy: 0.1515\n",
      "Test accuracy : 0.1411\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting!\")\n",
    "gscv_clf.fit(train_set, train_labels)\n",
    "print(\"Finished!\")\n",
    "\n",
    "print(\"Best: %f using %s\" % (gscv_clf.best_score_, gscv_clf.best_params_))\n",
    "print(f\"Train accuracy: {gscv_clf.score(train_set, train_labels):.4f}\")\n",
    "print(f\"Test accuracy : {gscv_clf.score(test_set, test_labels):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_clf_pipeline = Pipeline(\n",
    "    [\n",
    "        (\n",
    "            \"clf\",\n",
    "            DecisionTreeClassifier(criterion=\"entropy\", max_depth=None, splitter=\"best\",\n",
    "                                   min_samples_split=2, random_state=42),\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting!\n",
      "Finished!\n",
      "Train accuracy: 0.5392\n",
      "Test accuracy : 0.1512\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting!\")\n",
    "tree_clf_pipeline.fit(train_set, train_labels)\n",
    "print(\"Finished!\")\n",
    "\n",
    "print(f\"Train accuracy: {tree_clf_pipeline.score(train_set, train_labels):.4f}\")\n",
    "print(f\"Test accuracy : {tree_clf_pipeline.score(test_set, test_labels):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Phonemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xkadlec6/.local/lib/python3.6/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "train_set, train_labels = get_labels(two_sentence_train, label=[\"phonemes\"])\n",
    "test_set, test_labels = get_labels(two_sentence_test, label=[\"phonemes\"])\n",
    "\n",
    "train_labels, test_labels, _ = prepare_labels(train_labels, test_labels, label=[\"phonemes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'criterion':['gini', 'entropy'], 'max_depth':[12, None], 'splitter':['best'],\n",
    "              'min_samples_split':[2], 'random_state':[42]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_clf = DecisionTreeClassifier()\n",
    "gscv_clf = GridSearchCV(orig_clf, parameters, n_jobs = -1, cv=cv_dialect_splitter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting!\n",
      "Finished!\n",
      "Best: 0.143448 using {'criterion': 'gini', 'max_depth': 12, 'min_samples_split': 2, 'random_state': 42, 'splitter': 'best'}\n",
      "Train accuracy: 0.1515\n",
      "Test accuracy : 0.1411\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting!\")\n",
    "gscv_clf.fit(train_set, train_labels)\n",
    "print(\"Finished!\")\n",
    "\n",
    "print(\"Best: %f using %s\" % (gscv_clf.best_score_, gscv_clf.best_params_))\n",
    "print(f\"Train accuracy: {gscv_clf.score(train_set, train_labels):.4f}\")\n",
    "print(f\"Test accuracy : {gscv_clf.score(test_set, test_labels):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_clf_pipeline = Pipeline(\n",
    "    [\n",
    "        (\n",
    "            \"clf\",\n",
    "            DecisionTreeClassifier(criterion=\"entropy\", max_depth=None, splitter=\"best\",\n",
    "                                   min_samples_split=2, random_state=42),\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting!\n",
      "Finished!\n",
      "Train accuracy: 0.5287\n",
      "Test accuracy : 0.1410\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting!\")\n",
    "tree_clf_pipeline.fit(train_set, train_labels)\n",
    "print(\"Finished!\")\n",
    "\n",
    "print(f\"Train accuracy: {tree_clf_pipeline.score(train_set, train_labels):.4f}\")\n",
    "print(f\"Test accuracy : {tree_clf_pipeline.score(test_set, test_labels):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xkadlec6/.local/lib/python3.6/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "train_set, train_labels = get_labels(two_sentence_train, label=[\"words\"])\n",
    "test_set, test_labels = get_labels(two_sentence_test, label=[\"words\"])\n",
    "\n",
    "train_labels, test_labels, _ = prepare_labels(two_sentence_train, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'n_neighbors':[16,32], 'weights':['uniform', 'distance'], 'n_jobs':[-1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_clf = KNeighborsClassifier()\n",
    "gscv_clf = GridSearchCV(orig_clf, parameters, n_jobs = -1, cv=cv_dialect_splitter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting!\n",
      "Finished!\n",
      "Best: 0.136635 using {'n_jobs': -1, 'n_neighbors': 32, 'weights': 'uniform'}\n",
      "Train accuracy: 0.1700\n",
      "Test accuracy : 0.1343\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting!\")\n",
    "gscv_clf.fit(train_set, train_labels)\n",
    "print(\"Finished!\")\n",
    "\n",
    "print(\"Best: %f using %s\" % (gscv_clf.best_score_, gscv_clf.best_params_))\n",
    "print(f\"Train accuracy: {gscv_clf.score(train_set, train_labels):.4f}\")\n",
    "print(f\"Test accuracy : {gscv_clf.score(test_set, test_labels):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_clf_pipeline = Pipeline(\n",
    "    [\n",
    "        (\n",
    "            \"scaler\",\n",
    "            StandardScaler()\n",
    "        ),\n",
    "        (\n",
    "            \"clf\",\n",
    "            KNeighborsClassifier(32, weights='distance', n_jobs=-1)\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 20, distance => 0.2887, 0.1203\n",
    "# 32, uniform => 0.1700, 0.1343\n",
    "# 32, distance => 0.2912, 0.1216"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting!\n",
      "Finished!\n",
      "Train accuracy: 0.5392\n",
      "Test accuracy : 0.1664\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting!\")\n",
    "knn_clf_pipeline.fit(train_set, train_labels)\n",
    "print(\"Finished!\")\n",
    "\n",
    "print(f\"Train accuracy: {knn_clf_pipeline.score(train_set, train_labels):.4f}\")\n",
    "print(f\"Test accuracy : {knn_clf_pipeline.score(test_set, test_labels):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the search space of 32 nearest neighbours we get around 12% success rate on our test data (which is around 31436 words). I have listed other parameters and their resulting percentages in the comments in the code cell. Also worth noting is that \"StandardScaler\" only worsens (not tested on skype) our predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try our luck with phonemes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xkadlec6/.local/lib/python3.6/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "train_set, train_labels = get_labels(two_sentence_train, label=[\"phonemes\"])\n",
    "test_set, test_labels = get_labels(two_sentence_test, label=[\"phonemes\"])\n",
    "\n",
    "train_labels, test_labels, _ = prepare_labels(train_labels, test_labels, label=[\"phonemes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'n_neighbors':[16,32], 'weights':['uniform', 'distance'], 'n_jobs':[-1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_clf = KNeighborsClassifier()\n",
    "gscv_clf = GridSearchCV(orig_clf, parameters, n_jobs = -1, cv=cv_dialect_splitter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting!\n",
      "Finished!\n",
      "Best: 0.136635 using {'n_jobs': -1, 'n_neighbors': 32, 'weights': 'uniform'}\n",
      "Train accuracy: 0.1700\n",
      "Test accuracy : 0.1343\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting!\")\n",
    "gscv_clf.fit(train_set, train_labels)\n",
    "print(\"Finished!\")\n",
    "\n",
    "print(\"Best: %f using %s\" % (gscv_clf.best_score_, gscv_clf.best_params_))\n",
    "print(f\"Train accuracy: {gscv_clf.score(train_set, train_labels):.4f}\")\n",
    "print(f\"Test accuracy : {gscv_clf.score(test_set, test_labels):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_clf_pipeline = Pipeline(\n",
    "    [\n",
    "        (\n",
    "            \"clf\",\n",
    "            KNeighborsClassifier(32, weights='distance', n_jobs=-1)\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "# 20, distance => 0.3221, 0.1377\n",
    "# 32, uniform => 0.2093, 0.1574\n",
    "# 32, distance => 0.3265, 0.1410"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting!\n",
      "Finished!\n",
      "Train accuracy: 0.5287\n",
      "Test accuracy : 0.1586\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting!\")\n",
    "knn_clf_pipeline.fit(train_set, train_labels)\n",
    "print(\"Finished!\")\n",
    "\n",
    "print(f\"Train accuracy: {knn_clf_pipeline.score(train_set, train_labels):.4f}\")\n",
    "print(f\"Test accuracy : {knn_clf_pipeline.score(test_set, test_labels):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
