{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replication of attack on VoIP end-to-end encrypted messengers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now try to explore various models on `skype` dataset. Bellow we will find loading and preprocessing that we have come up with in the analysis section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "sns.set()  # make plots nicer\n",
    "\n",
    "np.random.seed(42)  # set seed for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_parser_with_prev_next(path):\n",
    "    file = open(path, 'r')\n",
    "    lines = file.readlines()\n",
    "    \n",
    "    file_name = [path.split('/')[-1]]\n",
    "    sentence = \"\"\n",
    "    file_data = []\n",
    "    \n",
    "    has_value = False\n",
    "    previous = 0\n",
    "    \n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        \n",
    "        # if there are only 2 informations on line and second is h#, then ignore\n",
    "        # strip line, split primarly on ; secondary on ,\n",
    "        if (line.startswith('#')):\n",
    "            if (not sentence):\n",
    "                sentence = line[len('# Sentence: \"'): len(line) - 1]\n",
    "            continue\n",
    "        \n",
    "        line = line.split(';')\n",
    "        \n",
    "        if (len(line) == 1):\n",
    "            #lines containing only their packet size and nothing else, they should be added\n",
    "            #TODO\n",
    "            line += [\"\"]\n",
    "            line += [\"\"]\n",
    "            #continue\n",
    "        \n",
    "        if (len(line) == 2):\n",
    "            #this tries to remove most of the silence at the start of the recording\n",
    "            #potentionally harmfull as we shouldn't clean test data this way (we will be reading labels)\n",
    "            #if (line[1] == 'h#'):\n",
    "            #    continue\n",
    "            line += [\"\"]\n",
    "        \n",
    "        line[1] = tuple(line[1].split(','))\n",
    "        line[2] = tuple(list(map(lambda a: a.strip('\"'), line[2].split(','))))\n",
    "        \n",
    "        if (has_value):\n",
    "            file_data[-1][4] = line[0]\n",
    "           \n",
    "        # file_type and sentence contain duplicate informations, but are kept for readability\n",
    "        line = file_name + [file_name[0][0:9]] + [sentence] + [previous] + [0] + line\n",
    "        #adding previous as feature\n",
    "        previous = line[5]\n",
    "        file_data += [line]\n",
    "        \n",
    "        #adding next frame as feature\n",
    "        has_value = True\n",
    "        \n",
    "    return pd.DataFrame(file_data, columns=['file', 'speaker', 'sentence', 'previous_packet', 'next_packet','packet_size', 'phonemes', 'words'])\n",
    "\n",
    "def load_files_with_prev_next(directory):\n",
    "    filelist = os.listdir(directory)\n",
    "    #read them into pandas\n",
    "    df_list = [file_parser_with_prev_next(directory+file) for file in filelist]\n",
    "    #concatenate them together\n",
    "    return pd.concat(df_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_types(data_frame):\n",
    "    data_frame['packet_size'] = pd.to_numeric(data_frame['packet_size'])\n",
    "    data_frame['previous_packet'] = pd.to_numeric(data_frame['previous_packet'])\n",
    "    data_frame['next_packet'] = pd.to_numeric(data_frame['next_packet'])\n",
    "\n",
    "    data_frame['file'] = data_frame['file'].astype('category')\n",
    "    data_frame['sentence'] = data_frame['sentence'].astype('category')\n",
    "    data_frame['speaker'] = data_frame['speaker'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>speaker</th>\n",
       "      <th>sentence</th>\n",
       "      <th>previous_packet</th>\n",
       "      <th>next_packet</th>\n",
       "      <th>packet_size</th>\n",
       "      <th>phonemes</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DR1-FAKS0-SA1.CSV</td>\n",
       "      <td>DR1-FAKS0</td>\n",
       "      <td>She had your dark suit in greasy wash water al...</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>30</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DR1-FAKS0-SA1.CSV</td>\n",
       "      <td>DR1-FAKS0</td>\n",
       "      <td>She had your dark suit in greasy wash water al...</td>\n",
       "      <td>30</td>\n",
       "      <td>43</td>\n",
       "      <td>35</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DR1-FAKS0-SA1.CSV</td>\n",
       "      <td>DR1-FAKS0</td>\n",
       "      <td>She had your dark suit in greasy wash water al...</td>\n",
       "      <td>35</td>\n",
       "      <td>26</td>\n",
       "      <td>43</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DR1-FAKS0-SA1.CSV</td>\n",
       "      <td>DR1-FAKS0</td>\n",
       "      <td>She had your dark suit in greasy wash water al...</td>\n",
       "      <td>43</td>\n",
       "      <td>30</td>\n",
       "      <td>26</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DR1-FAKS0-SA1.CSV</td>\n",
       "      <td>DR1-FAKS0</td>\n",
       "      <td>She had your dark suit in greasy wash water al...</td>\n",
       "      <td>26</td>\n",
       "      <td>31</td>\n",
       "      <td>30</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258516</th>\n",
       "      <td>DR8-MSLB0-SX383.CSV</td>\n",
       "      <td>DR8-MSLB0</td>\n",
       "      <td>The carpet cleaners shampooed our oriental rug.</td>\n",
       "      <td>40</td>\n",
       "      <td>43</td>\n",
       "      <td>46</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258517</th>\n",
       "      <td>DR8-MSLB0-SX383.CSV</td>\n",
       "      <td>DR8-MSLB0</td>\n",
       "      <td>The carpet cleaners shampooed our oriental rug.</td>\n",
       "      <td>46</td>\n",
       "      <td>41</td>\n",
       "      <td>43</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258518</th>\n",
       "      <td>DR8-MSLB0-SX383.CSV</td>\n",
       "      <td>DR8-MSLB0</td>\n",
       "      <td>The carpet cleaners shampooed our oriental rug.</td>\n",
       "      <td>43</td>\n",
       "      <td>34</td>\n",
       "      <td>41</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258519</th>\n",
       "      <td>DR8-MSLB0-SX383.CSV</td>\n",
       "      <td>DR8-MSLB0</td>\n",
       "      <td>The carpet cleaners shampooed our oriental rug.</td>\n",
       "      <td>41</td>\n",
       "      <td>33</td>\n",
       "      <td>34</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258520</th>\n",
       "      <td>DR8-MSLB0-SX383.CSV</td>\n",
       "      <td>DR8-MSLB0</td>\n",
       "      <td>The carpet cleaners shampooed our oriental rug.</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>258521 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       file    speaker  \\\n",
       "0         DR1-FAKS0-SA1.CSV  DR1-FAKS0   \n",
       "1         DR1-FAKS0-SA1.CSV  DR1-FAKS0   \n",
       "2         DR1-FAKS0-SA1.CSV  DR1-FAKS0   \n",
       "3         DR1-FAKS0-SA1.CSV  DR1-FAKS0   \n",
       "4         DR1-FAKS0-SA1.CSV  DR1-FAKS0   \n",
       "...                     ...        ...   \n",
       "258516  DR8-MSLB0-SX383.CSV  DR8-MSLB0   \n",
       "258517  DR8-MSLB0-SX383.CSV  DR8-MSLB0   \n",
       "258518  DR8-MSLB0-SX383.CSV  DR8-MSLB0   \n",
       "258519  DR8-MSLB0-SX383.CSV  DR8-MSLB0   \n",
       "258520  DR8-MSLB0-SX383.CSV  DR8-MSLB0   \n",
       "\n",
       "                                                 sentence  previous_packet  \\\n",
       "0       She had your dark suit in greasy wash water al...                0   \n",
       "1       She had your dark suit in greasy wash water al...               30   \n",
       "2       She had your dark suit in greasy wash water al...               35   \n",
       "3       She had your dark suit in greasy wash water al...               43   \n",
       "4       She had your dark suit in greasy wash water al...               26   \n",
       "...                                                   ...              ...   \n",
       "258516    The carpet cleaners shampooed our oriental rug.               40   \n",
       "258517    The carpet cleaners shampooed our oriental rug.               46   \n",
       "258518    The carpet cleaners shampooed our oriental rug.               43   \n",
       "258519    The carpet cleaners shampooed our oriental rug.               41   \n",
       "258520    The carpet cleaners shampooed our oriental rug.               34   \n",
       "\n",
       "        next_packet  packet_size phonemes words  \n",
       "0                35           30    (h#,)   (,)  \n",
       "1                43           35    (h#,)   (,)  \n",
       "2                26           43    (h#,)   (,)  \n",
       "3                30           26    (h#,)   (,)  \n",
       "4                31           30    (h#,)   (,)  \n",
       "...             ...          ...      ...   ...  \n",
       "258516           43           46    (h#,)   (,)  \n",
       "258517           41           43    (h#,)   (,)  \n",
       "258518           34           41    (h#,)   (,)  \n",
       "258519           33           34    (h#,)   (,)  \n",
       "258520            0           33    (h#,)   (,)  \n",
       "\n",
       "[258521 rows x 8 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skype_data_train = load_files_with_prev_next(\"./../data/skype_train_data/\")\n",
    "skype_data_test = load_files_with_prev_next(\"./../data/skype_test_data/\")\n",
    "convert_types(skype_data_train)\n",
    "convert_types(skype_data_test)\n",
    "skype_data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>speaker</th>\n",
       "      <th>sentence</th>\n",
       "      <th>previous_packet</th>\n",
       "      <th>next_packet</th>\n",
       "      <th>packet_size</th>\n",
       "      <th>prev_curr</th>\n",
       "      <th>next_curr</th>\n",
       "      <th>packet_surrounding</th>\n",
       "      <th>phonemes</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DR1-FCJF0-SA1.CSV</td>\n",
       "      <td>DR1-FCJF0</td>\n",
       "      <td>She had your dark suit in greasy wash water al...</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>(0, 32)</td>\n",
       "      <td>(32, 32)</td>\n",
       "      <td>(0, 32, 32)</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DR1-FCJF0-SA1.CSV</td>\n",
       "      <td>DR1-FCJF0</td>\n",
       "      <td>She had your dark suit in greasy wash water al...</td>\n",
       "      <td>32</td>\n",
       "      <td>31</td>\n",
       "      <td>32</td>\n",
       "      <td>(32, 32)</td>\n",
       "      <td>(31, 32)</td>\n",
       "      <td>(32, 32, 31)</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DR1-FCJF0-SA1.CSV</td>\n",
       "      <td>DR1-FCJF0</td>\n",
       "      <td>She had your dark suit in greasy wash water al...</td>\n",
       "      <td>32</td>\n",
       "      <td>28</td>\n",
       "      <td>31</td>\n",
       "      <td>(32, 31)</td>\n",
       "      <td>(28, 31)</td>\n",
       "      <td>(32, 31, 28)</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DR1-FCJF0-SA1.CSV</td>\n",
       "      <td>DR1-FCJF0</td>\n",
       "      <td>She had your dark suit in greasy wash water al...</td>\n",
       "      <td>31</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>(31, 28)</td>\n",
       "      <td>(28, 28)</td>\n",
       "      <td>(31, 28, 28)</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DR1-FCJF0-SA1.CSV</td>\n",
       "      <td>DR1-FCJF0</td>\n",
       "      <td>She had your dark suit in greasy wash water al...</td>\n",
       "      <td>28</td>\n",
       "      <td>36</td>\n",
       "      <td>28</td>\n",
       "      <td>(28, 28)</td>\n",
       "      <td>(36, 28)</td>\n",
       "      <td>(28, 28, 36)</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707433</th>\n",
       "      <td>DR8-MTCS0-SX82.CSV</td>\n",
       "      <td>DR8-MTCS0</td>\n",
       "      <td>Good service should be rewarded by big tips.</td>\n",
       "      <td>47</td>\n",
       "      <td>34</td>\n",
       "      <td>32</td>\n",
       "      <td>(47, 32)</td>\n",
       "      <td>(34, 32)</td>\n",
       "      <td>(47, 32, 34)</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707434</th>\n",
       "      <td>DR8-MTCS0-SX82.CSV</td>\n",
       "      <td>DR8-MTCS0</td>\n",
       "      <td>Good service should be rewarded by big tips.</td>\n",
       "      <td>32</td>\n",
       "      <td>39</td>\n",
       "      <td>34</td>\n",
       "      <td>(32, 34)</td>\n",
       "      <td>(39, 34)</td>\n",
       "      <td>(32, 34, 39)</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707435</th>\n",
       "      <td>DR8-MTCS0-SX82.CSV</td>\n",
       "      <td>DR8-MTCS0</td>\n",
       "      <td>Good service should be rewarded by big tips.</td>\n",
       "      <td>34</td>\n",
       "      <td>33</td>\n",
       "      <td>39</td>\n",
       "      <td>(34, 39)</td>\n",
       "      <td>(33, 39)</td>\n",
       "      <td>(34, 39, 33)</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707436</th>\n",
       "      <td>DR8-MTCS0-SX82.CSV</td>\n",
       "      <td>DR8-MTCS0</td>\n",
       "      <td>Good service should be rewarded by big tips.</td>\n",
       "      <td>39</td>\n",
       "      <td>36</td>\n",
       "      <td>33</td>\n",
       "      <td>(39, 33)</td>\n",
       "      <td>(36, 33)</td>\n",
       "      <td>(39, 33, 36)</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707437</th>\n",
       "      <td>DR8-MTCS0-SX82.CSV</td>\n",
       "      <td>DR8-MTCS0</td>\n",
       "      <td>Good service should be rewarded by big tips.</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>(33, 36)</td>\n",
       "      <td>(0, 36)</td>\n",
       "      <td>(33, 36, 0)</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>707438 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      file    speaker  \\\n",
       "0        DR1-FCJF0-SA1.CSV  DR1-FCJF0   \n",
       "1        DR1-FCJF0-SA1.CSV  DR1-FCJF0   \n",
       "2        DR1-FCJF0-SA1.CSV  DR1-FCJF0   \n",
       "3        DR1-FCJF0-SA1.CSV  DR1-FCJF0   \n",
       "4        DR1-FCJF0-SA1.CSV  DR1-FCJF0   \n",
       "...                    ...        ...   \n",
       "707433  DR8-MTCS0-SX82.CSV  DR8-MTCS0   \n",
       "707434  DR8-MTCS0-SX82.CSV  DR8-MTCS0   \n",
       "707435  DR8-MTCS0-SX82.CSV  DR8-MTCS0   \n",
       "707436  DR8-MTCS0-SX82.CSV  DR8-MTCS0   \n",
       "707437  DR8-MTCS0-SX82.CSV  DR8-MTCS0   \n",
       "\n",
       "                                                 sentence  previous_packet  \\\n",
       "0       She had your dark suit in greasy wash water al...                0   \n",
       "1       She had your dark suit in greasy wash water al...               32   \n",
       "2       She had your dark suit in greasy wash water al...               32   \n",
       "3       She had your dark suit in greasy wash water al...               31   \n",
       "4       She had your dark suit in greasy wash water al...               28   \n",
       "...                                                   ...              ...   \n",
       "707433       Good service should be rewarded by big tips.               47   \n",
       "707434       Good service should be rewarded by big tips.               32   \n",
       "707435       Good service should be rewarded by big tips.               34   \n",
       "707436       Good service should be rewarded by big tips.               39   \n",
       "707437       Good service should be rewarded by big tips.               33   \n",
       "\n",
       "        next_packet  packet_size prev_curr next_curr packet_surrounding  \\\n",
       "0                32           32   (0, 32)  (32, 32)        (0, 32, 32)   \n",
       "1                31           32  (32, 32)  (31, 32)       (32, 32, 31)   \n",
       "2                28           31  (32, 31)  (28, 31)       (32, 31, 28)   \n",
       "3                28           28  (31, 28)  (28, 28)       (31, 28, 28)   \n",
       "4                36           28  (28, 28)  (36, 28)       (28, 28, 36)   \n",
       "...             ...          ...       ...       ...                ...   \n",
       "707433           34           32  (47, 32)  (34, 32)       (47, 32, 34)   \n",
       "707434           39           34  (32, 34)  (39, 34)       (32, 34, 39)   \n",
       "707435           33           39  (34, 39)  (33, 39)       (34, 39, 33)   \n",
       "707436           36           33  (39, 33)  (36, 33)       (39, 33, 36)   \n",
       "707437            0           36  (33, 36)   (0, 36)        (33, 36, 0)   \n",
       "\n",
       "       phonemes words  \n",
       "0         (h#,)   (,)  \n",
       "1         (h#,)   (,)  \n",
       "2         (h#,)   (,)  \n",
       "3         (h#,)   (,)  \n",
       "4         (h#,)   (,)  \n",
       "...         ...   ...  \n",
       "707433    (h#,)   (,)  \n",
       "707434    (h#,)   (,)  \n",
       "707435    (h#,)   (,)  \n",
       "707436    (h#,)   (,)  \n",
       "707437    (h#,)   (,)  \n",
       "\n",
       "[707438 rows x 11 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_surrounding(data_frame):\n",
    "    data_frame['prev_curr'] = list(zip(data_frame.previous_packet, data_frame.packet_size))\n",
    "    data_frame['next_curr'] = list(zip(data_frame.next_packet, data_frame.packet_size))\n",
    "    data_frame['packet_surrounding'] = list(zip(data_frame.previous_packet, data_frame.packet_size, data_frame.next_packet))\n",
    "    \n",
    "    #data_frame['prev_curr'] = data_frame['prev_curr'].astype('category')\n",
    "    #data_frame['next_curr'] = data_frame['next_curr'].astype('category')\n",
    "    #data_frame['packet_surrounding'] = data_frame['packet_surrounding'].astype('category')\n",
    "\n",
    "add_surrounding(skype_data_train)\n",
    "add_surrounding(skype_data_test)\n",
    "\n",
    "skype_data_train = skype_data_train[['file', 'speaker', 'sentence', 'previous_packet', 'next_packet','packet_size', 'prev_curr', 'next_curr', 'packet_surrounding', 'phonemes', 'words']]\n",
    "skype_data_test = skype_data_test[['file', 'speaker', 'sentence', 'previous_packet', 'next_packet','packet_size', 'prev_curr', 'next_curr', 'packet_surrounding', 'phonemes', 'words']]\n",
    "skype_data_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add removal of labels for the test_dataset\n",
    "def get_labels(df, label=[\"words\"], feature=[\"previous_packet\", \"packet_size\", \"next_packet\"]):\n",
    "    labels = df.loc[:, label]\n",
    "    features = df.loc[:, feature]\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_labels(train_labels, test_labels, label=[\"words\"]):\n",
    "    train_labels = train_labels.astype('category')\n",
    "    test_labels = test_labels.astype('category')\n",
    "    \n",
    "    total_labels = train_labels.append(test_labels)\n",
    "    \n",
    "    lab_enc = LabelEncoder()\n",
    "    lab_enc.fit(total_labels[label])\n",
    "\n",
    "    train_labels = lab_enc.transform(train_labels[label])\n",
    "    test_labels = lab_enc.transform(test_labels[label])\n",
    "    \n",
    "    return train_labels, test_labels, lab_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15713\n",
      "6626\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20568"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set, train_labels = get_labels(skype_data_train)\n",
    "test_set, test_labels = get_labels(skype_data_test)\n",
    "\n",
    "train_labels = train_labels.astype('category')\n",
    "test_labels = test_labels.astype('category')\n",
    "\n",
    "total_labels = train_labels.append(test_labels)\n",
    "print(len(pd.unique(train_labels.words)))\n",
    "print(len(pd.unique(test_labels.words)))\n",
    "total_unique_words = len(pd.unique(total_labels.words))\n",
    "total_unique_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can see that we have a really big problem => there are 4855 new words that we have never seen. As we saw in our analysis we can't really generalise on never seen words before => this will hinder our results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3083\n",
      "2363\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3281"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set, train_labels = get_labels(skype_data_train, label=['phonemes'])\n",
    "test_set, test_labels = get_labels(skype_data_test, label=['phonemes'])\n",
    "\n",
    "train_labels = train_labels.astype('category')\n",
    "test_labels = test_labels.astype('category')\n",
    "\n",
    "total_labels = train_labels.append(test_labels)\n",
    "print(len(pd.unique(train_labels.phonemes)))\n",
    "print(len(pd.unique(test_labels.phonemes)))\n",
    "total_unique_phonemes = len(pd.unique(total_labels.phonemes))\n",
    "total_unique_phonemes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But this is really promissing. There are only 198 new phonemes, that we haven't seen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First model that we will be trying is tree classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, train_labels = get_labels(skype_data_train, label=[\"words\"])\n",
    "test_set, test_labels = get_labels(skype_data_test, label=[\"words\"])\n",
    "\n",
    "train_labels, test_labels, _ = prepare_labels(train_labels, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_clf_pipeline = Pipeline(\n",
    "    [\n",
    "        (\n",
    "            \"clf\",\n",
    "            DecisionTreeClassifier(criterion=\"entropy\", max_depth=None, splitter=\"best\",\n",
    "                                   min_samples_split=2, random_state=42),\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting!\n",
      "Finished!\n",
      "Train accuracy: 0.2925\n",
      "Test accuracy : 0.1195\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting!\")\n",
    "tree_clf_pipeline.fit(train_set, train_labels)\n",
    "print(\"Finished!\")\n",
    "\n",
    "print(f\"Train accuracy: {tree_clf_pipeline.score(train_set, train_labels):.4f}\")\n",
    "print(f\"Test accuracy : {tree_clf_pipeline.score(test_set, test_labels):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Phonemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, train_labels = get_labels(skype_data_train, label=[\"phonemes\"])\n",
    "test_set, test_labels = get_labels(skype_data_test, label=[\"phonemes\"])\n",
    "\n",
    "train_labels, test_labels, _ = prepare_labels(train_labels, test_labels, label=[\"phonemes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting!\n",
      "Finished!\n",
      "Train accuracy: 0.3282\n",
      "Test accuracy : 0.1399\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting!\")\n",
    "tree_clf_pipeline.fit(train_set, train_labels)\n",
    "print(\"Finished!\")\n",
    "\n",
    "print(f\"Train accuracy: {tree_clf_pipeline.score(train_set, train_labels):.4f}\")\n",
    "print(f\"Test accuracy : {tree_clf_pipeline.score(test_set, test_labels):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is already quite a promissing success rate for \"just a simple\" tree classifier. Also as we can see, `phonemes` give better results in skype dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look a different kind of classifier => k nearest neighbours. This classifier shouldn't need that much RAM and that much of a computational power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xkadlec6/.local/lib/python3.6/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "train_set, train_labels = get_labels(skype_data_train, label=[\"words\"])\n",
    "test_set, test_labels = get_labels(skype_data_test, label=[\"words\"])\n",
    "\n",
    "train_labels, test_labels, _ = prepare_labels(train_labels, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_clf_pipeline = Pipeline(\n",
    "    [\n",
    "        (\n",
    "            \"scaler\",\n",
    "            StandardScaler()\n",
    "        ),\n",
    "        (\n",
    "            \"clf\",\n",
    "            KNeighborsClassifier(32, weights='distance', n_jobs=-1)\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 20, distance => 0.2887, 0.1203\n",
    "# 32, uniform => 0.1700, 0.1343\n",
    "# 32, distance => 0.2912, 0.1216"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting!\n",
      "Finished!\n",
      "Train accuracy: 0.2911\n",
      "Test accuracy : 0.1213\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting!\")\n",
    "knn_clf_pipeline.fit(train_set, train_labels)\n",
    "print(\"Finished!\")\n",
    "\n",
    "print(f\"Train accuracy: {knn_clf_pipeline.score(train_set, train_labels):.4f}\")\n",
    "print(f\"Test accuracy : {knn_clf_pipeline.score(test_set, test_labels):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the search space of 32 nearest neighbours we get around 12% success rate on our test data (which is around 31436 words). I have listed other parameters and their resulting percentages in the comments in the code cell. Also worth noting is that \"StandardScaler\" only worsens (not tested on skype) our predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try our luck with phonemes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xkadlec6/.local/lib/python3.6/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "train_set, train_labels = get_labels(skype_data_train, label=[\"phonemes\"])\n",
    "test_set, test_labels = get_labels(skype_data_test, label=[\"phonemes\"])\n",
    "\n",
    "train_labels, test_labels, _ = prepare_labels(train_labels, test_labels, label=[\"phonemes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_clf_pipeline = Pipeline(\n",
    "    [\n",
    "        (\n",
    "            \"clf\",\n",
    "            KNeighborsClassifier(32, weights='distance', n_jobs=-1)\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "# 20, distance => 0.3221, 0.1377\n",
    "# 32, uniform => 0.2093, 0.1574\n",
    "# 32, distance => 0.3265, 0.1410"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting!\n",
      "Finished!\n",
      "Train accuracy: 0.3265\n",
      "Test accuracy : 0.1410\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting!\")\n",
    "knn_clf_pipeline.fit(train_set, train_labels)\n",
    "print(\"Finished!\")\n",
    "\n",
    "print(f\"Train accuracy: {knn_clf_pipeline.score(train_set, train_labels):.4f}\")\n",
    "print(f\"Test accuracy : {knn_clf_pipeline.score(test_set, test_labels):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can clearly see that phonemes are indeed actually better than just words and help us get better predictions. But of course there is also adds the complication of how to make words from these phonemes / make something, that makes sense."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xkadlec6/.local/lib/python3.6/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "train_set, train_labels = get_labels(skype_data_train, label=[\"phonemes\"])\n",
    "test_set, test_labels = get_labels(skype_data_test, label=[\"phonemes\"])\n",
    "\n",
    "train_labels, test_labels, _ = prepare_labels(train_labels, test_labels, label=[\"phonemes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_pipeline = Pipeline(\n",
    "    [\n",
    "        (\n",
    "            \"clf\",\n",
    "            RandomForestClassifier(max_depth=12, random_state=42, criterion = 'entropy', n_jobs = -1, min_samples_split = 2)\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Starting!\")\n",
    "rfc_pipeline.fit(train_set, train_labels)\n",
    "print(\"Finished!\")\n",
    "\n",
    "print(f\"Train accuracy: {rfc_pipeline.score(train_set, train_labels):.4f}\")\n",
    "print(f\"Test accuracy : {rfc_pipeline.score(test_set, test_labels):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RAM :("
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xkadlec6/.local/lib/python3.6/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "train_set, train_labels = get_labels(skype_data_train, label=[\"words\"])\n",
    "test_set, test_labels = get_labels(skype_data_test, label=[\"words\"])\n",
    "\n",
    "train_labels, test_labels, _ = prepare_labels(train_labels, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "abc_pipeline = Pipeline(\n",
    "    [\n",
    "        (\n",
    "            \"clf\",\n",
    "            AdaBoostClassifier(random_state=1, n_estimators = 60, learning_rate=0.9)\n",
    "        ),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0505, 0.0471\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting!\")\n",
    "#abc_pipeline.fit(train_set, train_labels)\n",
    "print(\"Finished!\")\n",
    "\n",
    "#print(f\"Train accuracy: {abc_pipeline.score(train_set, train_labels):.4f}\")\n",
    "#print(f\"Test accuracy : {abc_pipeline.score(test_set, test_labels):.4f}\")\n",
    "\n",
    "print(\"0.0505, 0.0471\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This classifier ended in absolute failure as it wasn't able to get even acceptable results on the train data. And it even took 8 hours to learn (this is because it can only use 1 thread), so this classifier is pretty much worthless to us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's now try to bring out the big guns - neural networks. For this I've chosen to use TensorFlow and Keras (PyTorch could also be used). We are able to get reasonably better results but at the cost of long compute times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xkadlec6/.local/lib/python3.6/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "train_set, train_labels = get_labels(skype_data_train, label=[\"words\"])\n",
    "test_set, test_labels = get_labels(skype_data_test, label=[\"words\"])\n",
    "\n",
    "train_labels, test_labels, _ = prepare_labels(train_labels, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(707438, 3)\n",
      "(707438,)\n"
     ]
    }
   ],
   "source": [
    "print(train_set.shape)\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(707438, 20568)\n"
     ]
    }
   ],
   "source": [
    "train_labels = to_categorical(train_labels, num_classes=total_unique_words)\n",
    "test_labels = to_categorical(test_labels, num_classes=total_unique_words)\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 20568)             5285976   \n",
      "=================================================================\n",
      "Total params: 5,419,352\n",
      "Trainable params: 5,419,352\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(units=512, activation='relu', input_dim=3*1))  # first hidden layer\n",
    "model.add(Dense(units=256, activation='relu'))  # second hidden layer\n",
    "# model.add(Dense(units=128, activation='relu'))  # third hidden layer\n",
    "model.add(Dense(units=total_unique_words, activation='softmax'))  # output layer\n",
    "# model.add(Dense(units=128))  # output layer\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "2764/2764 [==============================] - 110s 39ms/step - loss: 7.0326 - accuracy: 0.1377\n",
      "Epoch 2/4\n",
      "2764/2764 [==============================] - 103s 37ms/step - loss: 6.6209 - accuracy: 0.1422\n",
      "Epoch 3/4\n",
      "2764/2764 [==============================] - 102s 37ms/step - loss: 6.5636 - accuracy: 0.1428\n",
      "Epoch 4/4\n",
      "2764/2764 [==============================] - 100s 36ms/step - loss: 6.5314 - accuracy: 0.1433\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f6d28076080>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_set, train_labels, epochs=4, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8079/8079 [==============================] - 55s 7ms/step - loss: 9.7407 - accuracy: 0.1413\n",
      "test loss, test acc: [9.740732192993164, 0.14129993319511414]\n"
     ]
    }
   ],
   "source": [
    "print(\"test loss, test acc:\", model.evaluate(test_set, test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "batch size = 128:  \n",
    "test loss, test acc: [12.597193717956543, 0.1413850337266922] => 128 epochs  \n",
    "\n",
    "batch size = 256:  \n",
    "test loss, test acc: [9.740732192993164, 0.14129993319511414] => 4 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not used\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "pred_y = model.predict(test_set)\n",
    "print(len(pred_y))\n",
    "print(pred_y[0])\n",
    "\n",
    "pred_y_labels = [0]*len(pred_y)\n",
    "for i in range(len(pred_y)):\n",
    "    pred_y_labels[i] = np.argmax(pred_y[i])\n",
    "    \n",
    "print(pred_y_labels[0])\n",
    "\n",
    "print(classification_report(test_labels, pred_y_labels))\n",
    "\"\"\"\n",
    "print(\"Not used\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that changing epoch count doesn't change the results that much and we should try to explore different models / architectures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Phonemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xkadlec6/.local/lib/python3.6/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "train_set, train_labels = get_labels(skype_data_train, label=[\"phonemes\"])\n",
    "test_set, test_labels = get_labels(skype_data_test, label=[\"phonemes\"])\n",
    "\n",
    "train_labels, test_labels, _ = prepare_labels(train_labels, test_labels, label=[\"phonemes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(707438, 3)\n",
      "(707438,)\n"
     ]
    }
   ],
   "source": [
    "print(train_set.shape)\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(707438, 3281)\n"
     ]
    }
   ],
   "source": [
    "train_labels = to_categorical(train_labels, num_classes=total_unique_phonemes)\n",
    "test_labels = to_categorical(test_labels, num_classes=total_unique_phonemes)\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 3281)              843217    \n",
      "=================================================================\n",
      "Total params: 976,593\n",
      "Trainable params: 976,593\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(units=512, activation='relu', input_dim=3*1))  # first hidden layer\n",
    "model.add(Dense(units=256, activation='relu'))  # second hidden layer\n",
    "# model.add(Dense(units=128, activation='relu'))  # third hidden layer\n",
    "model.add(Dense(units=total_unique_phonemes, activation='softmax'))  # output layer\n",
    "# model.add(Dense(units=128))  # output layer\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "2764/2764 [==============================] - 32s 11ms/step - loss: 4.5476 - accuracy: 0.1544\n",
      "Epoch 2/4\n",
      "2764/2764 [==============================] - 30s 11ms/step - loss: 4.1565 - accuracy: 0.1777\n",
      "Epoch 3/4\n",
      "2764/2764 [==============================] - 30s 11ms/step - loss: 4.1220 - accuracy: 0.1795\n",
      "Epoch 4/4\n",
      "2764/2764 [==============================] - 31s 11ms/step - loss: 4.1061 - accuracy: 0.1802\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f6d282227b8>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_set, train_labels, epochs=4, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8079/8079 [==============================] - 23s 3ms/step - loss: 4.1649 - accuracy: 0.1740\n",
      "test loss, test acc: [4.16491174697876, 0.17395879328250885]\n"
     ]
    }
   ],
   "source": [
    "print(\"test loss, test acc:\", model.evaluate(test_set, test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "batch size = 256:  \n",
    "test loss, test acc: [4.276370048522949, 0.17660073935985565] => 128 epochs  \n",
    "test loss, test acc: [4.16491174697876, 0.17395879328250885] => 4 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that changing epoch count doesn't change the results that much and we should try to explore different models / architectures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_lstm = Sequential()\n",
    "# model_lstm.add(LSTM(256, input_shape = (1, 3)))\n",
    "# model_lstm.add(Dense(units=total_unique_words))\n",
    "# model_lstm.compile(loss='categorical_crossentropy',\n",
    "#               optimizer='adam',\n",
    "#               metrics=['accuracy']\n",
    "#              )\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Embedding\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import SpatialDropout1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 256)               266240    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 20568)             5285976   \n",
      "=================================================================\n",
      "Total params: 5,618,008\n",
      "Trainable params: 5,618,008\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#more elaborate model\n",
    "model_lstm = Sequential()\n",
    "\n",
    "#model_lstm.add(Embedding(input_dim = 3, output_dim = 2, input_length = 86497))\n",
    "#model_lstm.add(SpatialDropout1D(0.3))\n",
    "model_lstm.add(LSTM(256, input_shape = (1, 3), dropout = 0.3, recurrent_dropout = 0.3))\n",
    "model_lstm.add(Dense(256, activation = 'relu'))\n",
    "model_lstm.add(Dropout(0.3))\n",
    "model_lstm.add(Dense(total_unique_words, activation = 'softmax'))\n",
    "\n",
    "model_lstm.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='Adam',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model_lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xkadlec6/.local/lib/python3.6/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "train_set, train_labels = get_labels(skype_data_train, label=[\"words\"])\n",
    "test_set, test_labels = get_labels(skype_data_test, label=[\"words\"])\n",
    "\n",
    "train_labels, test_labels, _ = prepare_labels(train_labels, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(707438, 20568)\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "train_labels = to_categorical(train_labels, num_classes=total_unique_words)\n",
    "test_labels = to_categorical(test_labels, num_classes=total_unique_words)\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0, 32, 32])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshaped_values = train_set.values.reshape(-1, 1, 3)\n",
    "reshaped_values[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "5527/5527 [==============================] - 137s 24ms/step - loss: 6.9988 - accuracy: 0.1361\n",
      "Epoch 2/16\n",
      "5527/5527 [==============================] - 130s 23ms/step - loss: 6.7345 - accuracy: 0.1398\n",
      "Epoch 3/16\n",
      "5527/5527 [==============================] - 132s 24ms/step - loss: 6.6964 - accuracy: 0.1407\n",
      "Epoch 4/16\n",
      "5527/5527 [==============================] - 131s 24ms/step - loss: 6.6819 - accuracy: 0.1406\n",
      "Epoch 5/16\n",
      "5527/5527 [==============================] - 131s 24ms/step - loss: 6.6712 - accuracy: 0.1400\n",
      "Epoch 6/16\n",
      "5527/5527 [==============================] - 129s 23ms/step - loss: 6.6446 - accuracy: 0.1415\n",
      "Epoch 7/16\n",
      "5527/5527 [==============================] - 131s 24ms/step - loss: 6.6479 - accuracy: 0.1404\n",
      "Epoch 8/16\n",
      "5527/5527 [==============================] - 129s 23ms/step - loss: 6.6412 - accuracy: 0.1406\n",
      "Epoch 9/16\n",
      "5527/5527 [==============================] - 130s 24ms/step - loss: 6.6365 - accuracy: 0.1407\n",
      "Epoch 10/16\n",
      "5527/5527 [==============================] - 129s 23ms/step - loss: 6.6330 - accuracy: 0.1411\n",
      "Epoch 11/16\n",
      "5527/5527 [==============================] - 130s 24ms/step - loss: 6.6325 - accuracy: 0.1403\n",
      "Epoch 12/16\n",
      "5527/5527 [==============================] - 129s 23ms/step - loss: 6.6245 - accuracy: 0.1404\n",
      "Epoch 13/16\n",
      "5527/5527 [==============================] - 130s 23ms/step - loss: 6.6200 - accuracy: 0.1406\n",
      "Epoch 14/16\n",
      "5527/5527 [==============================] - 130s 24ms/step - loss: 6.6199 - accuracy: 0.1406\n",
      "Epoch 15/16\n",
      "5527/5527 [==============================] - 130s 23ms/step - loss: 6.6171 - accuracy: 0.1405\n",
      "Epoch 16/16\n",
      "5527/5527 [==============================] - 131s 24ms/step - loss: 6.6125 - accuracy: 0.1408\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f6c873c14a8>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lstm.fit(reshaped_values, train_labels, epochs=16, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8079/8079 [==============================] - 34s 4ms/step - loss: 10.5921 - accuracy: 0.1336\n",
      "test loss, test acc: [10.59206485748291, 0.13356362283229828]\n"
     ]
    }
   ],
   "source": [
    "print(\"test loss, test acc:\", model_lstm.evaluate(test_set.values.reshape(-1, 1, 3), test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Phonemes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (None, 256)               266240    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 3281)              843217    \n",
      "=================================================================\n",
      "Total params: 1,175,249\n",
      "Trainable params: 1,175,249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#more elaborate model\n",
    "model_lstm = Sequential()\n",
    "\n",
    "#model_lstm.add(Embedding(input_dim = 3, output_dim = 2, input_length = 86497))\n",
    "#model_lstm.add(SpatialDropout1D(0.3))\n",
    "model_lstm.add(LSTM(256, input_shape = (1, 3), dropout = 0.3, recurrent_dropout = 0.3))\n",
    "model_lstm.add(Dense(256, activation = 'relu'))\n",
    "model_lstm.add(Dropout(0.3))\n",
    "model_lstm.add(Dense(total_unique_phonemes, activation = 'softmax'))\n",
    "\n",
    "model_lstm.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='Adam',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model_lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(707438, 3281)\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "train_set, train_labels = get_labels(skype_data_train, label=['phonemes'])\n",
    "test_set, test_labels = get_labels(skype_data_test, label=['phonemes'])\n",
    "\n",
    "train_labels, test_labels, _ = prepare_labels(train_labels, test_labels, label=['phonemes'])\n",
    "\n",
    "train_labels = to_categorical(train_labels, num_classes=total_unique_phonemes)\n",
    "test_labels = to_categorical(test_labels, num_classes=total_unique_phonemes)\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0, 32, 32])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshaped_values = train_set.values.reshape(-1, 1, 3)\n",
    "reshaped_values[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "2764/2764 [==============================] - 49s 17ms/step - loss: 4.6698 - accuracy: 0.1509\n",
      "Epoch 2/64\n",
      "2764/2764 [==============================] - 45s 16ms/step - loss: 4.2666 - accuracy: 0.1706\n",
      "Epoch 3/64\n",
      "2764/2764 [==============================] - 42s 15ms/step - loss: 4.2308 - accuracy: 0.1725\n",
      "Epoch 4/64\n",
      "2764/2764 [==============================] - 43s 15ms/step - loss: 4.2184 - accuracy: 0.1732\n",
      "Epoch 5/64\n",
      "2764/2764 [==============================] - 43s 16ms/step - loss: 4.2142 - accuracy: 0.1736\n",
      "Epoch 6/64\n",
      "2764/2764 [==============================] - 41s 15ms/step - loss: 4.2074 - accuracy: 0.1746\n",
      "Epoch 7/64\n",
      "2764/2764 [==============================] - 43s 15ms/step - loss: 4.1973 - accuracy: 0.1749\n",
      "Epoch 8/64\n",
      "2764/2764 [==============================] - 41s 15ms/step - loss: 4.1966 - accuracy: 0.1752\n",
      "Epoch 9/64\n",
      "2764/2764 [==============================] - 43s 16ms/step - loss: 4.1909 - accuracy: 0.1754\n",
      "Epoch 10/64\n",
      "2764/2764 [==============================] - 42s 15ms/step - loss: 4.1867 - accuracy: 0.1754\n",
      "Epoch 11/64\n",
      "2764/2764 [==============================] - 43s 15ms/step - loss: 4.1838 - accuracy: 0.1752\n",
      "Epoch 12/64\n",
      "2764/2764 [==============================] - 43s 15ms/step - loss: 4.1860 - accuracy: 0.1752\n",
      "Epoch 13/64\n",
      "2764/2764 [==============================] - 43s 16ms/step - loss: 4.1811 - accuracy: 0.1760\n",
      "Epoch 14/64\n",
      "2764/2764 [==============================] - 44s 16ms/step - loss: 4.1822 - accuracy: 0.1761\n",
      "Epoch 15/64\n",
      "2764/2764 [==============================] - 43s 16ms/step - loss: 4.1776 - accuracy: 0.1756\n",
      "Epoch 16/64\n",
      "2764/2764 [==============================] - 43s 15ms/step - loss: 4.1755 - accuracy: 0.1765\n",
      "Epoch 17/64\n",
      "2764/2764 [==============================] - 43s 15ms/step - loss: 4.1783 - accuracy: 0.1758\n",
      "Epoch 18/64\n",
      "2764/2764 [==============================] - 42s 15ms/step - loss: 4.1767 - accuracy: 0.1754\n",
      "Epoch 19/64\n",
      "2764/2764 [==============================] - 41s 15ms/step - loss: 4.1731 - accuracy: 0.1758\n",
      "Epoch 20/64\n",
      "2764/2764 [==============================] - 42s 15ms/step - loss: 4.1771 - accuracy: 0.1758\n",
      "Epoch 21/64\n",
      "2764/2764 [==============================] - 43s 16ms/step - loss: 4.1715 - accuracy: 0.1757\n",
      "Epoch 22/64\n",
      "2764/2764 [==============================] - 44s 16ms/step - loss: 4.1725 - accuracy: 0.1764\n",
      "Epoch 23/64\n",
      "2764/2764 [==============================] - 43s 16ms/step - loss: 4.1724 - accuracy: 0.1761\n",
      "Epoch 24/64\n",
      "2764/2764 [==============================] - 43s 16ms/step - loss: 4.1686 - accuracy: 0.1762\n",
      "Epoch 25/64\n",
      "2764/2764 [==============================] - 41s 15ms/step - loss: 4.1699 - accuracy: 0.1759\n",
      "Epoch 26/64\n",
      "2764/2764 [==============================] - 43s 15ms/step - loss: 4.1711 - accuracy: 0.1766\n",
      "Epoch 27/64\n",
      "2764/2764 [==============================] - 42s 15ms/step - loss: 4.1691 - accuracy: 0.1759\n",
      "Epoch 28/64\n",
      "2764/2764 [==============================] - 42s 15ms/step - loss: 4.1698 - accuracy: 0.1762\n",
      "Epoch 29/64\n",
      "2764/2764 [==============================] - 41s 15ms/step - loss: 4.1679 - accuracy: 0.1760\n",
      "Epoch 30/64\n",
      "2764/2764 [==============================] - 41s 15ms/step - loss: 4.1657 - accuracy: 0.1766\n",
      "Epoch 31/64\n",
      "2764/2764 [==============================] - 42s 15ms/step - loss: 4.1643 - accuracy: 0.1766\n",
      "Epoch 32/64\n",
      "2764/2764 [==============================] - 42s 15ms/step - loss: 4.1653 - accuracy: 0.1759\n",
      "Epoch 33/64\n",
      "2764/2764 [==============================] - 41s 15ms/step - loss: 4.1635 - accuracy: 0.1764\n",
      "Epoch 34/64\n",
      "2764/2764 [==============================] - 40s 14ms/step - loss: 4.1717 - accuracy: 0.1760\n",
      "Epoch 35/64\n",
      "2764/2764 [==============================] - 41s 15ms/step - loss: 4.1680 - accuracy: 0.1760\n",
      "Epoch 36/64\n",
      "2764/2764 [==============================] - 41s 15ms/step - loss: 4.1574 - accuracy: 0.1763\n",
      "Epoch 37/64\n",
      "2764/2764 [==============================] - 41s 15ms/step - loss: 4.1661 - accuracy: 0.1763\n",
      "Epoch 38/64\n",
      "2764/2764 [==============================] - 42s 15ms/step - loss: 4.1622 - accuracy: 0.1767\n",
      "Epoch 39/64\n",
      "2764/2764 [==============================] - 42s 15ms/step - loss: 4.1655 - accuracy: 0.1762\n",
      "Epoch 40/64\n",
      "2764/2764 [==============================] - 41s 15ms/step - loss: 4.1637 - accuracy: 0.1759\n",
      "Epoch 41/64\n",
      "2764/2764 [==============================] - 41s 15ms/step - loss: 4.1631 - accuracy: 0.1765\n",
      "Epoch 42/64\n",
      "2764/2764 [==============================] - 41s 15ms/step - loss: 4.1646 - accuracy: 0.1764\n",
      "Epoch 43/64\n",
      "2764/2764 [==============================] - 41s 15ms/step - loss: 4.1635 - accuracy: 0.1764\n",
      "Epoch 44/64\n",
      "2764/2764 [==============================] - 42s 15ms/step - loss: 4.1578 - accuracy: 0.1776\n",
      "Epoch 45/64\n",
      "2764/2764 [==============================] - 41s 15ms/step - loss: 4.1663 - accuracy: 0.1764\n",
      "Epoch 46/64\n",
      "2764/2764 [==============================] - 42s 15ms/step - loss: 4.1622 - accuracy: 0.1769\n",
      "Epoch 47/64\n",
      "2764/2764 [==============================] - 44s 16ms/step - loss: 4.1594 - accuracy: 0.1770\n",
      "Epoch 48/64\n",
      "2764/2764 [==============================] - 43s 15ms/step - loss: 4.1614 - accuracy: 0.1770\n",
      "Epoch 49/64\n",
      "2764/2764 [==============================] - 43s 15ms/step - loss: 4.1594 - accuracy: 0.1769\n",
      "Epoch 50/64\n",
      "2764/2764 [==============================] - 41s 15ms/step - loss: 4.1600 - accuracy: 0.1766\n",
      "Epoch 51/64\n",
      "2764/2764 [==============================] - 43s 16ms/step - loss: 4.1603 - accuracy: 0.1764\n",
      "Epoch 52/64\n",
      "2764/2764 [==============================] - 45s 16ms/step - loss: 4.1615 - accuracy: 0.1774\n",
      "Epoch 53/64\n",
      "2764/2764 [==============================] - 44s 16ms/step - loss: 4.1628 - accuracy: 0.1760\n",
      "Epoch 54/64\n",
      "2764/2764 [==============================] - 44s 16ms/step - loss: 4.1571 - accuracy: 0.1772\n",
      "Epoch 55/64\n",
      "2764/2764 [==============================] - 41s 15ms/step - loss: 4.1580 - accuracy: 0.1774\n",
      "Epoch 56/64\n",
      "2764/2764 [==============================] - 45s 16ms/step - loss: 4.1563 - accuracy: 0.1772\n",
      "Epoch 57/64\n",
      "2764/2764 [==============================] - 44s 16ms/step - loss: 4.1649 - accuracy: 0.1760\n",
      "Epoch 58/64\n",
      "2764/2764 [==============================] - 43s 15ms/step - loss: 4.1625 - accuracy: 0.1764\n",
      "Epoch 59/64\n",
      "2764/2764 [==============================] - 44s 16ms/step - loss: 4.1629 - accuracy: 0.1757\n",
      "Epoch 60/64\n",
      "2764/2764 [==============================] - 43s 16ms/step - loss: 4.1634 - accuracy: 0.1763\n",
      "Epoch 61/64\n",
      "2764/2764 [==============================] - 42s 15ms/step - loss: 4.1620 - accuracy: 0.1768\n",
      "Epoch 62/64\n",
      "2764/2764 [==============================] - 43s 16ms/step - loss: 4.1609 - accuracy: 0.1772\n",
      "Epoch 63/64\n",
      "2764/2764 [==============================] - 43s 16ms/step - loss: 4.1613 - accuracy: 0.1766\n",
      "Epoch 64/64\n",
      "2764/2764 [==============================] - 43s 16ms/step - loss: 4.1637 - accuracy: 0.1768\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f58b7e112b0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lstm.fit(reshaped_values, train_labels, epochs=64, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8079/8079 [==============================] - 32s 3ms/step - loss: 7.0681 - accuracy: 0.1187\n",
      "test loss, test acc: [7.068105220794678, 0.118659608066082]\n"
     ]
    }
   ],
   "source": [
    "print(\"test loss, test acc:\", model_lstm.evaluate(test_set.values.reshape(-1, 1, 3), test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the 2 most spoken sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "She had your dark suit in greasy wash water all year.                             168\n",
       "Don't ask me to carry an oily rag like that.                                      168\n",
       "Youngsters love common candy as treats.                                             7\n",
       "The clumsy customer spilled some expensive perfume.                                 7\n",
       "The gunman kept his victim cornered at gunpoint for three hours.                    7\n",
       "                                                                                 ... \n",
       "Selected bibliographies and tables of available data are now in preparation.        1\n",
       "Set aside to dry with lid on sugar bowl.                                            1\n",
       "Several firms are merchandising enzyme preparation through feed manufacturers.      1\n",
       "She blew her nose on a tissue and opened the coke bottle.                           1\n",
       "\"Presently\", his water brother said breathlessly.                                   1\n",
       "Name: sentence, Length: 632, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_1 = \"She had your dark suit in greasy wash water all year.\"\n",
    "sentence_2 = \"Don't ask me to carry an oily rag like that.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>file</th>\n",
       "      <th>speaker</th>\n",
       "      <th>sentence</th>\n",
       "      <th>previous_packet</th>\n",
       "      <th>next_packet</th>\n",
       "      <th>packet_size</th>\n",
       "      <th>prev_curr</th>\n",
       "      <th>next_curr</th>\n",
       "      <th>packet_surrounding</th>\n",
       "      <th>phonemes</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>DR1-FCJF0-SA1.CSV</td>\n",
       "      <td>DR1-FCJF0</td>\n",
       "      <td>She had your dark suit in greasy wash water al...</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>(0, 32)</td>\n",
       "      <td>(32, 32)</td>\n",
       "      <td>(0, 32, 32)</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>DR1-FCJF0-SA1.CSV</td>\n",
       "      <td>DR1-FCJF0</td>\n",
       "      <td>She had your dark suit in greasy wash water al...</td>\n",
       "      <td>32</td>\n",
       "      <td>31</td>\n",
       "      <td>32</td>\n",
       "      <td>(32, 32)</td>\n",
       "      <td>(31, 32)</td>\n",
       "      <td>(32, 32, 31)</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>DR1-FCJF0-SA1.CSV</td>\n",
       "      <td>DR1-FCJF0</td>\n",
       "      <td>She had your dark suit in greasy wash water al...</td>\n",
       "      <td>32</td>\n",
       "      <td>28</td>\n",
       "      <td>31</td>\n",
       "      <td>(32, 31)</td>\n",
       "      <td>(28, 31)</td>\n",
       "      <td>(32, 31, 28)</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>DR1-FCJF0-SA1.CSV</td>\n",
       "      <td>DR1-FCJF0</td>\n",
       "      <td>She had your dark suit in greasy wash water al...</td>\n",
       "      <td>31</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>(31, 28)</td>\n",
       "      <td>(28, 28)</td>\n",
       "      <td>(31, 28, 28)</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>DR1-FCJF0-SA1.CSV</td>\n",
       "      <td>DR1-FCJF0</td>\n",
       "      <td>She had your dark suit in greasy wash water al...</td>\n",
       "      <td>28</td>\n",
       "      <td>36</td>\n",
       "      <td>28</td>\n",
       "      <td>(28, 28)</td>\n",
       "      <td>(36, 28)</td>\n",
       "      <td>(28, 28, 36)</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142973</th>\n",
       "      <td>706238</td>\n",
       "      <td>DR8-MTCS0-SA2.CSV</td>\n",
       "      <td>DR8-MTCS0</td>\n",
       "      <td>Don't ask me to carry an oily rag like that.</td>\n",
       "      <td>30</td>\n",
       "      <td>47</td>\n",
       "      <td>27</td>\n",
       "      <td>(30, 27)</td>\n",
       "      <td>(47, 27)</td>\n",
       "      <td>(30, 27, 47)</td>\n",
       "      <td>(tcl,)</td>\n",
       "      <td>(that,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142974</th>\n",
       "      <td>706239</td>\n",
       "      <td>DR8-MTCS0-SA2.CSV</td>\n",
       "      <td>DR8-MTCS0</td>\n",
       "      <td>Don't ask me to carry an oily rag like that.</td>\n",
       "      <td>27</td>\n",
       "      <td>49</td>\n",
       "      <td>47</td>\n",
       "      <td>(27, 47)</td>\n",
       "      <td>(49, 47)</td>\n",
       "      <td>(27, 47, 49)</td>\n",
       "      <td>(tcl, h#)</td>\n",
       "      <td>(that,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142975</th>\n",
       "      <td>706240</td>\n",
       "      <td>DR8-MTCS0-SA2.CSV</td>\n",
       "      <td>DR8-MTCS0</td>\n",
       "      <td>Don't ask me to carry an oily rag like that.</td>\n",
       "      <td>47</td>\n",
       "      <td>40</td>\n",
       "      <td>49</td>\n",
       "      <td>(47, 49)</td>\n",
       "      <td>(40, 49)</td>\n",
       "      <td>(47, 49, 40)</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142976</th>\n",
       "      <td>706241</td>\n",
       "      <td>DR8-MTCS0-SA2.CSV</td>\n",
       "      <td>DR8-MTCS0</td>\n",
       "      <td>Don't ask me to carry an oily rag like that.</td>\n",
       "      <td>49</td>\n",
       "      <td>50</td>\n",
       "      <td>40</td>\n",
       "      <td>(49, 40)</td>\n",
       "      <td>(50, 40)</td>\n",
       "      <td>(49, 40, 50)</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142977</th>\n",
       "      <td>706242</td>\n",
       "      <td>DR8-MTCS0-SA2.CSV</td>\n",
       "      <td>DR8-MTCS0</td>\n",
       "      <td>Don't ask me to carry an oily rag like that.</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>(40, 50)</td>\n",
       "      <td>(0, 50)</td>\n",
       "      <td>(40, 50, 0)</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>142978 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         index               file    speaker  \\\n",
       "0            0  DR1-FCJF0-SA1.CSV  DR1-FCJF0   \n",
       "1            1  DR1-FCJF0-SA1.CSV  DR1-FCJF0   \n",
       "2            2  DR1-FCJF0-SA1.CSV  DR1-FCJF0   \n",
       "3            3  DR1-FCJF0-SA1.CSV  DR1-FCJF0   \n",
       "4            4  DR1-FCJF0-SA1.CSV  DR1-FCJF0   \n",
       "...        ...                ...        ...   \n",
       "142973  706238  DR8-MTCS0-SA2.CSV  DR8-MTCS0   \n",
       "142974  706239  DR8-MTCS0-SA2.CSV  DR8-MTCS0   \n",
       "142975  706240  DR8-MTCS0-SA2.CSV  DR8-MTCS0   \n",
       "142976  706241  DR8-MTCS0-SA2.CSV  DR8-MTCS0   \n",
       "142977  706242  DR8-MTCS0-SA2.CSV  DR8-MTCS0   \n",
       "\n",
       "                                                 sentence  previous_packet  \\\n",
       "0       She had your dark suit in greasy wash water al...                0   \n",
       "1       She had your dark suit in greasy wash water al...               32   \n",
       "2       She had your dark suit in greasy wash water al...               32   \n",
       "3       She had your dark suit in greasy wash water al...               31   \n",
       "4       She had your dark suit in greasy wash water al...               28   \n",
       "...                                                   ...              ...   \n",
       "142973       Don't ask me to carry an oily rag like that.               30   \n",
       "142974       Don't ask me to carry an oily rag like that.               27   \n",
       "142975       Don't ask me to carry an oily rag like that.               47   \n",
       "142976       Don't ask me to carry an oily rag like that.               49   \n",
       "142977       Don't ask me to carry an oily rag like that.               40   \n",
       "\n",
       "        next_packet  packet_size prev_curr next_curr packet_surrounding  \\\n",
       "0                32           32   (0, 32)  (32, 32)        (0, 32, 32)   \n",
       "1                31           32  (32, 32)  (31, 32)       (32, 32, 31)   \n",
       "2                28           31  (32, 31)  (28, 31)       (32, 31, 28)   \n",
       "3                28           28  (31, 28)  (28, 28)       (31, 28, 28)   \n",
       "4                36           28  (28, 28)  (36, 28)       (28, 28, 36)   \n",
       "...             ...          ...       ...       ...                ...   \n",
       "142973           47           27  (30, 27)  (47, 27)       (30, 27, 47)   \n",
       "142974           49           47  (27, 47)  (49, 47)       (27, 47, 49)   \n",
       "142975           40           49  (47, 49)  (40, 49)       (47, 49, 40)   \n",
       "142976           50           40  (49, 40)  (50, 40)       (49, 40, 50)   \n",
       "142977            0           50  (40, 50)   (0, 50)        (40, 50, 0)   \n",
       "\n",
       "         phonemes    words  \n",
       "0           (h#,)      (,)  \n",
       "1           (h#,)      (,)  \n",
       "2           (h#,)      (,)  \n",
       "3           (h#,)      (,)  \n",
       "4           (h#,)      (,)  \n",
       "...           ...      ...  \n",
       "142973     (tcl,)  (that,)  \n",
       "142974  (tcl, h#)  (that,)  \n",
       "142975      (h#,)      (,)  \n",
       "142976      (h#,)      (,)  \n",
       "142977      (h#,)      (,)  \n",
       "\n",
       "[142978 rows x 12 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_sentence_train = skype_data_train.loc[skype_data_train[\"sentence\"].isin([sentence_1, sentence_2])]\n",
    "two_sentence_train.reset_index(inplace=True)\n",
    "two_sentence_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>file</th>\n",
       "      <th>speaker</th>\n",
       "      <th>sentence</th>\n",
       "      <th>previous_packet</th>\n",
       "      <th>next_packet</th>\n",
       "      <th>packet_size</th>\n",
       "      <th>prev_curr</th>\n",
       "      <th>next_curr</th>\n",
       "      <th>packet_surrounding</th>\n",
       "      <th>phonemes</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>DR1-FAKS0-SA1.CSV</td>\n",
       "      <td>DR1-FAKS0</td>\n",
       "      <td>She had your dark suit in greasy wash water al...</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>30</td>\n",
       "      <td>(0, 30)</td>\n",
       "      <td>(35, 30)</td>\n",
       "      <td>(0, 30, 35)</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>DR1-FAKS0-SA1.CSV</td>\n",
       "      <td>DR1-FAKS0</td>\n",
       "      <td>She had your dark suit in greasy wash water al...</td>\n",
       "      <td>30</td>\n",
       "      <td>43</td>\n",
       "      <td>35</td>\n",
       "      <td>(30, 35)</td>\n",
       "      <td>(43, 35)</td>\n",
       "      <td>(30, 35, 43)</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>DR1-FAKS0-SA1.CSV</td>\n",
       "      <td>DR1-FAKS0</td>\n",
       "      <td>She had your dark suit in greasy wash water al...</td>\n",
       "      <td>35</td>\n",
       "      <td>26</td>\n",
       "      <td>43</td>\n",
       "      <td>(35, 43)</td>\n",
       "      <td>(26, 43)</td>\n",
       "      <td>(35, 43, 26)</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>DR1-FAKS0-SA1.CSV</td>\n",
       "      <td>DR1-FAKS0</td>\n",
       "      <td>She had your dark suit in greasy wash water al...</td>\n",
       "      <td>43</td>\n",
       "      <td>30</td>\n",
       "      <td>26</td>\n",
       "      <td>(43, 26)</td>\n",
       "      <td>(30, 26)</td>\n",
       "      <td>(43, 26, 30)</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>DR1-FAKS0-SA1.CSV</td>\n",
       "      <td>DR1-FAKS0</td>\n",
       "      <td>She had your dark suit in greasy wash water al...</td>\n",
       "      <td>26</td>\n",
       "      <td>31</td>\n",
       "      <td>30</td>\n",
       "      <td>(26, 30)</td>\n",
       "      <td>(31, 30)</td>\n",
       "      <td>(26, 30, 31)</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52356</th>\n",
       "      <td>257508</td>\n",
       "      <td>DR8-MSLB0-SA2.CSV</td>\n",
       "      <td>DR8-MSLB0</td>\n",
       "      <td>Don't ask me to carry an oily rag like that.</td>\n",
       "      <td>47</td>\n",
       "      <td>36</td>\n",
       "      <td>32</td>\n",
       "      <td>(47, 32)</td>\n",
       "      <td>(36, 32)</td>\n",
       "      <td>(47, 32, 36)</td>\n",
       "      <td>(tcl,)</td>\n",
       "      <td>(that,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52357</th>\n",
       "      <td>257509</td>\n",
       "      <td>DR8-MSLB0-SA2.CSV</td>\n",
       "      <td>DR8-MSLB0</td>\n",
       "      <td>Don't ask me to carry an oily rag like that.</td>\n",
       "      <td>32</td>\n",
       "      <td>27</td>\n",
       "      <td>36</td>\n",
       "      <td>(32, 36)</td>\n",
       "      <td>(27, 36)</td>\n",
       "      <td>(32, 36, 27)</td>\n",
       "      <td>(tcl,)</td>\n",
       "      <td>(that,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52358</th>\n",
       "      <td>257510</td>\n",
       "      <td>DR8-MSLB0-SA2.CSV</td>\n",
       "      <td>DR8-MSLB0</td>\n",
       "      <td>Don't ask me to carry an oily rag like that.</td>\n",
       "      <td>36</td>\n",
       "      <td>26</td>\n",
       "      <td>27</td>\n",
       "      <td>(36, 27)</td>\n",
       "      <td>(26, 27)</td>\n",
       "      <td>(36, 27, 26)</td>\n",
       "      <td>(tcl, h#)</td>\n",
       "      <td>(that,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52359</th>\n",
       "      <td>257511</td>\n",
       "      <td>DR8-MSLB0-SA2.CSV</td>\n",
       "      <td>DR8-MSLB0</td>\n",
       "      <td>Don't ask me to carry an oily rag like that.</td>\n",
       "      <td>27</td>\n",
       "      <td>24</td>\n",
       "      <td>26</td>\n",
       "      <td>(27, 26)</td>\n",
       "      <td>(24, 26)</td>\n",
       "      <td>(27, 26, 24)</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52360</th>\n",
       "      <td>257512</td>\n",
       "      <td>DR8-MSLB0-SA2.CSV</td>\n",
       "      <td>DR8-MSLB0</td>\n",
       "      <td>Don't ask me to carry an oily rag like that.</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>(26, 24)</td>\n",
       "      <td>(0, 24)</td>\n",
       "      <td>(26, 24, 0)</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>52361 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        index               file    speaker  \\\n",
       "0           0  DR1-FAKS0-SA1.CSV  DR1-FAKS0   \n",
       "1           1  DR1-FAKS0-SA1.CSV  DR1-FAKS0   \n",
       "2           2  DR1-FAKS0-SA1.CSV  DR1-FAKS0   \n",
       "3           3  DR1-FAKS0-SA1.CSV  DR1-FAKS0   \n",
       "4           4  DR1-FAKS0-SA1.CSV  DR1-FAKS0   \n",
       "...       ...                ...        ...   \n",
       "52356  257508  DR8-MSLB0-SA2.CSV  DR8-MSLB0   \n",
       "52357  257509  DR8-MSLB0-SA2.CSV  DR8-MSLB0   \n",
       "52358  257510  DR8-MSLB0-SA2.CSV  DR8-MSLB0   \n",
       "52359  257511  DR8-MSLB0-SA2.CSV  DR8-MSLB0   \n",
       "52360  257512  DR8-MSLB0-SA2.CSV  DR8-MSLB0   \n",
       "\n",
       "                                                sentence  previous_packet  \\\n",
       "0      She had your dark suit in greasy wash water al...                0   \n",
       "1      She had your dark suit in greasy wash water al...               30   \n",
       "2      She had your dark suit in greasy wash water al...               35   \n",
       "3      She had your dark suit in greasy wash water al...               43   \n",
       "4      She had your dark suit in greasy wash water al...               26   \n",
       "...                                                  ...              ...   \n",
       "52356       Don't ask me to carry an oily rag like that.               47   \n",
       "52357       Don't ask me to carry an oily rag like that.               32   \n",
       "52358       Don't ask me to carry an oily rag like that.               36   \n",
       "52359       Don't ask me to carry an oily rag like that.               27   \n",
       "52360       Don't ask me to carry an oily rag like that.               26   \n",
       "\n",
       "       next_packet  packet_size prev_curr next_curr packet_surrounding  \\\n",
       "0               35           30   (0, 30)  (35, 30)        (0, 30, 35)   \n",
       "1               43           35  (30, 35)  (43, 35)       (30, 35, 43)   \n",
       "2               26           43  (35, 43)  (26, 43)       (35, 43, 26)   \n",
       "3               30           26  (43, 26)  (30, 26)       (43, 26, 30)   \n",
       "4               31           30  (26, 30)  (31, 30)       (26, 30, 31)   \n",
       "...            ...          ...       ...       ...                ...   \n",
       "52356           36           32  (47, 32)  (36, 32)       (47, 32, 36)   \n",
       "52357           27           36  (32, 36)  (27, 36)       (32, 36, 27)   \n",
       "52358           26           27  (36, 27)  (26, 27)       (36, 27, 26)   \n",
       "52359           24           26  (27, 26)  (24, 26)       (27, 26, 24)   \n",
       "52360            0           24  (26, 24)   (0, 24)        (26, 24, 0)   \n",
       "\n",
       "        phonemes    words  \n",
       "0          (h#,)      (,)  \n",
       "1          (h#,)      (,)  \n",
       "2          (h#,)      (,)  \n",
       "3          (h#,)      (,)  \n",
       "4          (h#,)      (,)  \n",
       "...          ...      ...  \n",
       "52356     (tcl,)  (that,)  \n",
       "52357     (tcl,)  (that,)  \n",
       "52358  (tcl, h#)  (that,)  \n",
       "52359      (h#,)      (,)  \n",
       "52360      (h#,)      (,)  \n",
       "\n",
       "[52361 rows x 12 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_sentence_test = skype_data_test.loc[skype_data_test[\"sentence\"].isin([sentence_1, sentence_2])]\n",
    "two_sentence_test.reset_index(inplace=True, drop=True)\n",
    "two_sentence_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, train_labels = get_labels(two_sentence_train, label=[\"words\"])\n",
    "test_set, test_labels = get_labels(two_sentence_test, label=[\"words\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n",
      "41\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_labels_2 = train_labels.append(test_labels)\n",
    "print(len(pd.unique(train_labels.words)))\n",
    "print(len(pd.unique(test_labels.words)))\n",
    "total_unique_words_2 = len(pd.unique(total_labels_2.words))\n",
    "total_unique_words_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels, test_labels, _ = prepare_labels(train_labels, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(142978, 42)\n"
     ]
    }
   ],
   "source": [
    "train_labels = to_categorical(train_labels, num_classes=total_unique_words_2)\n",
    "test_labels = to_categorical(test_labels, num_classes=total_unique_words_2)\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BE CAREFUL ABOUT TOTAL WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 42)                10794     \n",
      "=================================================================\n",
      "Total params: 144,170\n",
      "Trainable params: 144,170\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(units=512, activation='relu', input_dim=3*1))  # first hidden layer\n",
    "model.add(Dense(units=256, activation='relu'))  # second hidden layer\n",
    "# model.add(Dense(units=128, activation='relu'))  # third hidden layer\n",
    "model.add(Dense(units=total_unique_words_2, activation='softmax'))  # output layer\n",
    "# model.add(Dense(units=128))  # output layer\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 3.4161 - accuracy: 0.1275\n",
      "Epoch 2/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.8519 - accuracy: 0.1890\n",
      "Epoch 3/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.8181 - accuracy: 0.1948\n",
      "Epoch 4/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.8062 - accuracy: 0.1973\n",
      "Epoch 5/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.7795 - accuracy: 0.2017\n",
      "Epoch 6/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.7657 - accuracy: 0.2042\n",
      "Epoch 7/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.7649 - accuracy: 0.2036\n",
      "Epoch 8/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.7563 - accuracy: 0.2059\n",
      "Epoch 9/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.7460 - accuracy: 0.2083\n",
      "Epoch 10/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.7422 - accuracy: 0.2103\n",
      "Epoch 11/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.7398 - accuracy: 0.2124\n",
      "Epoch 12/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.7362 - accuracy: 0.2114\n",
      "Epoch 13/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.7372 - accuracy: 0.2096\n",
      "Epoch 14/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.7384 - accuracy: 0.2090\n",
      "Epoch 15/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.7378 - accuracy: 0.2092\n",
      "Epoch 16/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.7267 - accuracy: 0.2134\n",
      "Epoch 17/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.7343 - accuracy: 0.2108\n",
      "Epoch 18/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.7310 - accuracy: 0.2096\n",
      "Epoch 19/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.7258 - accuracy: 0.2122\n",
      "Epoch 20/128\n",
      "559/559 [==============================] - 3s 4ms/step - loss: 2.7290 - accuracy: 0.2117\n",
      "Epoch 21/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.7250 - accuracy: 0.2124\n",
      "Epoch 22/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.7260 - accuracy: 0.2142\n",
      "Epoch 23/128\n",
      "559/559 [==============================] - 3s 4ms/step - loss: 2.7256 - accuracy: 0.2131\n",
      "Epoch 24/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.7298 - accuracy: 0.2131\n",
      "Epoch 25/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.7249 - accuracy: 0.2146\n",
      "Epoch 26/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.7239 - accuracy: 0.2135\n",
      "Epoch 27/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.7186 - accuracy: 0.2138\n",
      "Epoch 28/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.7208 - accuracy: 0.2140\n",
      "Epoch 29/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.7196 - accuracy: 0.2148\n",
      "Epoch 30/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.7179 - accuracy: 0.2149\n",
      "Epoch 31/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.7150 - accuracy: 0.2159\n",
      "Epoch 32/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.7173 - accuracy: 0.2156\n",
      "Epoch 33/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.7129 - accuracy: 0.2175\n",
      "Epoch 34/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.7166 - accuracy: 0.2162\n",
      "Epoch 35/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.7138 - accuracy: 0.2160\n",
      "Epoch 36/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.7121 - accuracy: 0.2175\n",
      "Epoch 37/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.7175 - accuracy: 0.2165\n",
      "Epoch 38/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.7170 - accuracy: 0.2161\n",
      "Epoch 39/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.7189 - accuracy: 0.2155\n",
      "Epoch 40/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.7168 - accuracy: 0.2137\n",
      "Epoch 41/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.7134 - accuracy: 0.2157\n",
      "Epoch 42/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.7195 - accuracy: 0.2141\n",
      "Epoch 43/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.7118 - accuracy: 0.2171\n",
      "Epoch 44/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.7133 - accuracy: 0.2159\n",
      "Epoch 45/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.7144 - accuracy: 0.2173\n",
      "Epoch 46/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.7134 - accuracy: 0.2173\n",
      "Epoch 47/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.7175 - accuracy: 0.2144\n",
      "Epoch 48/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.7094 - accuracy: 0.2161\n",
      "Epoch 49/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.7188 - accuracy: 0.2145\n",
      "Epoch 50/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.7131 - accuracy: 0.2152\n",
      "Epoch 51/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.7084 - accuracy: 0.2171\n",
      "Epoch 52/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.7112 - accuracy: 0.2163\n",
      "Epoch 53/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.7140 - accuracy: 0.2134\n",
      "Epoch 54/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.6987 - accuracy: 0.2193\n",
      "Epoch 55/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.7081 - accuracy: 0.2158\n",
      "Epoch 56/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.7055 - accuracy: 0.2178\n",
      "Epoch 57/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.7048 - accuracy: 0.2187\n",
      "Epoch 58/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.7027 - accuracy: 0.2189\n",
      "Epoch 59/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.7090 - accuracy: 0.2179\n",
      "Epoch 60/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.7124 - accuracy: 0.2164\n",
      "Epoch 61/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.7038 - accuracy: 0.2182\n",
      "Epoch 62/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.7132 - accuracy: 0.2143\n",
      "Epoch 63/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.7038 - accuracy: 0.2193\n",
      "Epoch 64/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.7137 - accuracy: 0.2163\n",
      "Epoch 65/128\n",
      "559/559 [==============================] - 2s 4ms/step - loss: 2.7183 - accuracy: 0.2144\n",
      "Epoch 66/128\n",
      "559/559 [==============================] - 2s 4ms/step - loss: 2.7146 - accuracy: 0.2156\n",
      "Epoch 67/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.7058 - accuracy: 0.2171\n",
      "Epoch 68/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.7027 - accuracy: 0.2174\n",
      "Epoch 69/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.7056 - accuracy: 0.2165\n",
      "Epoch 70/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.7060 - accuracy: 0.2172\n",
      "Epoch 71/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.7037 - accuracy: 0.2182\n",
      "Epoch 72/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.7069 - accuracy: 0.2167\n",
      "Epoch 73/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.7076 - accuracy: 0.2162\n",
      "Epoch 74/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.7111 - accuracy: 0.2179\n",
      "Epoch 75/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.7115 - accuracy: 0.2168\n",
      "Epoch 76/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.7029 - accuracy: 0.2166\n",
      "Epoch 77/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.7112 - accuracy: 0.2165\n",
      "Epoch 78/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.7087 - accuracy: 0.2162\n",
      "Epoch 79/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.7035 - accuracy: 0.2182\n",
      "Epoch 80/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.7082 - accuracy: 0.2173\n",
      "Epoch 81/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.7039 - accuracy: 0.2174\n",
      "Epoch 82/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.7031 - accuracy: 0.2179\n",
      "Epoch 83/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.7048 - accuracy: 0.2184\n",
      "Epoch 84/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.7036 - accuracy: 0.2179\n",
      "Epoch 85/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.7088 - accuracy: 0.2182\n",
      "Epoch 86/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.7094 - accuracy: 0.2157\n",
      "Epoch 87/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.7036 - accuracy: 0.2170\n",
      "Epoch 88/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.7051 - accuracy: 0.2168\n",
      "Epoch 89/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.7024 - accuracy: 0.2192\n",
      "Epoch 90/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.7018 - accuracy: 0.2194\n",
      "Epoch 91/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.7020 - accuracy: 0.2183\n",
      "Epoch 92/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.7072 - accuracy: 0.2161\n",
      "Epoch 93/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.7068 - accuracy: 0.2169\n",
      "Epoch 94/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.7033 - accuracy: 0.2193\n",
      "Epoch 95/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.7054 - accuracy: 0.2169\n",
      "Epoch 96/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.6962 - accuracy: 0.2204\n",
      "Epoch 97/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.7128 - accuracy: 0.2154\n",
      "Epoch 98/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.7078 - accuracy: 0.2173\n",
      "Epoch 99/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.7071 - accuracy: 0.2147\n",
      "Epoch 100/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.7041 - accuracy: 0.2166\n",
      "Epoch 101/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.7043 - accuracy: 0.2198\n",
      "Epoch 102/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.7077 - accuracy: 0.2168\n",
      "Epoch 103/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.7044 - accuracy: 0.2180\n",
      "Epoch 104/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.6934 - accuracy: 0.2212\n",
      "Epoch 105/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.7076 - accuracy: 0.2167\n",
      "Epoch 106/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.6985 - accuracy: 0.2201\n",
      "Epoch 107/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.7064 - accuracy: 0.2160\n",
      "Epoch 108/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.6992 - accuracy: 0.2201\n",
      "Epoch 109/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.7035 - accuracy: 0.2187\n",
      "Epoch 110/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.7009 - accuracy: 0.2178\n",
      "Epoch 111/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.7040 - accuracy: 0.2191\n",
      "Epoch 112/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.7052 - accuracy: 0.2170\n",
      "Epoch 113/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.7040 - accuracy: 0.2191\n",
      "Epoch 114/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.7091 - accuracy: 0.2168\n",
      "Epoch 115/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.7030 - accuracy: 0.2191\n",
      "Epoch 116/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.6983 - accuracy: 0.2187\n",
      "Epoch 117/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.7053 - accuracy: 0.2176\n",
      "Epoch 118/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.7029 - accuracy: 0.2191\n",
      "Epoch 119/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.7070 - accuracy: 0.2170\n",
      "Epoch 120/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.7010 - accuracy: 0.2177\n",
      "Epoch 121/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.7022 - accuracy: 0.2174\n",
      "Epoch 122/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.7043 - accuracy: 0.2169\n",
      "Epoch 123/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.7044 - accuracy: 0.2170\n",
      "Epoch 124/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.7014 - accuracy: 0.2180\n",
      "Epoch 125/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.7049 - accuracy: 0.2173\n",
      "Epoch 126/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.7015 - accuracy: 0.2184\n",
      "Epoch 127/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.7043 - accuracy: 0.2170\n",
      "Epoch 128/128\n",
      "559/559 [==============================] - 3s 5ms/step - loss: 2.7017 - accuracy: 0.2204\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe7b516ac18>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_set, train_labels, epochs=128, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1637/1637 [==============================] - 3s 2ms/step - loss: 2.7430 - accuracy: 0.2090\n",
      "test loss, test acc: [2.743013381958008, 0.20897231996059418]\n"
     ]
    }
   ],
   "source": [
    "print(\"test loss, test acc:\", model.evaluate(test_set, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
