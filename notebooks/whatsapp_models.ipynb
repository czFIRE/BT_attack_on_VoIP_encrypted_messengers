{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replication of attack on VoIP end-to-end encrypted messengers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now try to explore various models on `Whatsapp` dataset. Bellow we will find loading and preprocessing that we have come up with in the analysis section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "sns.set()  # make plots nicer\n",
    "\n",
    "np.random.seed(42)  # set seed for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_parser_with_prev_next(path):\n",
    "    file = open(path, 'r')\n",
    "    lines = file.readlines()\n",
    "    \n",
    "    file_name = [path.split('/')[-1]]\n",
    "    sentence = \"\"\n",
    "    file_data = []\n",
    "    \n",
    "    has_value = False\n",
    "    previous = 0\n",
    "    \n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        \n",
    "        # if there are only 2 informations on line and second is h#, then ignore\n",
    "        # strip line, split primarly on ; secondary on ,\n",
    "        if (line.startswith('#')):\n",
    "            if (not sentence):\n",
    "                sentence = line[len('# Sentence: \"'): len(line) - 1]\n",
    "            continue\n",
    "        \n",
    "        line = line.split(';')\n",
    "        \n",
    "        if (len(line) == 1):\n",
    "            #lines containing only their packet size and nothing else, they should be added\n",
    "            #TODO\n",
    "            line += [\"\"]\n",
    "            line += [\"\"]\n",
    "            #continue\n",
    "        \n",
    "        if (len(line) == 2):\n",
    "            #this tries to remove most of the silence at the start of the recording\n",
    "            #potentionally harmfull as we shouldn't clean test data this way (we will be reading labels)\n",
    "            #if (line[1] == 'h#'):\n",
    "            #    continue\n",
    "            line += [\"\"]\n",
    "        \n",
    "        line[1] = tuple(line[1].split(','))\n",
    "        line[2] = tuple(list(map(lambda a: a.strip('\"'), line[2].split(','))))\n",
    "        \n",
    "        if (has_value):\n",
    "            file_data[-1][4] = line[0]\n",
    "           \n",
    "        # file_type and sentence contain duplicate informations, but are kept for readability\n",
    "        line = file_name + [file_name[0][0:9]] + [sentence] + [previous] + [0] + line\n",
    "        #adding previous as feature\n",
    "        previous = line[5]\n",
    "        file_data += [line]\n",
    "        \n",
    "        #adding next frame as feature\n",
    "        has_value = True\n",
    "        \n",
    "        \n",
    "\n",
    "    return pd.DataFrame(file_data, columns=['file', 'speaker', 'sentence', 'previous_packet', 'next_packet','packet_size', 'phonemes', 'words'])\n",
    "\n",
    "def load_files_with_prev_next(directory):\n",
    "    filelist = os.listdir(directory)\n",
    "    #read them into pandas\n",
    "    df_list = [file_parser_with_prev_next(directory+file) for file in filelist]\n",
    "    #concatenate them together\n",
    "    return pd.concat(df_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_types(data_frame):\n",
    "    data_frame['packet_size'] = pd.to_numeric(data_frame['packet_size'])\n",
    "    data_frame['previous_packet'] = pd.to_numeric(data_frame['previous_packet'])\n",
    "    data_frame['next_packet'] = pd.to_numeric(data_frame['next_packet'])\n",
    "\n",
    "    data_frame['file'] = data_frame['file'].astype('category')\n",
    "    data_frame['sentence'] = data_frame['sentence'].astype('category')\n",
    "    data_frame['speaker'] = data_frame['speaker'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>speaker</th>\n",
       "      <th>sentence</th>\n",
       "      <th>previous_packet</th>\n",
       "      <th>next_packet</th>\n",
       "      <th>packet_size</th>\n",
       "      <th>phonemes</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DR1-FAKS0-SA1.CSV</td>\n",
       "      <td>DR1-FAKS0</td>\n",
       "      <td>She had your dark suit in greasy wash water al...</td>\n",
       "      <td>0</td>\n",
       "      <td>342</td>\n",
       "      <td>249</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DR1-FAKS0-SA1.CSV</td>\n",
       "      <td>DR1-FAKS0</td>\n",
       "      <td>She had your dark suit in greasy wash water al...</td>\n",
       "      <td>249</td>\n",
       "      <td>335</td>\n",
       "      <td>342</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DR1-FAKS0-SA1.CSV</td>\n",
       "      <td>DR1-FAKS0</td>\n",
       "      <td>She had your dark suit in greasy wash water al...</td>\n",
       "      <td>342</td>\n",
       "      <td>303</td>\n",
       "      <td>335</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DR1-FAKS0-SA1.CSV</td>\n",
       "      <td>DR1-FAKS0</td>\n",
       "      <td>She had your dark suit in greasy wash water al...</td>\n",
       "      <td>335</td>\n",
       "      <td>364</td>\n",
       "      <td>303</td>\n",
       "      <td>(h#, sh)</td>\n",
       "      <td>(she,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DR1-FAKS0-SA1.CSV</td>\n",
       "      <td>DR1-FAKS0</td>\n",
       "      <td>She had your dark suit in greasy wash water al...</td>\n",
       "      <td>303</td>\n",
       "      <td>418</td>\n",
       "      <td>364</td>\n",
       "      <td>(sh, iy, hv)</td>\n",
       "      <td>(she, had)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31584</th>\n",
       "      <td>DR8-MSLB0-SX383.CSV</td>\n",
       "      <td>DR8-MSLB0</td>\n",
       "      <td>The carpet cleaners shampooed our oriental rug.</td>\n",
       "      <td>338</td>\n",
       "      <td>370</td>\n",
       "      <td>303</td>\n",
       "      <td>(r, ao, r)</td>\n",
       "      <td>(our, oriental)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31585</th>\n",
       "      <td>DR8-MSLB0-SX383.CSV</td>\n",
       "      <td>DR8-MSLB0</td>\n",
       "      <td>The carpet cleaners shampooed our oriental rug.</td>\n",
       "      <td>303</td>\n",
       "      <td>314</td>\n",
       "      <td>370</td>\n",
       "      <td>(r, iy, eh)</td>\n",
       "      <td>(oriental,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31586</th>\n",
       "      <td>DR8-MSLB0-SX383.CSV</td>\n",
       "      <td>DR8-MSLB0</td>\n",
       "      <td>The carpet cleaners shampooed our oriental rug.</td>\n",
       "      <td>370</td>\n",
       "      <td>303</td>\n",
       "      <td>314</td>\n",
       "      <td>(eh, n, tcl, t)</td>\n",
       "      <td>(oriental,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31587</th>\n",
       "      <td>DR8-MSLB0-SX383.CSV</td>\n",
       "      <td>DR8-MSLB0</td>\n",
       "      <td>The carpet cleaners shampooed our oriental rug.</td>\n",
       "      <td>314</td>\n",
       "      <td>295</td>\n",
       "      <td>303</td>\n",
       "      <td>(t, el, r, ah)</td>\n",
       "      <td>(oriental, rug)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31588</th>\n",
       "      <td>DR8-MSLB0-SX383.CSV</td>\n",
       "      <td>DR8-MSLB0</td>\n",
       "      <td>The carpet cleaners shampooed our oriental rug.</td>\n",
       "      <td>303</td>\n",
       "      <td>0</td>\n",
       "      <td>295</td>\n",
       "      <td>(ah, gcl)</td>\n",
       "      <td>(rug,)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31589 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      file    speaker  \\\n",
       "0        DR1-FAKS0-SA1.CSV  DR1-FAKS0   \n",
       "1        DR1-FAKS0-SA1.CSV  DR1-FAKS0   \n",
       "2        DR1-FAKS0-SA1.CSV  DR1-FAKS0   \n",
       "3        DR1-FAKS0-SA1.CSV  DR1-FAKS0   \n",
       "4        DR1-FAKS0-SA1.CSV  DR1-FAKS0   \n",
       "...                    ...        ...   \n",
       "31584  DR8-MSLB0-SX383.CSV  DR8-MSLB0   \n",
       "31585  DR8-MSLB0-SX383.CSV  DR8-MSLB0   \n",
       "31586  DR8-MSLB0-SX383.CSV  DR8-MSLB0   \n",
       "31587  DR8-MSLB0-SX383.CSV  DR8-MSLB0   \n",
       "31588  DR8-MSLB0-SX383.CSV  DR8-MSLB0   \n",
       "\n",
       "                                                sentence  previous_packet  \\\n",
       "0      She had your dark suit in greasy wash water al...                0   \n",
       "1      She had your dark suit in greasy wash water al...              249   \n",
       "2      She had your dark suit in greasy wash water al...              342   \n",
       "3      She had your dark suit in greasy wash water al...              335   \n",
       "4      She had your dark suit in greasy wash water al...              303   \n",
       "...                                                  ...              ...   \n",
       "31584    The carpet cleaners shampooed our oriental rug.              338   \n",
       "31585    The carpet cleaners shampooed our oriental rug.              303   \n",
       "31586    The carpet cleaners shampooed our oriental rug.              370   \n",
       "31587    The carpet cleaners shampooed our oriental rug.              314   \n",
       "31588    The carpet cleaners shampooed our oriental rug.              303   \n",
       "\n",
       "       next_packet  packet_size         phonemes            words  \n",
       "0              342          249            (h#,)              (,)  \n",
       "1              335          342            (h#,)              (,)  \n",
       "2              303          335            (h#,)              (,)  \n",
       "3              364          303         (h#, sh)           (she,)  \n",
       "4              418          364     (sh, iy, hv)       (she, had)  \n",
       "...            ...          ...              ...              ...  \n",
       "31584          370          303       (r, ao, r)  (our, oriental)  \n",
       "31585          314          370      (r, iy, eh)      (oriental,)  \n",
       "31586          303          314  (eh, n, tcl, t)      (oriental,)  \n",
       "31587          295          303   (t, el, r, ah)  (oriental, rug)  \n",
       "31588            0          295        (ah, gcl)           (rug,)  \n",
       "\n",
       "[31589 rows x 8 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whatsapp_data_train = load_files_with_prev_next(\"./../data/whatsapp_train_data/\")\n",
    "whatsapp_data_test = load_files_with_prev_next(\"./../data/whatsapp_test_data/\")\n",
    "convert_types(whatsapp_data_train)\n",
    "convert_types(whatsapp_data_test)\n",
    "whatsapp_data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>speaker</th>\n",
       "      <th>sentence</th>\n",
       "      <th>previous_packet</th>\n",
       "      <th>next_packet</th>\n",
       "      <th>packet_size</th>\n",
       "      <th>prev_curr</th>\n",
       "      <th>next_curr</th>\n",
       "      <th>packet_surrounding</th>\n",
       "      <th>phonemes</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DR1-FCJF0-SA1.CSV</td>\n",
       "      <td>DR1-FCJF0</td>\n",
       "      <td>She had your dark suit in greasy wash water al...</td>\n",
       "      <td>0</td>\n",
       "      <td>380</td>\n",
       "      <td>227</td>\n",
       "      <td>(0, 227)</td>\n",
       "      <td>(380, 227)</td>\n",
       "      <td>(0, 227, 380)</td>\n",
       "      <td>(h#,)</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DR1-FCJF0-SA1.CSV</td>\n",
       "      <td>DR1-FCJF0</td>\n",
       "      <td>She had your dark suit in greasy wash water al...</td>\n",
       "      <td>227</td>\n",
       "      <td>407</td>\n",
       "      <td>380</td>\n",
       "      <td>(227, 380)</td>\n",
       "      <td>(407, 380)</td>\n",
       "      <td>(227, 380, 407)</td>\n",
       "      <td>(h#, sh, ix)</td>\n",
       "      <td>(she,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DR1-FCJF0-SA1.CSV</td>\n",
       "      <td>DR1-FCJF0</td>\n",
       "      <td>She had your dark suit in greasy wash water al...</td>\n",
       "      <td>380</td>\n",
       "      <td>350</td>\n",
       "      <td>407</td>\n",
       "      <td>(380, 407)</td>\n",
       "      <td>(350, 407)</td>\n",
       "      <td>(380, 407, 350)</td>\n",
       "      <td>(ix, hv, eh)</td>\n",
       "      <td>(she, had)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DR1-FCJF0-SA1.CSV</td>\n",
       "      <td>DR1-FCJF0</td>\n",
       "      <td>She had your dark suit in greasy wash water al...</td>\n",
       "      <td>407</td>\n",
       "      <td>281</td>\n",
       "      <td>350</td>\n",
       "      <td>(407, 350)</td>\n",
       "      <td>(281, 350)</td>\n",
       "      <td>(407, 350, 281)</td>\n",
       "      <td>(eh, dcl, jh)</td>\n",
       "      <td>(had, your)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DR1-FCJF0-SA1.CSV</td>\n",
       "      <td>DR1-FCJF0</td>\n",
       "      <td>She had your dark suit in greasy wash water al...</td>\n",
       "      <td>350</td>\n",
       "      <td>327</td>\n",
       "      <td>281</td>\n",
       "      <td>(350, 281)</td>\n",
       "      <td>(327, 281)</td>\n",
       "      <td>(350, 281, 327)</td>\n",
       "      <td>(jh, ih, dcl, d, ah)</td>\n",
       "      <td>(had, your, dark)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86492</th>\n",
       "      <td>DR8-MTCS0-SX82.CSV</td>\n",
       "      <td>DR8-MTCS0</td>\n",
       "      <td>Good service should be rewarded by big tips.</td>\n",
       "      <td>286</td>\n",
       "      <td>253</td>\n",
       "      <td>268</td>\n",
       "      <td>(286, 268)</td>\n",
       "      <td>(253, 268)</td>\n",
       "      <td>(286, 268, 253)</td>\n",
       "      <td>(ay, bcl, b, ih)</td>\n",
       "      <td>(by, big)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86493</th>\n",
       "      <td>DR8-MTCS0-SX82.CSV</td>\n",
       "      <td>DR8-MTCS0</td>\n",
       "      <td>Good service should be rewarded by big tips.</td>\n",
       "      <td>268</td>\n",
       "      <td>315</td>\n",
       "      <td>253</td>\n",
       "      <td>(268, 253)</td>\n",
       "      <td>(315, 253)</td>\n",
       "      <td>(268, 253, 315)</td>\n",
       "      <td>(ih, gcl)</td>\n",
       "      <td>(big,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86494</th>\n",
       "      <td>DR8-MTCS0-SX82.CSV</td>\n",
       "      <td>DR8-MTCS0</td>\n",
       "      <td>Good service should be rewarded by big tips.</td>\n",
       "      <td>253</td>\n",
       "      <td>279</td>\n",
       "      <td>315</td>\n",
       "      <td>(253, 315)</td>\n",
       "      <td>(279, 315)</td>\n",
       "      <td>(253, 315, 279)</td>\n",
       "      <td>(gcl, t, ih)</td>\n",
       "      <td>(big, tips)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86495</th>\n",
       "      <td>DR8-MTCS0-SX82.CSV</td>\n",
       "      <td>DR8-MTCS0</td>\n",
       "      <td>Good service should be rewarded by big tips.</td>\n",
       "      <td>315</td>\n",
       "      <td>392</td>\n",
       "      <td>279</td>\n",
       "      <td>(315, 279)</td>\n",
       "      <td>(392, 279)</td>\n",
       "      <td>(315, 279, 392)</td>\n",
       "      <td>(ih, pcl, p)</td>\n",
       "      <td>(tips,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86496</th>\n",
       "      <td>DR8-MTCS0-SX82.CSV</td>\n",
       "      <td>DR8-MTCS0</td>\n",
       "      <td>Good service should be rewarded by big tips.</td>\n",
       "      <td>279</td>\n",
       "      <td>0</td>\n",
       "      <td>392</td>\n",
       "      <td>(279, 392)</td>\n",
       "      <td>(0, 392)</td>\n",
       "      <td>(279, 392, 0)</td>\n",
       "      <td>(p, s, h#)</td>\n",
       "      <td>(tips,)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86497 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     file    speaker  \\\n",
       "0       DR1-FCJF0-SA1.CSV  DR1-FCJF0   \n",
       "1       DR1-FCJF0-SA1.CSV  DR1-FCJF0   \n",
       "2       DR1-FCJF0-SA1.CSV  DR1-FCJF0   \n",
       "3       DR1-FCJF0-SA1.CSV  DR1-FCJF0   \n",
       "4       DR1-FCJF0-SA1.CSV  DR1-FCJF0   \n",
       "...                   ...        ...   \n",
       "86492  DR8-MTCS0-SX82.CSV  DR8-MTCS0   \n",
       "86493  DR8-MTCS0-SX82.CSV  DR8-MTCS0   \n",
       "86494  DR8-MTCS0-SX82.CSV  DR8-MTCS0   \n",
       "86495  DR8-MTCS0-SX82.CSV  DR8-MTCS0   \n",
       "86496  DR8-MTCS0-SX82.CSV  DR8-MTCS0   \n",
       "\n",
       "                                                sentence  previous_packet  \\\n",
       "0      She had your dark suit in greasy wash water al...                0   \n",
       "1      She had your dark suit in greasy wash water al...              227   \n",
       "2      She had your dark suit in greasy wash water al...              380   \n",
       "3      She had your dark suit in greasy wash water al...              407   \n",
       "4      She had your dark suit in greasy wash water al...              350   \n",
       "...                                                  ...              ...   \n",
       "86492       Good service should be rewarded by big tips.              286   \n",
       "86493       Good service should be rewarded by big tips.              268   \n",
       "86494       Good service should be rewarded by big tips.              253   \n",
       "86495       Good service should be rewarded by big tips.              315   \n",
       "86496       Good service should be rewarded by big tips.              279   \n",
       "\n",
       "       next_packet  packet_size   prev_curr   next_curr packet_surrounding  \\\n",
       "0              380          227    (0, 227)  (380, 227)      (0, 227, 380)   \n",
       "1              407          380  (227, 380)  (407, 380)    (227, 380, 407)   \n",
       "2              350          407  (380, 407)  (350, 407)    (380, 407, 350)   \n",
       "3              281          350  (407, 350)  (281, 350)    (407, 350, 281)   \n",
       "4              327          281  (350, 281)  (327, 281)    (350, 281, 327)   \n",
       "...            ...          ...         ...         ...                ...   \n",
       "86492          253          268  (286, 268)  (253, 268)    (286, 268, 253)   \n",
       "86493          315          253  (268, 253)  (315, 253)    (268, 253, 315)   \n",
       "86494          279          315  (253, 315)  (279, 315)    (253, 315, 279)   \n",
       "86495          392          279  (315, 279)  (392, 279)    (315, 279, 392)   \n",
       "86496            0          392  (279, 392)    (0, 392)      (279, 392, 0)   \n",
       "\n",
       "                   phonemes              words  \n",
       "0                     (h#,)                (,)  \n",
       "1              (h#, sh, ix)             (she,)  \n",
       "2              (ix, hv, eh)         (she, had)  \n",
       "3             (eh, dcl, jh)        (had, your)  \n",
       "4      (jh, ih, dcl, d, ah)  (had, your, dark)  \n",
       "...                     ...                ...  \n",
       "86492      (ay, bcl, b, ih)          (by, big)  \n",
       "86493             (ih, gcl)             (big,)  \n",
       "86494          (gcl, t, ih)        (big, tips)  \n",
       "86495          (ih, pcl, p)            (tips,)  \n",
       "86496            (p, s, h#)            (tips,)  \n",
       "\n",
       "[86497 rows x 11 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_surrounding(data_frame):\n",
    "    data_frame['prev_curr'] = list(zip(data_frame.previous_packet, data_frame.packet_size))\n",
    "    data_frame['next_curr'] = list(zip(data_frame.next_packet, data_frame.packet_size))\n",
    "    data_frame['packet_surrounding'] = list(zip(data_frame.previous_packet, data_frame.packet_size, data_frame.next_packet))\n",
    "    \n",
    "    #data_frame['prev_curr'] = data_frame['prev_curr'].astype('category')\n",
    "    #data_frame['next_curr'] = data_frame['next_curr'].astype('category')\n",
    "    #data_frame['packet_surrounding'] = data_frame['packet_surrounding'].astype('category')\n",
    "\n",
    "add_surrounding(whatsapp_data_train)\n",
    "add_surrounding(whatsapp_data_test)\n",
    "\n",
    "whatsapp_data_train = whatsapp_data_train[['file', 'speaker', 'sentence', 'previous_packet', 'next_packet','packet_size', 'prev_curr', 'next_curr', 'packet_surrounding', 'phonemes', 'words']]\n",
    "whatsapp_data_test = whatsapp_data_test[['file', 'speaker', 'sentence', 'previous_packet', 'next_packet','packet_size', 'prev_curr', 'next_curr', 'packet_surrounding', 'phonemes', 'words']]\n",
    "whatsapp_data_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add removal of labels for the test_dataset\n",
    "def get_labels(df, label=[\"words\"], feature=[\"previous_packet\", \"packet_size\", \"next_packet\"]):\n",
    "    labels = df[label]\n",
    "    features = df[feature]\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def prepare_labels(train_labels, test_labels, label=[\"words\"]):\n",
    "    train_labels = train_labels.astype('category')\n",
    "    test_labels = test_labels.astype('category')\n",
    "    \n",
    "    total_labels = train_labels.append(test_labels)\n",
    "    \n",
    "    lab_enc = LabelEncoder()\n",
    "    lab_enc.fit(total_labels[label])\n",
    "\n",
    "    train_labels = lab_enc.transform(train_labels[label])\n",
    "    test_labels = lab_enc.transform(test_labels[label])\n",
    "    \n",
    "    return train_labels, test_labels, lab_enc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First model that we will be trying is tree classifier. In the analysis we have noticed, that there is almost a 1:1 correspondence of trigram of phoneme sizes and words (eg. that for every trigram of phoneme sizes there is different word). \n",
    "\n",
    "add something how it might lead to something\n",
    "or about that if we have everything from the same user that then we decipher his voice recordings really easily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, train_labels = get_labels(whatsapp_data_train)\n",
    "test_set, test_labels = get_labels(whatsapp_data_test)\n",
    "\n",
    "train_labels = train_labels.astype('category')\n",
    "test_labels = test_labels.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16168\n",
      "6739\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "21317"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_labels = train_labels.append(test_labels)\n",
    "print(len(pd.unique(train_labels.words)))\n",
    "print(len(pd.unique(test_labels.words)))\n",
    "len(pd.unique(total_labels.words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can see that we have a really big problem => there are 5149 new words that we have never seen. As we saw in our analysis we can't really generalise on never seen words before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0, 15548, 15578, ...,  2531, 18676, 18676])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "lab_enc = LabelEncoder()\n",
    "lab_enc.fit(total_labels.words)\n",
    "\n",
    "train_labels = lab_enc.transform(train_labels.words)\n",
    "test_labels = lab_enc.transform(test_labels.words)\n",
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "tree_clf_pipeline = Pipeline(\n",
    "    [\n",
    "        (\n",
    "            \"clf\",\n",
    "            DecisionTreeClassifier(criterion=\"entropy\", max_depth=14, splitter=\"best\",\n",
    "                                   min_samples_split=2, random_state=42),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "# Words: criterion=\"entropy\", max_depth=None, splitter=\"best\", min_samples_split=2, random_state=42 => 0.97, 0.02\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.2631\n",
      "Test accuracy : 0.0380\n"
     ]
    }
   ],
   "source": [
    "tree_clf_pipeline.fit(train_set, train_labels)\n",
    "\n",
    "print(f\"Train accuracy: {tree_clf_pipeline.score(train_set, train_labels):.4f}\")\n",
    "print(f\"Test accuracy : {tree_clf_pipeline.score(test_set, test_labels):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Phonemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, train_labels = get_labels(whatsapp_data_train, label=[\"phonemes\"])\n",
    "test_set, test_labels = get_labels(whatsapp_data_test, label=[\"phonemes\"])\n",
    "\n",
    "train_labels = train_labels.astype('category')\n",
    "test_labels = test_labels.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27369\n",
      "12655\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "33990"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_labels = train_labels.append(test_labels)\n",
    "print(len(pd.unique(train_labels.phonemes)))\n",
    "print(len(pd.unique(test_labels.phonemes)))\n",
    "len(pd.unique(total_labels.phonemes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12858, 13445, 15553, ..., 12837, 14816, 24059])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lab_enc = LabelEncoder()\n",
    "lab_enc.fit(total_labels.phonemes)\n",
    "\n",
    "train_labels = lab_enc.transform(train_labels.phonemes)\n",
    "test_labels = lab_enc.transform(test_labels.phonemes)\n",
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.2454\n",
      "Test accuracy : 0.0293\n"
     ]
    }
   ],
   "source": [
    "tree_clf_pipeline.fit(train_set, train_labels)\n",
    "\n",
    "print(f\"Train accuracy: {tree_clf_pipeline.score(train_set, train_labels):.4f}\")\n",
    "print(f\"Test accuracy : {tree_clf_pipeline.score(test_set, test_labels):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All and all we can see, that tree classifier was really underperforming. It needed too much RAM and didn't provide any meaningfull results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look a different kind of classifier => k nearest neighbours. This classifier shouldn't need that much RAM and that much of a computational power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\swdevelopment\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "train_set, train_labels = get_labels(whatsapp_data_train, label=[\"words\"])\n",
    "test_set, test_labels = get_labels(whatsapp_data_test, label=[\"words\"])\n",
    "\n",
    "train_labels, test_labels, _ = prepare_labels(train_labels, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aha\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_clf_pipeline = Pipeline(\n",
    "    [\n",
    "        (\n",
    "            \"clf\",\n",
    "            KNeighborsClassifier(64, weights='distance', n_jobs=4)\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "#5   => 0.0313\n",
    "#10  => 0.0377\n",
    "#20  => 0.0450\n",
    "#32  => 0.0497\n",
    "#64  => 0.0567\n",
    "#128 => 0.0625\n",
    "#256 => 0.0668\n",
    "\n",
    "# uniform gives better test results but doesn't seem to be able to \"answer correctly\" on the train test\n",
    "# 64 => 0.0927, 0.0685"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9723\n",
      "Test accuracy : 0.0567\n"
     ]
    }
   ],
   "source": [
    "knn_clf_pipeline.fit(train_set, train_labels)\n",
    "\n",
    "print(f\"Train accuracy: {knn_clf_pipeline.score(train_set, train_labels):.4f}\")\n",
    "print(f\"Test accuracy : {knn_clf_pipeline.score(test_set, test_labels):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the search space of 64 nearest neighbours we get only 5.67% success rate on our test data (which is around 1971 words). I have listed other parameters and their resulting percentages in the comments in the code cell. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This whole section is just made as sanity check that we actually get expected results (that is we only guess the words we've already seen and none from which we haven't seen)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16405\n",
      "15184\n"
     ]
    }
   ],
   "source": [
    "data_test_copy = whatsapp_data_test.copy()\n",
    "\n",
    "column_select = list(map(lambda x: x in list(whatsapp_data_train.words.drop_duplicates()), list(data_test_copy.words)))\n",
    "\n",
    "print(\"Known words:\\t\", column_select.count(True))\n",
    "print(\"Unknown words:\\t\", column_select.count(False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test_copy = data_test_copy[column_select]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\swdevelopment\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "train_set, train_labels = get_labels(whatsapp_data_train, label=[\"words\"])\n",
    "test_set, test_labels = get_labels(data_test_copy, label=[\"words\"])\n",
    "\n",
    "train_labels, test_labels, _ = prepare_labels(train_labels, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.0516\n",
      "Test accuracy : 0.0622\n"
     ]
    }
   ],
   "source": [
    "# knn_clf_pipeline.fit(train_set, train_labels)\n",
    "\n",
    "# 256, distance => 0.9723, 0.1286 on only \n",
    "\n",
    "print(f\"Train accuracy: {knn_clf_pipeline.score(train_set, train_labels):.4f}\")\n",
    "print(f\"Test accuracy : {knn_clf_pipeline.score(test_set, test_labels):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this we get that the succes rate on known is around double the ammount on all words (this can be seen from the output of a cell 2 cells above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\swdevelopment\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "train_set, train_labels = get_labels(whatsapp_data_train, label=[\"words\"])\n",
    "test_set, test_labels = get_labels(whatsapp_data_test[list(map(lambda x: not x, column_select))], label=[\"words\"])\n",
    "\n",
    "train_labels, test_labels, _ = prepare_labels(train_labels, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9723\n",
      "Test accuracy : 0.0000\n"
     ]
    }
   ],
   "source": [
    "#knn_clf_pipeline.fit(train_set, train_labels)\n",
    "\n",
    "print(f\"Train accuracy: {knn_clf_pipeline.score(train_set, train_labels):.4f}\")\n",
    "print(f\"Test accuracy : {knn_clf_pipeline.score(test_set, test_labels):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This test was only made as \"sanity check\" as it is indeed highly probable that our model wouldn't be able to properly guess on never seen examples of words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try our luck with phonemes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\swdevelopment\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "train_set, train_labels = get_labels(whatsapp_data_train, label=[\"phonemes\"])\n",
    "test_set, test_labels = get_labels(whatsapp_data_test, label=[\"phonemes\"])\n",
    "\n",
    "train_labels, test_labels, _ = prepare_labels(train_labels, test_labels, label=[\"phonemes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_clf_pipeline = Pipeline(\n",
    "    [\n",
    "        (\n",
    "            \"clf\",\n",
    "            KNeighborsClassifier(64, weights='distance', n_jobs=4)\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "# 5 => 0.0256\n",
    "# 6 => 0.0269\n",
    "# 10 => 0.0299\n",
    "# 20 => 0.0343\n",
    "# 32 => 0.0368\n",
    "# 64 => 0.0404\n",
    "# 128 => 0.0441\n",
    "# 256 => 0.0465"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9723\n",
      "Test accuracy : 0.0404\n"
     ]
    }
   ],
   "source": [
    "knn_clf_pipeline.fit(train_set, train_labels)\n",
    "\n",
    "print(f\"Train accuracy: {knn_clf_pipeline.score(train_set, train_labels):.4f}\")\n",
    "print(f\"Test accuracy : {knn_clf_pipeline.score(test_set, test_labels):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can clearly see that phonemes didn't help us that much and that the results are far worse from those gotten by exploring words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, train_labels = get_labels(whatsapp_data_train, label=[\"words\"])\n",
    "test_set, test_labels = get_labels(whatsapp_data_test, label=[\"words\"])\n",
    "\n",
    "train_labels, test_labels, _ = prepare_labels(train_labels, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc_pipeline = Pipeline(\n",
    "    [\n",
    "        (\n",
    "            \"clf\",\n",
    "            KNeighborsClassifier(64, weights='distance', n_jobs=4)\n",
    "        ),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_pipeline.fit(train_set, train_labels)\n",
    "\n",
    "print(f\"Train accuracy: {svc_pipeline.score(train_set, train_labels):.4f}\")\n",
    "print(f\"Test accuracy : {svc_pipeline.score(test_set, test_labels):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, train_labels = get_labels(whatsapp_data_train, label=[\"words\"])\n",
    "test_set, test_labels = get_labels(whatsapp_data_test, label=[\"words\"])\n",
    "\n",
    "train_labels, test_labels, _ = prepare_labels(train_labels, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "abc_pipeline = Pipeline(\n",
    "    [\n",
    "        (\n",
    "            \"clf\",\n",
    "            KNeighborsClassifier(64, weights='distance', n_jobs=4)\n",
    "        ),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abc_pipeline.fit(train_set, train_labels)\n",
    "\n",
    "print(f\"Train accuracy: {abc_pipeline.score(train_set, train_labels):.4f}\")\n",
    "print(f\"Test accuracy : {abc_pipeline.score(test_set, test_labels):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, train_labels = get_labels(whatsapp_data_train, label=[\"words\"])\n",
    "test_set, test_labels = get_labels(whatsapp_data_test, label=[\"words\"])\n",
    "\n",
    "train_labels, test_labels, _ = prepare_labels(train_labels, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp_clf_pipeline = Pipeline(\n",
    "    [\n",
    "        (\n",
    "            \"clf\",\n",
    "            KNeighborsClassifier(64, weights='distance', n_jobs=4)\n",
    "        ),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_clf_pipeline.fit(train_set, train_labels)\n",
    "\n",
    "print(f\"Train accuracy: {mlp_clf_pipeline.score(train_set, train_labels):.4f}\")\n",
    "print(f\"Test accuracy : {mlp_clf_pipeline.score(test_set, test_labels):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
